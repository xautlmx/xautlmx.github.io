<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Docker," />










<meta name="description" content="环境要求 mater节点 物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台）  配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G  关闭所有swap分区或不划分swap分区   node节点 物理机虚拟机均可，大于等于1台  配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G  关闭所有swap分区或不划分swap分区   操作系统版本 Cen">
<meta name="keywords" content="Docker">
<meta property="og:type" content="article">
<meta property="og:title" content="在CentOS7上使用kubeadm快速部署Kubernetes高可用集群">
<meta property="og:url" content="http://koenli.github.io/ck49lypa4006ebvkcey7osa01.html">
<meta property="og:site_name" content="Koenli&#39;s Blog">
<meta property="og:description" content="环境要求 mater节点 物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台）  配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G  关闭所有swap分区或不划分swap分区   node节点 物理机虚拟机均可，大于等于1台  配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G  关闭所有swap分区或不划分swap分区   操作系统版本 Cen">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-12-16T09:29:34.746Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="在CentOS7上使用kubeadm快速部署Kubernetes高可用集群">
<meta name="twitter:description" content="环境要求 mater节点 物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台）  配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G  关闭所有swap分区或不划分swap分区   node节点 物理机虚拟机均可，大于等于1台  配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G  关闭所有swap分区或不划分swap分区   操作系统版本 Cen">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://koenli.github.io/ck49lypa4006ebvkcey7osa01.html"/>





  <title>在CentOS7上使用kubeadm快速部署Kubernetes高可用集群 | Koenli's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Koenli's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://koenli.github.io/ck49lypa4006ebvkcey7osa01.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Koenli">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Koenli's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">在CentOS7上使用kubeadm快速部署Kubernetes高可用集群</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-09T19:24:53+08:00">
                2019-12-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/容器/" itemprop="url" rel="index">
                    <span itemprop="name">容器</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/ck49lypa4006ebvkcey7osa01.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/ck49lypa4006ebvkcey7osa01.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/ck49lypa4006ebvkcey7osa01.html" class="leancloud_visitors" data-flag-title="在CentOS7上使用kubeadm快速部署Kubernetes高可用集群">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h1><hr>
<h2 id="mater节点"><a href="#mater节点" class="headerlink" title="mater节点"></a>mater节点</h2><ul>
<li><p>物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台）</p>
</li>
<li><p>配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G</p>
</li>
<li><p>关闭所有swap分区或不划分swap分区</p>
</li>
</ul>
<h2 id="node节点"><a href="#node节点" class="headerlink" title="node节点"></a>node节点</h2><ul>
<li><p>物理机虚拟机均可，大于等于1台</p>
</li>
<li><p>配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G</p>
</li>
<li><p>关闭所有swap分区或不划分swap分区</p>
</li>
</ul>
<h1 id="操作系统版本"><a href="#操作系统版本" class="headerlink" title="操作系统版本"></a>操作系统版本</h1><hr>
<p>CentOS7.5及以上</p>
<h1 id="实验环境信息"><a href="#实验环境信息" class="headerlink" title="实验环境信息"></a>实验环境信息</h1><hr>
<table>
<thead>
<tr>
<th style="text-align:center">主机名</th>
<th style="text-align:center">配置</th>
<th style="text-align:center">操作系统</th>
<th style="text-align:center">IP地址</th>
<th style="text-align:center">角色</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">k8s-master1</td>
<td style="text-align:center">2核2G</td>
<td style="text-align:center">CentOS7.5</td>
<td style="text-align:center">10.211.55.4</td>
<td style="text-align:center">master,node</td>
</tr>
<tr>
<td style="text-align:center">k8s-master2</td>
<td style="text-align:center">2核2G</td>
<td style="text-align:center">CentOS7.5</td>
<td style="text-align:center">10.211.55.5</td>
<td style="text-align:center">master,node</td>
</tr>
<tr>
<td style="text-align:center">k8s-master3</td>
<td style="text-align:center">2核2G</td>
<td style="text-align:center">CentOS7.5</td>
<td style="text-align:center">10.211.55.6</td>
<td style="text-align:center">master,node</td>
</tr>
</tbody>
</table>
<p>VIP:10.211.55.10</p>
<h1 id="系统初始化"><a href="#系统初始化" class="headerlink" title="系统初始化"></a>系统初始化</h1><hr>
<h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>
<h2 id="关闭selinux"><a href="#关闭selinux" class="headerlink" title="关闭selinux"></a>关闭selinux</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config</span><br></pre></td></tr></table></figure>
<h2 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">echo 'swapoff -a ' &gt;&gt; /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure>
<h2 id="配置主机名"><a href="#配置主机名" class="headerlink" title="配置主机名"></a>配置主机名</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname &lt;hostname&gt;</span><br></pre></td></tr></table></figure>
<h2 id="添加所有节点的本地host解析"><a href="#添加所有节点的本地host解析" class="headerlink" title="添加所有节点的本地host解析"></a>添加所有节点的本地host解析</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">x.x.x.x hostname1</span><br><span class="line">y.y.y.y hostname2</span><br><span class="line">...</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="安装基础软件包"><a href="#安装基础软件包" class="headerlink" title="安装基础软件包"></a>安装基础软件包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install vim net-tools lrzsz unzip dos2unix telnet sysstat iotop pciutils lsof tcpdump psmisc bc wget socat -y</span><br></pre></td></tr></table></figure>
<h2 id="内核开启网络支持"><a href="#内核开启网络支持" class="headerlink" title="内核开启网络支持"></a>内核开启网络支持</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;  /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.ipv4.ip_nonlocal_bind = 1</span><br><span class="line">EOF</span><br><span class="line">modprobe br_netfilter</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>
<h2 id="配置所有master到所有节点（包括自身）的ssh免密登录"><a href="#配置所有master到所有节点（包括自身）的ssh免密登录" class="headerlink" title="配置所有master到所有节点（包括自身）的ssh免密登录"></a>配置所有master到所有节点（包括自身）的ssh免密登录</h2><p>依此在所有的master节点上做如下操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub k8s-master1</span><br></pre></td></tr></table></figure>
<h2 id="节点之间时间同步"><a href="#节点之间时间同步" class="headerlink" title="节点之间时间同步"></a>节点之间时间同步</h2><h3 id="server端"><a href="#server端" class="headerlink" title="server端"></a>server端</h3><p><strong>注：</strong>如果环境可以访问互联网，可以不需要自己搭建server端，参考后面的client端部分设置所有节点与公网ntp时间服务器(例如time1.cloud.tencent.com)同步时间即可</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装chrony并备份配置文件</span></span><br><span class="line">yum install chrony ntpdate -y</span><br><span class="line">cp -a /etc/chrony.conf /etc/chrony.conf.bak</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改server端配置文件如下，标注的地方需要修改</span></span><br><span class="line">cat &gt; /etc/chrony.conf &lt;&lt; EOF</span><br><span class="line">stratumweight 0</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">rtcsync</span><br><span class="line">makestep 10 3</span><br><span class="line">allow 10.211.55.0/24    #设置为实际环境客户端所属IP网段</span><br><span class="line">smoothtime 400 0.01</span><br><span class="line"> </span><br><span class="line">bindcmdaddress 127.0.0.1</span><br><span class="line">bindcmdaddress ::1</span><br><span class="line"> </span><br><span class="line">local stratum 8</span><br><span class="line">manual</span><br><span class="line">keyfile /etc/chrony.keys</span><br><span class="line"><span class="meta">#</span><span class="bash">initstepslew 10 client1 client3 client6</span></span><br><span class="line">noclientlog</span><br><span class="line">logchange 0.5</span><br><span class="line">logdir /var/log/chrony</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动服务，设置开机自启</span></span><br><span class="line">systemctl restart chronyd.service</span><br><span class="line">systemctl enable  chronyd.service</span><br><span class="line">systemctl status chronyd.service</span><br></pre></td></tr></table></figure>
<h3 id="client端"><a href="#client端" class="headerlink" title="client端"></a>client端</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装chrony并备份配置文件</span></span><br><span class="line">yum install chrony ntpdate -y</span><br><span class="line">cp -a /etc/chrony.conf /etc/chrony.conf.bak</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改client端配置文件</span></span><br><span class="line">sed -i "s%^server%#server%g" /etc/chrony.conf</span><br><span class="line">echo "server 10.211.55.4 iburst" &gt;&gt; /etc/chrony.conf    #添加一行，其中的IP地址替换为实际环境server端的IP地址</span><br><span class="line"></span><br><span class="line">ntpdate  10.211.55.4    #手动同步一次时间，其中的IP地址替换为实际环境server端的IP地址</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动服务，设置开机自启</span></span><br><span class="line">systemctl restart chronyd.service</span><br><span class="line">systemctl enable  chronyd.service</span><br><span class="line">systemctl status chronyd.service</span><br><span class="line"></span><br><span class="line">chronyc  sources    #查看ntp_servers状态</span><br><span class="line">chronyc  tracking    #查看ntp详细信息</span><br></pre></td></tr></table></figure>
<h1 id="所有节点（master和node）安装docker"><a href="#所有节点（master和node）安装docker" class="headerlink" title="所有节点（master和node）安装docker"></a>所有节点（master和node）安装docker</h1><hr>
<h2 id="卸载旧版本的docker"><a href="#卸载旧版本的docker" class="headerlink" title="卸载旧版本的docker"></a>卸载旧版本的docker</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure>
<h2 id="配置docker-ce-repository"><a href="#配置docker-ce-repository" class="headerlink" title="配置docker-ce repository"></a>配置docker-ce repository</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装所需要的包，yum-utils提供了yum-config-manager工具，device-mapper-persistent-data和lvm2是设备映射存储驱动所需要的</span></span><br><span class="line">yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">设置稳定版的repo仓库</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>
<h2 id="安装docker-ce"><a href="#安装docker-ce" class="headerlink" title="安装docker-ce"></a>安装docker-ce</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装最新版本的docker-ce</span></span><br><span class="line">yum install docker-ce docker-ce-cli containerd.io -y</span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>若要安装指定版本的docker，按照如下步骤：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">列出repo仓库中可用的docker版本并降序排列</span></span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">确认好要安装的版本，例如为18.09.9，则替换yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io -y中的&lt;VERSION_STRING&gt;进行安装</span></span><br><span class="line">例如：yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y</span><br></pre></td></tr></table></figure>
<h2 id="启动docker并设置开机自启"><a href="#启动docker并设置开机自启" class="headerlink" title="启动docker并设置开机自启"></a>启动docker并设置开机自启</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br><span class="line">systemctl enable docker</span><br><span class="line">systemctl status docker</span><br></pre></td></tr></table></figure>
<h1 id="所有master节点上安装kubeadm、kubelet和kubectl"><a href="#所有master节点上安装kubeadm、kubelet和kubectl" class="headerlink" title="所有master节点上安装kubeadm、kubelet和kubectl"></a>所有master节点上安装kubeadm、kubelet和kubectl</h1><hr>
<ul>
<li><p><strong>Kubelet：</strong>负责与其他节点集群通信，并进行本节点Pod和容器生命周期的管理。</p>
</li>
<li><p><strong>Kubeadm：</strong>Kubernetes的自动化部署工具，降低了部署难度，提高效率。</p>
</li>
<li><p><strong>Kubectl：</strong>Kubernetes集群管理工具。</p>
</li>
</ul>
<h2 id="配置kubernetes-repository"><a href="#配置kubernetes-repository" class="headerlink" title="配置kubernetes repository"></a>配置kubernetes repository</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>若无法访问国外网站，可配置国内的kubernetes源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="关闭selinux-1"><a href="#关闭selinux-1" class="headerlink" title="关闭selinux"></a>关闭selinux</h2><p>关闭selinux主要是为了允许容器访问主机文件系统，在kubelet对SELINUX的支持改进前需要先关闭selinux，由于在前期准备中已做，此步可忽略</p>
<h2 id="打开net-bridge-bridge-nf-call-iptables内核参数"><a href="#打开net-bridge-bridge-nf-call-iptables内核参数" class="headerlink" title="打开net.bridge.bridge-nf-call-iptables内核参数"></a>打开net.bridge.bridge-nf-call-iptables内核参数</h2><p>配置net.bridge.bridge-nf-call-iptables内核参数为1，不开启的话可能出现流量绕过iptables而导致流量路由错误的问题，由于在前期准备中已做，此步可忽略</p>
<h2 id="安装kubeadm、kubelet和kubectl"><a href="#安装kubeadm、kubelet和kubectl" class="headerlink" title="安装kubeadm、kubelet和kubectl"></a>安装kubeadm、kubelet和kubectl</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装最新版本的kubelet、kubeadm、kubectl</span></span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line">systemctl enable --now kubelet</span><br><span class="line"><span class="meta">#</span><span class="bash">kubelet现在每隔几秒钟就重新启动一次，因为它在一个crashloop中等待kubeadm告诉它该做什么</span></span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>若要安装指定版本的kubelet、kubeadm、kubectl，可参考如下步骤：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装1.14.6版本的kubelet、kubeadm、kubectl</span></span><br><span class="line">yum install -y kubelet-1.14.6 kubeadm-1.14.6 kubectl-1.14.6 --disableexcludes=kubernetes</span><br><span class="line">systemctl enable --now kubelet</span><br><span class="line"><span class="meta">#</span><span class="bash">kubelet现在每隔几秒钟就重新启动一次，因为它在一个crashloop中等待kubeadm告诉它该做什么</span></span><br></pre></td></tr></table></figure>
<h1 id="所有的master上配置keepalived和haproxy"><a href="#所有的master上配置keepalived和haproxy" class="headerlink" title="所有的master上配置keepalived和haproxy"></a>所有的master上配置keepalived和haproxy</h1><hr>
<h2 id="keepalived"><a href="#keepalived" class="headerlink" title="keepalived"></a>keepalived</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装keeplived并备份配置文件</span></span><br><span class="line">yum install -y keepalived</span><br><span class="line">cp -a /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改keepalived配置文件如下，标注的地方需要修改</span></span><br><span class="line">cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"> </span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-master1 #标识，可用机器主机名作为标识</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER             #设置角色，第一个master为MASTER，剩余的节点均为BACKUP</span><br><span class="line">    interface eth0           #设置vip绑定端口</span><br><span class="line">    virtual_router_id 51     #让master和backup在同一个虚拟路由里，id号必须相同</span><br><span class="line">    priority 150             #优先级,谁的优先级高谁就是master，值越大优先级越高</span><br><span class="line">    advert_int 1             #心跳间隔时间</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS       #认证</span><br><span class="line">        auth_pass k8s        #密码</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        10.211.55.10      #虚拟ip</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动keepalived并设置开机自启</span></span><br><span class="line">systemctl restart keepalived.service</span><br><span class="line">systemctl enable keepalived.service</span><br><span class="line">systemctl status keepalived.service</span><br></pre></td></tr></table></figure>
<h2 id="haproxy"><a href="#haproxy" class="headerlink" title="haproxy"></a>haproxy</h2><p><strong>注：</strong>所有master节点上haproxy配置文件都是一样的</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装haproxy并备份配置文件</span></span><br><span class="line">yum install -y haproxy</span><br><span class="line">cp -a /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改haproxy配置文件如下，标注的地方需要修改</span></span><br><span class="line">cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOF</span><br><span class="line">global</span><br><span class="line">        chroot  /var/lib/haproxy</span><br><span class="line">        daemon</span><br><span class="line">        group haproxy</span><br><span class="line">        user haproxy</span><br><span class="line">        log 127.0.0.1:514 local0 warning</span><br><span class="line">        pidfile /var/lib/haproxy.pid</span><br><span class="line">        maxconn 20000</span><br><span class="line">        spread-checks 3</span><br><span class="line">        nbproc 8</span><br><span class="line">defaults</span><br><span class="line">        log     global</span><br><span class="line">        mode    tcp</span><br><span class="line">        retries 3</span><br><span class="line">        option redispatch</span><br><span class="line">listen k8s-apiserver</span><br><span class="line">        bind 0.0.0.0:8443   # 指定绑定的IP和端口，端口建议用非6443端口（此处用8443），因为如果haproxy是和k8s apiserver部署在同一台服务器上，用6443会产生端口冲突，若不是部署在同一台机器上则此处端口可以使用6443</span><br><span class="line">        mode tcp</span><br><span class="line">        balance roundrobin</span><br><span class="line">        timeout server 15s</span><br><span class="line">        timeout connect 15s</span><br><span class="line">        server k8sapiserver1 10.211.55.4:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master1的apiserver上，apiserver端口默认是6443</span><br><span class="line">        server k8sapiserver2 10.211.55.5:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master2的apiserver上，apiserver端口默认是6443</span><br><span class="line">        server k8sapiserver3 10.211.55.6:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master3的apiserver上，apiserver端口默认是6443</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动haproxy并设置开机自启</span></span><br><span class="line">systemctl restart haproxy </span><br><span class="line">systemctl enable haproxy</span><br><span class="line">systemctl status haproxy</span><br></pre></td></tr></table></figure>
<h1 id="初始化第一台master"><a href="#初始化第一台master" class="headerlink" title="初始化第一台master"></a>初始化第一台master</h1><hr>
<h2 id="新版本kubeadm"><a href="#新版本kubeadm" class="headerlink" title="新版本kubeadm"></a>新版本kubeadm</h2><h3 id="预下载镜像"><a href="#预下载镜像" class="headerlink" title="预下载镜像"></a>预下载镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images list    #查看所需的镜像</span><br><span class="line">kubeadm config images pull    #拉取所需的镜像</span><br></pre></td></tr></table></figure>
<h3 id="初始化第一个master"><a href="#初始化第一个master" class="headerlink" title="初始化第一个master"></a>初始化第一个master</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">--apiserver-advertise-address=10.211.55.4 \</span><br><span class="line">--kubernetes-version v1.16.4 \</span><br><span class="line">--service-cidr=10.1.0.0/16 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--control-plane-endpoint 10.211.55.10:8443 \</span><br><span class="line">--upload-certs</span><br></pre></td></tr></table></figure>
<p><strong>参数描述:</strong></p>
<p><strong>-–apiserver-advertise-address：</strong>用于指定kube-apiserver监听的ip地址,就是master本机IP地址。</p>
<p><strong>-–kubernetes-version：</strong>用于指定k8s版本；</p>
<p><strong>-–service-cidr：</strong>用于指定SVC的网络范围；</p>
<p><strong>-–pod-network-cidr：</strong>用于指定Pod的网络范围为10.244.0.0/16;</p>
<p><strong>-–control-plane-endpoint：</strong>指定keepalived的虚拟ip和端口</p>
<p><strong>-–upload-certs：</strong>上传证书</p>
<p>初始化成功后，会看到大概如下提示，下面信息先保留，后续添加master节点和node节点需要用到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b \</span><br><span class="line">    --control-plane --certificate-key b2ef4609c5af0d51334d49b20a3713e073ef818593d830b5b17ac58b294cc5c0</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use kubeadm init phase upload-certs to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b</span><br></pre></td></tr></table></figure>
<h3 id="配置kubectl的config文件"><a href="#配置kubectl的config文件" class="headerlink" title="配置kubectl的config文件"></a>配置kubectl的config文件</h3><p>kubectl默认会在执行的用户家目录下面的.kube目录下寻找config文件。按照上面输出的提示执行如下指令将在初始化时[kubeconfig]步骤生成的admin.conf拷贝到.kube/config，因为此配置文件中记录了apiserver的访问地址，所以后面直接执行kubectl命令就可以正常连接到APIServer中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<p>此时使用kubectl  get node能看到第一个master节点还处于NotReady状态，这是因为现在还没安装网络</p>
<h3 id="安装网络"><a href="#安装网络" class="headerlink" title="安装网络"></a>安装网络</h3><p>k8s支持多种网络类型，本文安装的是flannel网络，更多网络类型可参考<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>
<h2 id="旧版本kubeadm"><a href="#旧版本kubeadm" class="headerlink" title="旧版本kubeadm"></a>旧版本kubeadm</h2><h3 id="修改初始化配置文件"><a href="#修改初始化配置文件" class="headerlink" title="修改初始化配置文件"></a>修改初始化配置文件</h3><p><strong>注：</strong>由于之前版本的kubeadm(例如1.14.6)不支持–control-plane-endpoint参数，不能像上面那样通过kubeadm init直接初始化第一个master，需要先通过如下指令导出默认配置，然后在根据自己的实际环境修改配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config print init-defaults &gt; kubeadm-init.yml</span><br></pre></td></tr></table></figure>
<p>编辑kubeadm-init.yml，标注的地方需要修改或增加</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">bootstrapTokens:</span></span><br><span class="line"><span class="attr">- groups:</span></span><br><span class="line"><span class="attr">  - system:</span><span class="attr">bootstrappers:kubeadm:default-node-token</span></span><br><span class="line"><span class="attr">  token:</span> <span class="string">abcdef.0123456789abcdef</span></span><br><span class="line"><span class="attr">  ttl:</span> <span class="number">24</span><span class="string">h0m0s</span>    <span class="comment">####token有效期，添加节点如果token过期需要重新生成</span></span><br><span class="line"><span class="attr">  usages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">signing</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">authentication</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">localAPIEndpoint:</span></span><br><span class="line"><span class="attr">  advertiseAddress:</span> <span class="number">10.211</span><span class="number">.55</span><span class="number">.4</span>    <span class="comment">#填写本地真实IP</span></span><br><span class="line"><span class="attr">  bindPort:</span> <span class="number">6443</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line"><span class="attr">  criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">k8s-master1</span>    <span class="comment">#填写本地主机名</span></span><br><span class="line"><span class="attr">  taints:</span></span><br><span class="line"><span class="attr">  - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"><span class="attr">  timeoutForControlPlane:</span> <span class="number">4</span><span class="string">m0s</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">clusterName:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">controlPlaneEndpoint:</span> <span class="string">"10.211.55.10:8443"</span>    <span class="comment">#单master节点时这里写“本地真实IP:6443”；多master节点时写“VIP:端口”，端口要与haproxy配置中的bind字段的端口一致</span></span><br><span class="line"><span class="attr">controllerManager:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">dns:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">CoreDNS</span></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line"><span class="attr">  local:</span></span><br><span class="line"><span class="attr">    dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">k8s.gcr.io</span>    <span class="comment">#如果无法访问国外网址，可将此处的镜像仓库地址改为国内阿里云镜像仓库地址</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.14.6</span>    <span class="comment">#指定k8s版本</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"><span class="attr">  dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">  podSubnet:</span> <span class="string">"10.244.0.0/16"</span>    <span class="comment">#指定Pod的网络范围为0.244.0.0/16，若没有则flannel网络启动失败</span></span><br><span class="line"><span class="attr">  serviceSubnet:</span> <span class="number">10.1</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span>    <span class="comment">#指定SVC的网络范围</span></span><br><span class="line"><span class="attr">scheduler:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="预下载镜像-1"><a href="#预下载镜像-1" class="headerlink" title="预下载镜像"></a>预下载镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images pull --config kubeadm-init.yml</span><br></pre></td></tr></table></figure>
<h3 id="初始化第一个master-1"><a href="#初始化第一个master-1" class="headerlink" title="初始化第一个master"></a>初始化第一个master</h3><p>执行如下指令进行初始化第一个master节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config kubeadm-init.yml</span><br></pre></td></tr></table></figure>
<p>初始化成功后，会看到大概如下提示，下面信息先保留，后续添加master节点和node节点需要用到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13 \</span><br><span class="line">    --experimental-control-plane</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13</span><br></pre></td></tr></table></figure>
<h3 id="配置kubectl的config文件-1"><a href="#配置kubectl的config文件-1" class="headerlink" title="配置kubectl的config文件"></a>配置kubectl的config文件</h3><p>kubectl默认会在执行的用户家目录下面的.kube目录下寻找config文件。按照上面输出的提示执行如下指令将在初始化时[kubeconfig]步骤生成的admin.conf拷贝到.kube/config，因为此配置文件中记录了apiserver的访问地址，所以后面直接执行kubectl命令就可以正常连接到APIServer中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<p>此时使用kubectl  get node能看到第一个master节点还处于NotReady状态，这是因为现在还没安装网络</p>
<h3 id="安装网络-1"><a href="#安装网络-1" class="headerlink" title="安装网络"></a>安装网络</h3><p>k8s支持多种网络类型，本文安装的是flannel网络，更多网络类型可参考<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>
<h1 id="加入剩余的master"><a href="#加入剩余的master" class="headerlink" title="加入剩余的master"></a>加入剩余的master</h1><hr>
<h2 id="新版本kubeadm-1"><a href="#新版本kubeadm-1" class="headerlink" title="新版本kubeadm"></a>新版本kubeadm</h2><p>在剩余的master节点上运行如下指令进行初始化并配置kube的config文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \</span><br><span class="line">  --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b \</span><br><span class="line">  --control-plane --certificate-key b2ef4609c5af0d51334d49b20a3713e073ef818593d830b5b17ac58b294cc5c0</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<h2 id="旧版本kubeadm-1"><a href="#旧版本kubeadm-1" class="headerlink" title="旧版本kubeadm"></a>旧版本kubeadm</h2><p>在第一台master节点上创建如下内容的脚本（假设为add_master.sh）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CONTROL_PLANE_IPS="k8s-master2 k8s-master3"</span><br><span class="line">for host in $&#123;CONTROL_PLANE_IPS&#125;</span><br><span class="line">do</span><br><span class="line">    ssh root@$&#123;host&#125; "mkdir -p /etc/kubernetes/pki/etcd"</span><br><span class="line">    scp -r /etc/kubernetes/pki/ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/</span><br><span class="line">    scp -r /etc/kubernetes/pki/sa.* root@$&#123;host&#125;:/etc/kubernetes/pki/</span><br><span class="line">    scp -r /etc/kubernetes/pki/front-proxy-ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/</span><br><span class="line">    scp -r /etc/kubernetes/pki/etcd/ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/etcd/</span><br><span class="line">    scp -r /etc/kubernetes/admin.conf root@$&#123;host&#125;:/etc/kubernetes/</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><strong>CONTROL_PLANE_IPS变量设置其余master的主机名或者IP，之间用空格隔开(若设置主机名需要确保配置有解析)</strong></p>
<p>配置好ONTROL_PLANE_IPS后运行脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh add_master.sh</span><br></pre></td></tr></table></figure>
<p>在剩余的master节点上运行如下指令进行初始化并配置kube的config文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">  --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13 \</span><br><span class="line">  --experimental-control-plane</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>默认情况下出于安全的考虑业务pods不会调度到控制节点上，如果想要让业务pods能够调度到控制节点上的话，可以在其中一台master节点上执行如下指令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure>
<h1 id="加入node"><a href="#加入node" class="headerlink" title="加入node"></a>加入node</h1><hr>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b</span><br></pre></td></tr></table></figure>
<h1 id="安装helm"><a href="#安装helm" class="headerlink" title="安装helm"></a>安装helm</h1><hr>
<p>helm官网：<a href="https://helm.sh/" target="_blank" rel="noopener">https://helm.sh/</a></p>
<p>helm github：<a href="https://github.com/helm/helm" target="_blank" rel="noopener">https://github.com/helm/helm</a></p>
<p>下载所需版本的helm安装包（本文以2.16.1版本为例），上传到所有的master节点的/root/helm目录下(若没有此目录先创建)，执行如下指令安装helm客户端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /root/helm</span><br><span class="line">tar zxf helm-v2.16.1-linux-amd64.tar.gz</span><br><span class="line">cd linux-amd64/</span><br><span class="line">cp -a helm  /usr/local/bin/</span><br></pre></td></tr></table></figure>
<p>在其中一台master运行如下指令安装helm服务端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm init</span><br></pre></td></tr></table></figure>
<p>执行如下指令设置tiller的rbac权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl create serviceaccount -n kube-system tiller</span><br><span class="line">kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller</span><br><span class="line">kubectl --namespace kube-system patch deploy tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'</span><br><span class="line">helm init --upgrade --service-account tiller</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">稍等片刻待tiller的pod处于均Ready后执行helm list看是否可以正常列出所有的release</span></span><br><span class="line">kubectl get pods -n kube-system  |grep tiller</span><br><span class="line">helm list</span><br><span class="line">helm version</span><br></pre></td></tr></table></figure>
<p>若执行helm version出现类似如下报错</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Client: &amp;version.Version&#123;SemVer:"v2.16.1", GitCommit:"bbdfe5e7803a12bbdf97e94cd847859890cf4050", GitTreeState:"clean"&#125;</span><br><span class="line">E1213 15:58:40.605638   10274 portforward.go:400] an error occurred forwarding 34583 -&gt; 44134: error forwarding port 44134 to pod 1e92153b279110f9464193c4ea7d6314ac69e70ce60e7319df9443e379b52ed4, uid : unable to do port forwarding: socat not found</span><br></pre></td></tr></table></figure>
<p>解决办法：</p>
<p>在所有node节点上安装socat</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install socat -y</span><br></pre></td></tr></table></figure>
<h1 id="安装ingress-nginx"><a href="#安装ingress-nginx" class="headerlink" title="安装ingress-nginx"></a>安装ingress-nginx</h1><hr>
<p>ingress-nginx官网：<a href="https://kubernetes.github.io/ingress-nginx/" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/</a></p>
<p>ingress-nginx github：<a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx</a></p>
<p>在其中一台master节点上运行如下指令安装ingress-nginx</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml</span><br><span class="line">kubectl get pods -n ingress-nginx</span><br></pre></td></tr></table></figure>
<p><strong>至此已经完成一套k8s集群的部署。若还需要配置k8s对接外部存储做持久化存储，比如Ceph，可继续参考如下内容。</strong></p>
<h1 id="配置rbd-provisioner"><a href="#配置rbd-provisioner" class="headerlink" title="配置rbd-provisioner"></a>配置rbd-provisioner</h1><hr>
<p><strong>K8S要对接Ceph RBD存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考<a href="https://docs.ceph.com/docs/master/" target="_blank" rel="noopener">Ceph官网文档</a>进行。</strong></p>
<p>Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/rbd-provisioner目录下，并执行如下指令创建rbd-provisioner所需的yaml文件，标注部分根据实际情况进行修改</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/rbd-provisioner</span><br><span class="line">cd /root/rbd-provisioner</span><br><span class="line"></span><br><span class="line">cat &gt; clusterrole.yaml &lt;&lt; EOF</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["persistentvolumes"]</span><br><span class="line">    verbs: ["get", "list", "watch", "create", "delete"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["persistentvolumeclaims"]</span><br><span class="line">    verbs: ["get", "list", "watch", "update"]</span><br><span class="line">  - apiGroups: ["storage.k8s.io"]</span><br><span class="line">    resources: ["storageclasses"]</span><br><span class="line">    verbs: ["get", "list", "watch"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["events"]</span><br><span class="line">    verbs: ["create", "update", "patch"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["services"]</span><br><span class="line">    resourceNames: ["kube-dns","coredns"]</span><br><span class="line">    verbs: ["list", "get"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["endpoints"]</span><br><span class="line">    verbs: ["get", "list", "watch", "create", "update", "patch"]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; clusterrolebinding.yaml &lt;&lt; EOF</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: rbd-provisioner</span><br><span class="line">    namespace: ceph</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; deployment.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">spec:</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: rbd-provisioner</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: rbd-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: rbd-provisioner</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        image: "quay.io/external_storage/rbd-provisioner:latest"</span><br><span class="line">        env:</span><br><span class="line">        - name: PROVISIONER_NAME</span><br><span class="line">          value: ceph.com/rbd</span><br><span class="line">      serviceAccount: rbd-provisioner</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; role.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [""]</span><br><span class="line">  resources: ["secrets"]</span><br><span class="line">  verbs: ["get"]</span><br><span class="line">- apiGroups: [""]</span><br><span class="line">  resources: ["endpoints"]</span><br><span class="line">  verbs: ["get", "list", "watch", "create", "update", "patch"]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; rolebinding &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; serviceaccount.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; storageclass.yaml &lt;&lt; EOF</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.beta.kubernetes.io/is-default-class: "true"</span><br><span class="line">  name: rbd</span><br><span class="line">provisioner: ceph.com/rbd</span><br><span class="line">parameters:</span><br><span class="line">  monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789    #配置Ceph集群的monitor节点信息</span><br><span class="line">  pool: k8s    #配置要连接的pool，若没有需要先在ceph集群上创建</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretNamespace: ceph</span><br><span class="line">  adminSecretName: ceph-secret</span><br><span class="line">  fsType: ext4</span><br><span class="line">  userId: admin</span><br><span class="line">  userSecretNamespace: ceph</span><br><span class="line">  userSecretName: ceph-secret</span><br><span class="line">  imageFormat: "2"</span><br><span class="line">  imageFeatures: layering</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; secrets.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-secret</span><br><span class="line">  namespace: ceph</span><br><span class="line">type: "ceph.com/rbd"</span><br><span class="line">data:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> ceph auth add client.kube mon <span class="string">'allow r'</span> osd <span class="string">'allow rwx pool=kube'</span></span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> ceph auth get-key client.admin | base64</span></span><br><span class="line">  key: QVFEcTN5VmRvK28xRHhBQUlKNW5zQ0xwcTd3N0Q5OTJENm9YeGc9PQ==    #配置Ceph集群的kering，此处填的是经过base64编码后的值</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>执行如下执行创建rbd storageclass</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /root/rbd-provisioner</span><br><span class="line">kubectl create namespace ceph</span><br><span class="line">kubectl apply -f storageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding -f role.yaml -f secrets.yaml -f serviceaccount.yaml</span><br><span class="line">kubectl get pods -n ceph | grep rbd-provisioner</span><br></pre></td></tr></table></figure>
<h1 id="配置cephfs-provisioner"><a href="#配置cephfs-provisioner" class="headerlink" title="配置cephfs-provisioner"></a>配置cephfs-provisioner</h1><hr>
<p><strong>K8S要对接CephFS存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考<a href="https://docs.ceph.com/docs/master/" target="_blank" rel="noopener">Ceph官网文档</a>进行。</strong></p>
<p>Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/cephfs-provisioner目录下，并执行如下指令创建cephfs-provisioner所需的yaml文件，标注部分根据实际情况进行修改</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/cephfs-provisioner</span><br><span class="line">cd /root/cephfs-provisioner</span><br><span class="line"></span><br><span class="line">cat &gt; clusterrole.yaml &lt;&lt; EOF</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["persistentvolumes"]</span><br><span class="line">    verbs: ["get", "list", "watch", "create", "delete"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["persistentvolumeclaims"]</span><br><span class="line">    verbs: ["get", "list", "watch", "update"]</span><br><span class="line">  - apiGroups: ["storage.k8s.io"]</span><br><span class="line">    resources: ["storageclasses"]</span><br><span class="line">    verbs: ["get", "list", "watch"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["events"]</span><br><span class="line">    verbs: ["create", "update", "patch"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["services"]</span><br><span class="line">    resourceNames: ["kube-dns","coredns"]</span><br><span class="line">    verbs: ["list", "get"]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; clusterrolebinding.yaml &lt;&lt; EOF</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: cephfs-provisioner</span><br><span class="line">    namespace: ceph</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; deployment.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">spec:</span><br><span class="line">  progressDeadlineSeconds: 600</span><br><span class="line">  replicas: 1</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: cephfs-provisioner</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: cephfs-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: cephfs-provisioner</span><br><span class="line">        image: "quay.io/external_storage/cephfs-provisioner:latest"</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        env:</span><br><span class="line">        - name: PROVISIONER_NAME</span><br><span class="line">          value: ceph.com/cephfs</span><br><span class="line">        - name: PROVISIONER_SECRET_NAMESPACE</span><br><span class="line">          value: ceph</span><br><span class="line">        command:</span><br><span class="line">        - "/usr/local/bin/cephfs-provisioner"</span><br><span class="line">        args:</span><br><span class="line">        - "-id=cephfs-provisioner-1"</span><br><span class="line">        - "-disable-ceph-namespace-isolation=true"</span><br><span class="line">        - "-enable-quota=true"</span><br><span class="line">      serviceAccount: cephfs-provisioner</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &gt; role.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["secrets"]</span><br><span class="line">    verbs: ["create", "get", "delete"]</span><br><span class="line">  - apiGroups: [""]</span><br><span class="line">    resources: ["endpoints"]</span><br><span class="line">    verbs: ["get", "list", "watch", "create", "update", "patch"]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; rolebinding.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat  &gt; serviceaccount.yaml &lt;&lt; EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: ceph</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &gt; storageclass.yaml &lt;&lt; EOF</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs</span><br><span class="line">provisioner: ceph.com/cephfs</span><br><span class="line">parameters:</span><br><span class="line">    monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789    #配置Ceph集群的monitor节点信息</span><br><span class="line">    adminId: admin</span><br><span class="line">    adminSecretName: ceph-secret</span><br><span class="line">    adminSecretNamespace: "ceph"</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>执行如下指令创建cephfs storageclass</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /root/cephfs-provisioner</span><br><span class="line">kubectl apply -f torageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding.yaml -f role.yaml -f serviceaccount.yaml</span><br><span class="line">kubectl get pods -n ceph | grep cephfs-provisioner</span><br></pre></td></tr></table></figure>
<ul>
<li>EOF</li>
</ul>
<p>本文作者：Koen</p>
<p>参考链接：</p>
<p><a href="https://kubernetes.io/docs/setup/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/</a></p>
<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">https://docs.docker.com/install/linux/docker-ce/centos/</a></p>
<p><a href="https://blog.csdn.net/fuck487/article/details/102783300" target="_blank" rel="noopener">https://blog.csdn.net/fuck487/article/details/102783300</a></p>
<p><a href="https://github.com/kubernetes-incubator/external-storage" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/external-storage</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Docker/" rel="tag"># Docker</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/ck49lypa5006gbvkcx9cvpdfd.html" rel="next" title="在CentOS7上二进制部署Kubernetes高可用集群">
                <i class="fa fa-chevron-left"></i> 在CentOS7上二进制部署Kubernetes高可用集群
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Koenli" />
            
              <p class="site-author-name" itemprop="name">Koenli</p>
              <p class="site-description motion-element" itemprop="description">想要出类拔萃，就要做别人不想做的事</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#环境要求"><span class="nav-number">1.</span> <span class="nav-text">环境要求</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#mater节点"><span class="nav-number">1.1.</span> <span class="nav-text">mater节点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#node节点"><span class="nav-number">1.2.</span> <span class="nav-text">node节点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#操作系统版本"><span class="nav-number">2.</span> <span class="nav-text">操作系统版本</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验环境信息"><span class="nav-number">3.</span> <span class="nav-text">实验环境信息</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#系统初始化"><span class="nav-number">4.</span> <span class="nav-text">系统初始化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#关闭防火墙"><span class="nav-number">4.1.</span> <span class="nav-text">关闭防火墙</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关闭selinux"><span class="nav-number">4.2.</span> <span class="nav-text">关闭selinux</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关闭swap"><span class="nav-number">4.3.</span> <span class="nav-text">关闭swap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置主机名"><span class="nav-number">4.4.</span> <span class="nav-text">配置主机名</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#添加所有节点的本地host解析"><span class="nav-number">4.5.</span> <span class="nav-text">添加所有节点的本地host解析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装基础软件包"><span class="nav-number">4.6.</span> <span class="nav-text">安装基础软件包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#内核开启网络支持"><span class="nav-number">4.7.</span> <span class="nav-text">内核开启网络支持</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置所有master到所有节点（包括自身）的ssh免密登录"><span class="nav-number">4.8.</span> <span class="nav-text">配置所有master到所有节点（包括自身）的ssh免密登录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节点之间时间同步"><span class="nav-number">4.9.</span> <span class="nav-text">节点之间时间同步</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#server端"><span class="nav-number">4.9.1.</span> <span class="nav-text">server端</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#client端"><span class="nav-number">4.9.2.</span> <span class="nav-text">client端</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#所有节点（master和node）安装docker"><span class="nav-number">5.</span> <span class="nav-text">所有节点（master和node）安装docker</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#卸载旧版本的docker"><span class="nav-number">5.1.</span> <span class="nav-text">卸载旧版本的docker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置docker-ce-repository"><span class="nav-number">5.2.</span> <span class="nav-text">配置docker-ce repository</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装docker-ce"><span class="nav-number">5.3.</span> <span class="nav-text">安装docker-ce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动docker并设置开机自启"><span class="nav-number">5.4.</span> <span class="nav-text">启动docker并设置开机自启</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#所有master节点上安装kubeadm、kubelet和kubectl"><span class="nav-number">6.</span> <span class="nav-text">所有master节点上安装kubeadm、kubelet和kubectl</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#配置kubernetes-repository"><span class="nav-number">6.1.</span> <span class="nav-text">配置kubernetes repository</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关闭selinux-1"><span class="nav-number">6.2.</span> <span class="nav-text">关闭selinux</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#打开net-bridge-bridge-nf-call-iptables内核参数"><span class="nav-number">6.3.</span> <span class="nav-text">打开net.bridge.bridge-nf-call-iptables内核参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#安装kubeadm、kubelet和kubectl"><span class="nav-number">6.4.</span> <span class="nav-text">安装kubeadm、kubelet和kubectl</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#所有的master上配置keepalived和haproxy"><span class="nav-number">7.</span> <span class="nav-text">所有的master上配置keepalived和haproxy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#keepalived"><span class="nav-number">7.1.</span> <span class="nav-text">keepalived</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#haproxy"><span class="nav-number">7.2.</span> <span class="nav-text">haproxy</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#初始化第一台master"><span class="nav-number">8.</span> <span class="nav-text">初始化第一台master</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#新版本kubeadm"><span class="nav-number">8.1.</span> <span class="nav-text">新版本kubeadm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预下载镜像"><span class="nav-number">8.1.1.</span> <span class="nav-text">预下载镜像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#初始化第一个master"><span class="nav-number">8.1.2.</span> <span class="nav-text">初始化第一个master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置kubectl的config文件"><span class="nav-number">8.1.3.</span> <span class="nav-text">配置kubectl的config文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装网络"><span class="nav-number">8.1.4.</span> <span class="nav-text">安装网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#旧版本kubeadm"><span class="nav-number">8.2.</span> <span class="nav-text">旧版本kubeadm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#修改初始化配置文件"><span class="nav-number">8.2.1.</span> <span class="nav-text">修改初始化配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预下载镜像-1"><span class="nav-number">8.2.2.</span> <span class="nav-text">预下载镜像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#初始化第一个master-1"><span class="nav-number">8.2.3.</span> <span class="nav-text">初始化第一个master</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置kubectl的config文件-1"><span class="nav-number">8.2.4.</span> <span class="nav-text">配置kubectl的config文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装网络-1"><span class="nav-number">8.2.5.</span> <span class="nav-text">安装网络</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#加入剩余的master"><span class="nav-number">9.</span> <span class="nav-text">加入剩余的master</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#新版本kubeadm-1"><span class="nav-number">9.1.</span> <span class="nav-text">新版本kubeadm</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#旧版本kubeadm-1"><span class="nav-number">9.2.</span> <span class="nav-text">旧版本kubeadm</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#加入node"><span class="nav-number">10.</span> <span class="nav-text">加入node</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#安装helm"><span class="nav-number">11.</span> <span class="nav-text">安装helm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#安装ingress-nginx"><span class="nav-number">12.</span> <span class="nav-text">安装ingress-nginx</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#配置rbd-provisioner"><span class="nav-number">13.</span> <span class="nav-text">配置rbd-provisioner</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#配置cephfs-provisioner"><span class="nav-number">14.</span> <span class="nav-text">配置cephfs-provisioner</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Koenli</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'XD8aPBomWwb9OrD5OlP3F42U-gzGzoHsz',
        appKey: 'EHcp6RUK4G6BGD0dqfrz0IDo',
        placeholder: '想对作者说点什么',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("XD8aPBomWwb9OrD5OlP3F42U-gzGzoHsz", "EHcp6RUK4G6BGD0dqfrz0IDo");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  

  

</body>
</html>
