<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[在CentOS7上使用kubeadm快速部署Kubernetes高可用集群]]></title>
    <url>%2Fck74yvgos0025dhkcq6thzsae.html</url>
    <content type="text"><![CDATA[环境要求 Mater节点 物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台） 配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G 关闭所有swap分区或不划分swap分区 Node节点 物理机虚拟机均可，大于等于1台 配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G 关闭所有swap分区或不划分swap分区 操作系统版本 CentOS7.5及以上 实验环境信息 主机名 配置 操作系统 IP地址 角色 k8s-master1 2核2G CentOS7.5 10.211.55.4 master,node k8s-master2 2核2G CentOS7.5 10.211.55.5 master,node k8s-master3 2核2G CentOS7.5 10.211.55.6 master,node VIP:10.211.55.10 系统初始化 关闭防火墙12systemctl stop firewalldsystemctl disable firewalld 关闭selinux12setenforce 0sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config 关闭swap12swapoff -aecho 'swapoff -a ' &gt;&gt; /etc/rc.d/rc.local 配置主机名1hostnamectl set-hostname &lt;hostname&gt; 添加所有节点的本地host解析12345cat &gt;&gt; /etc/hosts &lt;&lt; EOFx.x.x.x hostname1y.y.y.y hostname2...EOF 安装基础软件包1yum install vim net-tools lrzsz unzip dos2unix telnet sysstat iotop pciutils lsof tcpdump psmisc bc wget socat -y 内核开启网络支持12345678cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1net.ipv4.ip_nonlocal_bind = 1EOFmodprobe br_netfiltersysctl -p 配置所有Master到所有节点（包括自身）的ssh免密登录依此在所有的master节点上做如下操作： 12ssh-keygen -t rsassh-copy-id -i ~/.ssh/id_rsa.pub k8s-master1 节点之间时间同步Server端注：如果环境可以访问互联网，可以不需要自己搭建server端，参考后面的client端部分设置所有节点与公网ntp时间服务器(例如time1.cloud.tencent.com)同步时间即可 1234567891011121314151617181920212223242526272829#安装chrony并备份配置文件yum install chrony ntpdate -ycp -a /etc/chrony.conf /etc/chrony.conf.bak#修改server端配置文件如下，标注的地方需要修改cat &gt; /etc/chrony.conf &lt;&lt; EOFstratumweight 0driftfile /var/lib/chrony/driftrtcsyncmakestep 10 3allow 10.211.55.0/24 #设置为实际环境客户端所属IP网段smoothtime 400 0.01 bindcmdaddress 127.0.0.1bindcmdaddress ::1 local stratum 8manualkeyfile /etc/chrony.keys#initstepslew 10 client1 client3 client6noclientloglogchange 0.5logdir /var/log/chronyEOF#启动服务，设置开机自启systemctl restart chronyd.servicesystemctl enable chronyd.servicesystemctl status chronyd.service Client端1234567891011121314151617#安装chrony并备份配置文件yum install chrony ntpdate -ycp -a /etc/chrony.conf /etc/chrony.conf.bak#修改client端配置文件sed -i "s%^server%#server%g" /etc/chrony.confecho "server 10.211.55.4 iburst" &gt;&gt; /etc/chrony.conf #添加一行，其中的IP地址替换为实际环境server端的IP地址ntpdate 10.211.55.4 #手动同步一次时间，其中的IP地址替换为实际环境server端的IP地址#启动服务，设置开机自启systemctl restart chronyd.servicesystemctl enable chronyd.servicesystemctl status chronyd.servicechronyc sources #查看ntp_servers状态chronyc tracking #查看ntp详细信息 所有节点（Master和Node）安装docker 卸载旧版本的Docker12345678yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 配置docker-ce repository123456789#安装所需要的包，yum-utils提供了yum-config-manager工具，device-mapper-persistent-data和lvm2是设备映射存储驱动所需要的yum install -y yum-utils \ device-mapper-persistent-data \ lvm2#设置稳定版的repo仓库yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 安装docker-ce12#安装最新版本的docker-ceyum install docker-ce docker-ce-cli containerd.io -y 注：若要安装指定版本的docker，按照如下步骤： 12345#列出repo仓库中可用的docker版本并降序排列yum list docker-ce --showduplicates | sort -r#确认好要安装的版本，例如为18.09.9，则替换yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io -y中的&lt;VERSION_STRING&gt;进行安装例如：yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y 启动Docker并设置开机自启123systemctl start dockersystemctl enable dockersystemctl status docker 所有节点（Master和Node）安装kubeadm、kubelet和kubectl Kubelet：负责与其他节点集群通信，并进行本节点Pod和容器生命周期的管理。 Kubeadm：Kubernetes的自动化部署工具，降低了部署难度，提高效率。 Kubectl：Kubernetes集群管理工具。 配置kubernetes repository123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF 注：若无法访问国外网站，可配置国内的kubernetes源 123456789cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 关闭selinux关闭selinux主要是为了允许容器访问主机文件系统，在kubelet对SELINUX的支持改进前需要先关闭selinux，由于在前期准备中已做，此步可忽略 打开net.bridge.bridge-nf-call-iptables内核参数配置net.bridge.bridge-nf-call-iptables内核参数为1，不开启的话可能出现流量绕过iptables而导致流量路由错误的问题，由于在前期准备中已做，此步可忽略 安装kubeadm、kubelet和kubectl1234#安装最新版本的kubelet、kubeadm、kubectlyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessystemctl enable --now kubelet#kubelet现在每隔几秒钟就重新启动一次，因为它在一个crashloop中等待kubeadm告诉它该做什么 注：若要安装指定版本的kubelet、kubeadm、kubectl，可参考如下步骤： 1234#安装1.14.6版本的kubelet、kubeadm、kubectlyum install -y kubelet-1.14.6 kubeadm-1.14.6 kubectl-1.14.6 --disableexcludes=kubernetessystemctl enable --now kubelet#kubelet现在每隔几秒钟就重新启动一次，因为它在一个crashloop中等待kubeadm告诉它该做什么 所有的Master上配置Keepalived和HAProxy（单Master节点部署忽略此步） Keepalived1234567891011121314151617181920212223242526272829303132#安装keeplived并备份配置文件yum install -y keepalivedcp -a /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak#修改keepalived配置文件如下，标注的地方需要修改cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalived global_defs &#123; router_id k8s-master1 #标识，可用机器主机名作为标识&#125; vrrp_instance VI_1 &#123; state MASTER #设置角色，第一个master为MASTER，剩余的节点均为BACKUP interface eth0 #设置vip绑定端口 virtual_router_id 51 #让master和backup在同一个虚拟路由里，id号必须相同 priority 150 #优先级,谁的优先级高谁就是master，值越大优先级越高 advert_int 1 #心跳间隔时间 authentication &#123; auth_type PASS #认证 auth_pass k8s #密码 &#125; virtual_ipaddress &#123; 10.211.55.10 #虚拟ip &#125;&#125;EOF#启动keepalived并设置开机自启systemctl restart keepalived.servicesystemctl enable keepalived.servicesystemctl status keepalived.service HAProxy注：所有master节点上haproxy配置文件都是一样的 123456789101112131415161718192021222324252627282930313233343536#安装haproxy并备份配置文件yum install -y haproxycp -a /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak#修改haproxy配置文件如下，标注的地方需要修改cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFglobal chroot /var/lib/haproxy daemon group haproxy user haproxy log 127.0.0.1:514 local0 warning pidfile /var/lib/haproxy.pid maxconn 20000 spread-checks 3 nbproc 8defaults log global mode tcp retries 3 option redispatchlisten k8s-apiserver bind 0.0.0.0:8443 # 指定绑定的IP和端口，端口建议用非6443端口（此处用8443），因为如果haproxy是和k8s apiserver部署在同一台服务器上，用6443会产生端口冲突，若不是部署在同一台机器上则此处端口可以使用6443 mode tcp balance roundrobin timeout server 15s timeout connect 15s server k8sapiserver1 10.211.55.4:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master1的apiserver上，apiserver端口默认是6443 server k8sapiserver2 10.211.55.5:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master2的apiserver上，apiserver端口默认是6443 server k8sapiserver3 10.211.55.6:6443 check port 6443 inter 5000 fall 5 #转发到k8s-master3的apiserver上，apiserver端口默认是6443EOF#启动haproxy并设置开机自启systemctl restart haproxy systemctl enable haproxysystemctl status haproxy 初始化第一台Master 新版本kubeadm初始化第一个master1234567kubeadm init \--apiserver-advertise-address=10.211.55.4 \--kubernetes-version v1.16.4 \--service-cidr=10.1.0.0/16 \--pod-network-cidr=10.244.0.0/16 \--control-plane-endpoint 10.211.55.10:8443 \--upload-certs 参数描述: -–apiserver-advertise-address：指定kube-apiserver监听的ip地址,就是master本机IP地址。 -–kubernetes-version：指定k8s版本； -–service-cidr：指定SVC的网络范围，注意不要与服务器的网络范围重叠； -–pod-network-cidr：指定Pod的网络范围，默认为10.244.0.0/16，安装网络时yaml文件中指定的网络范围要与此参数设置的一致; -–control-plane-endpoint：单Master部署时配置为Master节点IP，端口为6443；多Master部署时指定keepalived的虚拟ip和端口 -–upload-certs：上传证书 初始化成功后，会看到大概如下提示，下面信息先保留，后续添加master节点和node节点需要用到 1234567891011121314151617181920212223242526Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of control-plane nodes by copying certificate authoritiesand service account keys on each node and then running the following as root: kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \ --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b \ --control-plane --certificate-key b2ef4609c5af0d51334d49b20a3713e073ef818593d830b5b17ac58b294cc5c0Please note that the certificate-key gives access to cluster sensitive data, keep it secret!As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use kubeadm init phase upload-certs to reload certs afterward.Then you can join any number of worker nodes by running the following on each as root:kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \ --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b 配置kubectl的config文件kubectl默认会在执行的用户家目录下面的.kube目录下寻找config文件。按照上面输出的提示执行如下指令将在初始化时[kubeconfig]步骤生成的admin.conf拷贝到.kube/config，因为此配置文件中记录了apiserver的访问地址，所以后面直接执行kubectl命令就可以正常连接到APIServer中 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 此时使用kubectl get node能看到第一个master节点还处于NotReady状态，这是因为现在还没安装网络 安装网络在任意一台master节点执行如下指令下载网络yaml文件，k8s支持多种网络类型，本文安装的是flannel网络，更多网络类型可参考https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network 12cd /root/wget https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml 根据实际环境情况修改kube-flannel.yml文件，比如Network、Backend、hostNetwork配置等等，Network配置的网络范围要与kubeadm init时指定的-–pod-network-cidr一致，修改完成后进行安装 12cd /root/kubectl apply -f kube-flannel.yml 查看flannel的pod创建情况，等待到所有node节点上的flannel pod都处于running状态后表示cni部署完成 1kubectl get pods -n kube-system -o wide 旧版本kubeadm修改初始化配置文件注：由于之前版本的kubeadm(例如1.14.6)不支持–control-plane-endpoint参数，不能像上面那样通过kubeadm init直接初始化第一个master，需要先通过如下指令导出默认配置，然后在根据自己的实际环境修改配置。 1kubeadm config print init-defaults &gt; kubeadm-init.yml 编辑kubeadm-init.yml，标注的地方需要修改或增加 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: kubeadm.k8s.io/v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s ####token有效期，添加节点如果token过期需要重新生成 usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 10.211.55.4 #填写本地真实IP bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s-master1 #填写本地主机名 taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta1certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: "10.211.55.10:8443" #单master节点时这里写“本地真实IP:6443”；多master节点时写“VIP:端口”，端口要与haproxy配置中的bind字段的端口一致controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: k8s.gcr.io #如果无法访问国外网址，可将此处的镜像仓库地址改为国内阿里云镜像仓库地址kind: ClusterConfigurationkubernetesVersion: v1.14.6 #指定k8s版本networking: dnsDomain: cluster.local podSubnet: "10.244.0.0/16" #指定Pod的网络范围为10.244.0.0/16，若没有则flannel网络启动失败 serviceSubnet: 10.1.0.0/16 #指定SVC的网络范围scheduler: &#123;&#125; 预下载镜像1kubeadm config images pull --config kubeadm-init.yml 初始化第一个master执行如下指令进行初始化第一个master节点 1kubeadm init --config kubeadm-init.yml 初始化成功后，会看到大概如下提示，下面信息先保留，后续添加master节点和node节点需要用到 1234567891011121314151617181920212223Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of control-plane nodes by copying certificate authoritiesand service account keys on each node and then running the following as root: kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13 \ --experimental-control-planeThen you can join any number of worker nodes by running the following on each as root:kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13 配置kubectl的config文件kubectl默认会在执行的用户家目录下面的.kube目录下寻找config文件。按照上面输出的提示执行如下指令将在初始化时[kubeconfig]步骤生成的admin.conf拷贝到.kube/config，因为此配置文件中记录了apiserver的访问地址，所以后面直接执行kubectl命令就可以正常连接到APIServer中 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 此时使用kubectl get node能看到第一个master节点还处于NotReady状态，这是因为现在还没安装网络 安装网络在任意一台master节点执行如下指令下载网络yaml文件，k8s支持多种网络类型，本文安装的是flannel网络，更多网络类型可参考https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network 12cd /root/wget https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml 根据实际环境情况修改kube-flannel.yml文件，比如Network、Backend、hostNetwork配置等等，Network配置的网络范围要与kubeadm-init.yml中的podSubnet一致，修改完成后进行安装 12cd /root/kubectl apply -f kube-flannel.yml 查看flannel的pod创建情况，等待到所有node节点上的flannel pod都处于running状态后表示cni部署完成 1kubectl get pods -n kube-system -o wide 加入剩余的master 新版本kubeadm在剩余的master节点上运行如下指令进行初始化并配置kube的config文件： 1234567kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \ --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b \ --control-plane --certificate-key b2ef4609c5af0d51334d49b20a3713e073ef818593d830b5b17ac58b294cc5c0mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 旧版本kubeadm在第一台master节点上创建如下内容的脚本（假设为add_master.sh）： 12345678910CONTROL_PLANE_IPS="k8s-master2 k8s-master3"for host in $&#123;CONTROL_PLANE_IPS&#125;do ssh root@$&#123;host&#125; "mkdir -p /etc/kubernetes/pki/etcd" scp -r /etc/kubernetes/pki/ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/ scp -r /etc/kubernetes/pki/sa.* root@$&#123;host&#125;:/etc/kubernetes/pki/ scp -r /etc/kubernetes/pki/front-proxy-ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/ scp -r /etc/kubernetes/pki/etcd/ca.* root@$&#123;host&#125;:/etc/kubernetes/pki/etcd/ scp -r /etc/kubernetes/admin.conf root@$&#123;host&#125;:/etc/kubernetes/done CONTROL_PLANE_IPS变量设置其余master的主机名或者IP，之间用空格隔开(若设置主机名需要确保配置有解析) 配置好ONTROL_PLANE_IPS后运行脚本 1sh add_master.sh 在剩余的master节点上运行如下指令进行初始化并配置kube的config文件： 12345678kubeadm join 10.211.55.10:8443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:a0816d4859bcb4e84e25c5c87c5495e9b9e38486d3bfb3d71bc28e1ff8451e13 \ --experimental-control-planemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 注：默认情况下出于安全的考虑业务pods不会调度到控制节点上，如果想要让业务pods能够调度到控制节点上的话，可以在其中一台master节点上执行如下指令： 1kubectl taint nodes --all node-role.kubernetes.io/master- 加入Node 依此在node节点上运行如下指令： 12kubeadm join 10.211.55.10:6443 --token y55nex.s699ytnwr28o1vu1 \ --discovery-token-ca-cert-hash sha256:dd0932f4d17a864cf4ea3a7eff44c77695b47f39de03eaaf1dfd27762d7dd48b 环境测试验证 在任意一个master节点上执行如下指令创建一个nginx pod并暴露端口测试是否可以从外部正常访问 12345678910#创建nginx deploymentkubectl create deployment web --image=nginx#暴露端口kubectl expose deployment web --port=80 --type=NodePort#查看对应的访问端口kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEweb NodePort 10.1.153.72 &lt;none&gt; 80:30612/TCP 4s 浏览器访问：http://&lt;Node_IP&gt;:30612若能正常返回nginx欢迎页面，则表示环境一切正常。 部署Web UI Github地址：https://github.com/kubernetes/dashboard官方地址：https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/ 在任意一台master节点上下载Web UI的yaml文件到/root目录下 12cd /root/wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta6/aio/deploy/recommended.yaml 编辑recommended.yaml文件，找到kubernetes-dashboard这个Service的部分，设置其type为NodePort，nodePort为30001（可自定义） 12345678910111213141516171819......kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30001 selector: k8s-app: kubernetes-dashboard...... 修改完成后，执行如下指令开始部署Web UI 1234567kubectl apply -f /root/recommended.yaml#查看kubernetes-dashboard的pod，确认pod的STATUS均为running再继续下面的步骤kubectl get pods -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-76585494d8-v4gd9 1/1 Running 0 63skubernetes-dashboard-b65488c4-pwkc2 1/1 Running 0 63s 创建service account并绑定默认cluster-admin管理员集群角色： 123kubectl create serviceaccount dashboard-admin -n kubernetes-dashboardkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-adminkubectl describe secrets -n kubernetes-dashboard $(kubectl -n kubernetes-dashboard get secret | awk '/dashboard-admin/&#123;print $1&#125;') 使用上面输出的token登录Dashboard(https://&lt;NODE_IP&gt;:30001)。注意协议一定要用https **至此已经完成一套k8s集群的部署。若还需要再安装Helm、ingress-nginx、配置k8s对接外部存储做持久化存储，比如Ceph，可继续参考如下内容。 安装helm helm官网：https://helm.sh/ helm github：https://github.com/helm/helm 下载所需版本的helm安装包（本文以2.16.1版本为例），上传到所有的master节点的/root/helm目录下(若没有此目录先创建)，执行如下指令安装helm客户端 1234cd /root/helmtar zxf helm-v2.16.1-linux-amd64.tar.gzcd linux-amd64/cp -a helm /usr/local/bin/ 在其中一台master运行如下指令安装helm服务端 1helm init 执行如下指令设置tiller的rbac权限 123456789kubectl create serviceaccount -n kube-system tillerkubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tillerkubectl --namespace kube-system patch deploy tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'helm init --upgrade --service-account tiller#稍等片刻待tiller的pod处于均Ready后执行helm list看是否可以正常列出所有的releasekubectl get pods -n kube-system |grep tillerhelm listhelm version 若执行helm version出现类似如下报错 12Client: &amp;version.Version&#123;SemVer:"v2.16.1", GitCommit:"bbdfe5e7803a12bbdf97e94cd847859890cf4050", GitTreeState:"clean"&#125;E1213 15:58:40.605638 10274 portforward.go:400] an error occurred forwarding 34583 -&gt; 44134: error forwarding port 44134 to pod 1e92153b279110f9464193c4ea7d6314ac69e70ce60e7319df9443e379b52ed4, uid : unable to do port forwarding: socat not found 解决办法： 在所有node节点上安装socat 1yum install socat -y 安装ingress-nginx ingress-nginx官网：https://kubernetes.github.io/ingress-nginx/ ingress-nginx github：https://github.com/kubernetes/ingress-nginx 在任意一台master节点上下载ingress-nginx的yaml文件到/root目录下 12cd /root/wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml 编辑mandatory.yaml文件，设置ingress-nginx的部署模式，本文采用hostNetwork模式 12345678910111213141516171819202122232425262728293031...apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: "10254" prometheus.io/scrape: "true" spec: hostNetwork: true #添加此行设置ingress-nginx的部署模式为hostNetwork # wait up to five minutes for the drain of connections terminationGracePeriodSeconds: 300 serviceAccountName: nginx-ingress-serviceaccount nodeSelector: kubernetes.io/os: linux... 运行如下指令安装ingress-nginx 12345cd /root/kubectl apply -f mandatory.yaml#确认ingress-nginx的pod是否正常启动，处于running状态kubectl get pods -n ingress-nginx 配置rbd-provisioner K8S要对接Ceph RBD存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考Ceph官网文档进行。 Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/rbd-provisioner目录下，并执行如下指令创建rbd-provisioner所需的yaml文件，标注部分根据实际情况进行修改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154mkdir /root/rbd-provisionercd /root/rbd-provisionercat &gt; clusterrole.yaml &lt;&lt; EOFkind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: rbd-provisionerrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"] - apiGroups: [""] resources: ["services"] resourceNames: ["kube-dns","coredns"] verbs: ["list", "get"] - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; clusterrolebinding.yaml &lt;&lt; EOFkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: rbd-provisionersubjects: - kind: ServiceAccount name: rbd-provisioner namespace: cephroleRef: kind: ClusterRole name: rbd-provisioner apiGroup: rbac.authorization.k8s.ioEOFcat &gt; deployment.yaml &lt;&lt; EOFapiVersion: apps/v1kind: Deploymentmetadata: name: rbd-provisioner namespace: cephspec: progressDeadlineSeconds: 600 revisionHistoryLimit: 10 replicas: 1 selector: matchLabels: app: rbd-provisioner strategy: type: Recreate template: metadata: labels: app: rbd-provisioner spec: containers: - name: rbd-provisioner imagePullPolicy: IfNotPresent image: "quay.io/external_storage/rbd-provisioner:latest" env: - name: PROVISIONER_NAME value: ceph.com/rbd serviceAccount: rbd-provisioner restartPolicy: AlwaysEOFcat &gt; role.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: rbd-provisioner namespace: cephrules:- apiGroups: [""] resources: ["secrets"] verbs: ["get"]- apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; rolebinding.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: rbd-provisioner namespace: cephroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: rbd-provisionersubjects:- kind: ServiceAccount name: rbd-provisioner namespace: cephEOFcat &gt; serviceaccount.yaml &lt;&lt; EOFapiVersion: v1kind: ServiceAccountmetadata: name: rbd-provisioner namespace: cephEOFcat &gt; storageclass.yaml &lt;&lt; EOFkind: StorageClassapiVersion: storage.k8s.io/v1metadata: annotations: storageclass.beta.kubernetes.io/is-default-class: "true" name: rbdprovisioner: ceph.com/rbdparameters: monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789 #配置Ceph集群的monitor节点信息 pool: k8s #配置要连接的pool，若没有需要先在ceph集群上创建 adminId: admin adminSecretNamespace: ceph adminSecretName: ceph-secret fsType: ext4 userId: admin userSecretNamespace: ceph userSecretName: ceph-secret imageFormat: "2" imageFeatures: layeringreclaimPolicy: DeletevolumeBindingMode: ImmediateEOFcat &gt; secrets.yaml &lt;&lt; EOFapiVersion: v1kind: Secretmetadata: name: ceph-secret namespace: cephtype: "ceph.com/rbd"data: # ceph auth add client.kube mon 'allow r' osd 'allow rwx pool=kube' # ceph auth get-key client.admin | base64 key: QVFEcTN5VmRvK28xRHhBQUlKNW5zQ0xwcTd3N0Q5OTJENm9YeGc9PQ== #配置Ceph集群的kering，此处填的是经过base64编码后的值EOF 执行如下执行创建rbd storageclass 1234cd /root/rbd-provisionerkubectl create namespace cephkubectl apply -f storageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding.yaml -f role.yaml -f secrets.yaml -f serviceaccount.yamlkubectl get pods -n ceph | grep rbd-provisioner 配置cephfs-provisioner K8S要对接CephFS存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考Ceph官网文档进行。 Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/cephfs-provisioner目录下，并执行如下指令创建cephfs-provisioner所需的yaml文件，标注部分根据实际情况进行修改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139mkdir /root/cephfs-provisionercd /root/cephfs-provisionercat &gt; clusterrole.yaml &lt;&lt; EOFkind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: cephfs-provisioner namespace: cephrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"] - apiGroups: [""] resources: ["services"] resourceNames: ["kube-dns","coredns"] verbs: ["list", "get"]EOFcat &gt; clusterrolebinding.yaml &lt;&lt; EOFkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: cephfs-provisionersubjects: - kind: ServiceAccount name: cephfs-provisioner namespace: cephroleRef: kind: ClusterRole name: cephfs-provisioner apiGroup: rbac.authorization.k8s.ioEOFcat &gt; deployment.yaml &lt;&lt; EOFapiVersion: apps/v1kind: Deploymentmetadata: name: cephfs-provisioner namespace: cephspec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: cephfs-provisioner strategy: type: Recreate template: metadata: labels: app: cephfs-provisioner spec: containers: - name: cephfs-provisioner image: "quay.io/external_storage/cephfs-provisioner:latest" imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME value: ceph.com/cephfs - name: PROVISIONER_SECRET_NAMESPACE value: ceph command: - "/usr/local/bin/cephfs-provisioner" args: - "-id=cephfs-provisioner-1" - "-disable-ceph-namespace-isolation=true" - "-enable-quota=true" serviceAccount: cephfs-provisioner restartPolicy: Always terminationGracePeriodSeconds: 30EOFcat &gt; role.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: cephfs-provisioner namespace: cephrules: - apiGroups: [""] resources: ["secrets"] verbs: ["create", "get", "delete"] - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; rolebinding.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: cephfs-provisioner namespace: cephroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: cephfs-provisionersubjects:- kind: ServiceAccount name: cephfs-provisionerEOFcat &gt; serviceaccount.yaml &lt;&lt; EOFapiVersion: v1kind: ServiceAccountmetadata: name: cephfs-provisioner namespace: cephEOFcat &gt; storageclass.yaml &lt;&lt; EOFkind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: cephfsprovisioner: ceph.com/cephfsparameters: monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789 #配置Ceph集群的monitor节点信息 adminId: admin adminSecretName: ceph-secret adminSecretNamespace: "ceph"reclaimPolicy: DeletevolumeBindingMode: ImmediateEOF 执行如下指令创建cephfs storageclass 123cd /root/cephfs-provisionerkubectl apply -f storageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding.yaml -f role.yaml -f serviceaccount.yamlkubectl get pods -n ceph | grep cephfs-provisioner EOF 本文作者：Koen 参考链接： https://kubernetes.io/docs/setup/ https://docs.docker.com/install/linux/docker-ce/centos/ https://blog.csdn.net/fuck487/article/details/102783300 https://github.com/kubernetes-incubator/external-storage]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在CentOS7上二进制部署Kubernetes高可用集群]]></title>
    <url>%2Fck74yvgsa006jdhkcccfkweqt.html</url>
    <content type="text"><![CDATA[注：本文参考360资深运维工程师李振良老师的《Kubernetes/K8S架构师实战训练营【中级班】》视频课程总结而成。部分内容和图片均来自于视频课程中。 在正式进行部署之前先了解下关于Kubernetes的几个核心知识点 Kubernetes是什么 Kubernetes是Google在2014年开源的一个容器集群管理系统，Kubernetes简称K8S。 K8S用于容器化应用程序的部署、扩展和管理 K8S提供了容器编排，资源调度，弹性伸缩，部署管理，服务发现等一系列功能。 Kubernetes目标是让部署容器化应用简单高效 Kubernetes特性 自我修复 在节点故障时重新启动失败的容器，替换和重新部署，保证预期的副本数量；杀死健康检查失败的容器，并且在未准备好之前不会处理客户端请求，确保上线服务不中断。 弹性伸缩 使用命令、UI或者基于CPU使用情况自动快速扩容和缩容应用程序实例，保证应用业务高峰并发时的高可用性；业务低峰时回收资源，以最小成本运行服务。 自动部署和回滚 K8S采用滚动更新策略更新应用，一次更新一个Pod，而不是同时删除所有Pod，如果更新过程中出现问题，将回滚更改，确保升级不会影响业务。 服务发现和负载均衡 K8S为多个容器提供一个统一访问入口（内部IP地址和一个DNS名称），并且负载均衡关联所有容器，使得用户无需考虑容器IP问题 机密和配置管理 管理机密数据和应用程序配置，而不需要把敏感数据暴露在镜像里，提高敏感数据安全性。并可以将一些常用的配置存储在K8S中，方便应用程序使用。 存储编排 挂载外部存储系统，无论是来自本地存储，公有云（如AWS），还是网络存储（如NFS、GlusterFS、Ceph）都作为集群资源的一部分使用，极大提高存储使用灵活性 批处理 提供一次性任务，定时任务；满足批量数据处理和分析的场景 Kubernetes集群架构与组件 Master组件 kube-apiserver Kubernetes API，集群的统一入口，各组件协调者，以RESTful API提供接口服务，所有对象资源的增删查改和监听操作都交给APIServer处理后再提交给etcd存储。 kube-controller-manager 处理集群中常规后台任务，一个资源对应一个控制器，而ControllerManager就是负责管理这些控制器的。 kube-scheduler 根据调度算法为新创建的Pod选择一个Node节点，可以任意部署，可以部署在同一个节点，也可以部署在不同的节点上。 etcd 分布式键值存储系统。用于保存集群状态数据，比如Pod、Service等对象信息。 Node组件 kubelet kubelet是Master在Node节点上的Agent，管理本机运行容器的生命周期，比如创建容器、Pod挂载数据卷、下载secret、获取容器和节点状态等工作。kubelet将每个Pod转换成一组容器。 kube-proxy 在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作 docker或rocket 容器引擎，运行容器 Kubernetes核心概念 Pod 最小部署单元 一组容器的集合 一个Pod中的容器共享网络命名空间 Pod是暂短的 Controllers ReplicaSet：确保预期的Pod副本数量 Deployment：无状态应用部署 StatefulSet：有状态应用部署 DaemonSet：确保所有Node运行同一个Pod Job：一次性任务 CronJob：定时任务 Service 防止Pod失联 定义一组Pod的访问策略 Label标签，附加到某个资源上，用于关联对象、查询和筛选 Namespace命名空间，将对象逻辑上分离 生产环境K8S平台规划 单Master集群 多Master集群(HA) 服务器硬件配置推荐 Mater节点 物理机虚拟机均可，至少1台，高可用集群至少2台（etcd集群必须奇数台） 配置推荐：实验环境2核2G、测试环境2核4G、生产环境8核16G 关闭所有swap分区或不划分swap分区 Node节点 物理机虚拟机均可，大于等于1台 配置推荐：实验环境2核2G、测试环境4核8G、生产环境16核64G 关闭所有swap分区或不划分swap分区 实验环境信息 主机名 配置 操作系统 IP地址 角色 组件 k8s-master1 2核2G CentOS7.5 10.211.55.4 master kube-apiserverkube-controller-managerkube-scheduleretcdnginx k8s-master2 2核2G CentOS7.5 10.211.55.7 master kube-apiserverkube-controller-managerkube-schedulernginx k8s-node1 2核2G CentOS7.5 10.211.55.5 node kubeletkube-proxydockeretcd k8s-node2 2核2G CentOS7.5 10.211.55.6 node kubeletkube-proxydockeretcd VIP:10.211.55.10 系统初始化 关闭防火墙12systemctl stop firewalldsystemctl disable firewalld 关闭selinux12setenforce 0sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config 关闭swap12swapoff -aecho 'swapoff -a ' &gt;&gt; /etc/rc.d/rc.local 配置主机名1hostnamectl set-hostname &lt;hostname&gt; 添加所有节点的本地host解析12345cat &gt;&gt; /etc/hosts &lt;&lt; EOFx.x.x.x hostname1y.y.y.y hostname2...EOF 安装基础软件包1yum install vim net-tools lrzsz unzip dos2unix telnet sysstat iotop pciutils lsof tcpdump psmisc bc wget socat -y 内核开启网络支持12345678cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1net.ipv4.ip_nonlocal_bind = 1EOFmodprobe br_netfiltersysctl -p 配置所有master到所有节点（包括自身）的ssh免密登录依此在所有的master节点上做如下操作： 12ssh-keygen -t rsassh-copy-id -i ~/.ssh/id_rsa.pub k8s-master1 节点之间时间同步server端注：如果环境可以访问互联网，可以不需要自己搭建server端，参考后面的client端部分设置所有节点与公网ntp时间服务器(例如time1.cloud.tencent.com)同步时间即可 1234567891011121314151617181920212223242526272829#安装chrony并备份配置文件yum install chrony ntpdate -ycp -a /etc/chrony.conf /etc/chrony.conf.bak#修改server端配置文件如下，标注的地方需要修改cat &gt; /etc/chrony.conf &lt;&lt; EOFstratumweight 0driftfile /var/lib/chrony/driftrtcsyncmakestep 10 3allow 10.211.55.0/24 #设置为实际环境客户端所属IP网段smoothtime 400 0.01 bindcmdaddress 127.0.0.1bindcmdaddress ::1 local stratum 8manualkeyfile /etc/chrony.keys#initstepslew 10 client1 client3 client6noclientloglogchange 0.5logdir /var/log/chronyEOF#启动服务，设置开机自启systemctl restart chronyd.servicesystemctl enable chronyd.servicesystemctl status chronyd.service client端1234567891011121314151617#安装chrony并备份配置文件yum install chrony ntpdate -ycp -a /etc/chrony.conf /etc/chrony.conf.bak#修改client端配置文件sed -i "s%^server%#server%g" /etc/chrony.confecho "server 10.211.55.4 iburst" &gt;&gt; /etc/chrony.conf #添加一行，其中的IP地址替换为实际环境server端的IP地址ntpdate 10.211.55.4 #手动同步一次时间，其中的IP地址替换为实际环境server端的IP地址#启动服务，设置开机自启systemctl restart chronyd.servicesystemctl enable chronyd.servicesystemctl status chronyd.servicechronyc sources #查看ntp_servers状态chronyc tracking #查看ntp详细信息 安装CFSSL工具 CFSSL是CloudFlare开源的一款PKI/TLS工具。 CFSSL 包含一个命令行工具 和一个用于 签名，验证并且捆绑TLS证书的 HTTP API 服务。 使用Go语言编写 Github地址：https://github.com/cloudflare/cfssl官网地址：https://pkg.cfssl.org/ 在其中一台节点（一般是master1）上执行如下指令直接进行安装 1234curl -s -L -o /usr/local/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64curl -s -L -o /usr/local/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64curl -s -L -o /usr/local/bin/cfssl-certinfo https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x /usr/local/bin/cfssl* 如果环境无法联网，则到官网下载最新版本的cfssl_linux-amd64、cfssljson_linux-amd64、cfssl-certinfo_linux-amd64并上传到其中一台节点的/root目录下（一般是master1），并执行如下指令安装cfssl 1234mv cfssl_linux-amd64 /usr/local/bin/cfsslmv cfssljson_linux-amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfochmod +x /usr/local/bin/cfssl* 部署etcd数据库集群 etcd 是基于 Raft 的分布式 key-value 存储系统，由 CoreOS 开发，常用于服务发现、共享配置以及并发控制（如 leader 选举、分布式锁等）。kubernetes 使用 etcd 存储所有运行数据。 Github地址：https://github.com/etcd-io/etcd官网地址：https://etcd.io/ 使用cfssl为etcd生成自签证书在安装了cfssl工具的节点上执行如下指令为etcd创建对应的ca机构并生成自签证书 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#创建工作目录mkdir /root/etcd-cert &amp;&amp; cd /root/etcd-cert#创建ca-csr.json文件cat &gt; ca-csr.json &lt;&lt; EOF&#123; "CN": "etcd CA", "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "ShenZhen", "ST": "ShenZhen" &#125; ]&#125;EOF#创建ca-config.json文件#配置证书生成策略，让CA软件知道颁发什么样的证书#ca-config.json：定义多个profiles,分别指定不同的过期时间，使用场景等参数，这里我们只定义了etcd一个profile#signing：表示该证书可用于签名其它证书#server auth：表示client可以使用该CA对server提供的证书进行验证#client auth：表示server可以用该CA对client提供的证书进行验证cat &gt; ca-config.json &lt;&lt; EOF&#123; "signing": &#123; "default": &#123; "expiry": "876000h" &#125;, "profiles": &#123; "etcd": &#123; "expiry": "876000h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] &#125; &#125; &#125;&#125;EOF#创建etcd-csr.json文件#注：etcd-csr.json中的hosts字段需要所把有etcd集群节点的IP地址都添加进去cat &gt; etcd-csr.json &lt;&lt; EOF&#123; "CN": "etcd", "hosts": [ "10.211.55.4", "10.211.55.5", "10.211.55.6" ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "ShenZhen", "ST": "ShenZhen" &#125; ]&#125;EOF#生成CA证书和私钥cfssl gencert -initca ca-csr.json | cfssljson -bare ca -#为etcd生成自签证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=etcd etcd-csr.json | cfssljson -bare etcd 部署etcd3.4之前版本访问https://github.com/etcd-io/etcd/releases下载etcd3.4之前版本的二进制包（本文以3.3.18为例），并上传到其中一台etcd节点的/root目录下，然后执行如下指令解压并创建etcd相关目录和配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#解压到/optcd /root/tar zxf etcd-v3.3.18-linux-amd64.tar.gz -C /opt/mv /opt/etcd-v3.3.18-linux-amd64/ /opt/etcd#创建二进制文件存放目录、配置文件存放目录、证书存放目录mkdir /opt/etcd/binmkdir /opt/etcd/cfgmkdir /opt/etcd/ssl#拷贝二进制文件到bin目录下cp -a /opt/etcd/etcd* /opt/etcd/bin/#拷贝上一步生成的自签证书到ssl目录下cp -a /root/etcd-cert/&#123;ca,etcd,etcd-key&#125;.pem /opt/etcd/ssl/#创建etcd集群配置文件，标注部分按实际情况进行修改cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]#自定义此etcd节点的名称，集群内唯一ETCD_NAME="etcd-1"#定义etcd数据存放目录ETCD_DATA_DIR="/var/lib/etcd/default.etcd"#定义本机和成员之间通信的地址ETCD_LISTEN_PEER_URLS="https://10.211.55.4:2380" #定义etcd对外提供服务的地址ETCD_LISTEN_CLIENT_URLS="https://10.211.55.4:2379"#[Clustering]#定义该节点成员对等URL地址，且会通告集群的其余成员节点ETCD_INITIAL_ADVERTISE_PEER_URLS="https://10.211.55.4:2380"#此成员的客户端URL列表，用于通告群集的其余部分ETCD_ADVERTISE_CLIENT_URLS="https://10.211.55.4:2379"#集群中所有节点的信息ETCD_INITIAL_CLUSTER="etcd-1=https://10.211.55.4:2380,etcd-2=https://10.211.55.5:2380,etcd-3=https://10.211.55.6:2380"#创建集群的token，这个值每个集群保持唯一ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"#设置new为初始静态或DNS引导期间出现的所有成员。如果将此选项设置为existing，则etcd将尝试加入现有群集ETCD_INITIAL_CLUSTER_STATE="new"EOF#创建etcd的systemd unit文件vim /usr/lib/systemd/system/etcd.service[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \ --name=$&#123;ETCD_NAME&#125; \ --data-dir=$&#123;ETCD_DATA_DIR&#125; \ --listen-peer-urls=$&#123;ETCD_LISTEN_PEER_URLS&#125; \ --listen-client-urls=$&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http://127.0.0.1:2379 \ --advertise-client-urls=$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \ --initial-advertise-peer-urls=$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \ --initial-cluster=$&#123;ETCD_INITIAL_CLUSTER&#125; \ --initial-cluster-token=$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \ --initial-cluster-state=new \ --cert-file=/opt/etcd/ssl/etcd.pem \ --key-file=/opt/etcd/ssl/etcd-key.pem \ --peer-cert-file=/opt/etcd/ssl/etcd.pem \ --peer-key-file=/opt/etcd/ssl/etcd-key.pem \ --trusted-ca-file=/opt/etcd/ssl/ca.pem \ --peer-trusted-ca-file=/opt/etcd/ssl/ca.pemRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target 将etcd目录和systemd unit文件拷贝到其余etcd集群节点上，并修改etcd配置文件中的名称和IP地址 12345678910111213141516171819202122232425262728#拷贝etcd目录和etcd.service到其余etcd集群节点上scp -r /opt/etcd/ k8s-node1:/opt/scp -r /usr/lib/systemd/system/etcd.service k8s-node1:/usr/lib/systemd/system/#修改etcd集群配置文件，标注部分按实际情况进行修改vim /opt/etcd/cfg/etcd.conf#[Member]#自定义此etcd节点的名称，集群内唯一ETCD_NAME="etcd-1"#定义etcd数据存放目录ETCD_DATA_DIR="/var/lib/etcd/default.etcd"#定义本机和成员之间通信的地址ETCD_LISTEN_PEER_URLS="https://10.211.55.4:2380" #定义etcd对外提供服务的地址ETCD_LISTEN_CLIENT_URLS="https://10.211.55.4:2379"#[Clustering]#定义该节点成员对等URL地址，且会通告集群的其余成员节点ETCD_INITIAL_ADVERTISE_PEER_URLS="https://10.211.55.4:2380"#此成员的客户端URL列表，用于通告群集的其余部分ETCD_ADVERTISE_CLIENT_URLS="https://10.211.55.4:2379"#集群中所有节点的信息ETCD_INITIAL_CLUSTER="etcd-1=https://10.211.55.4:2380,etcd-2=https://10.211.55.5:2380,etcd-3=https://10.211.55.6:2380"#创建集群的token，这个值每个集群保持唯一ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"#设置new为初始静态或DNS引导期间出现的所有成员。如果将此选项设置为existing，则etcd将尝试加入现有群集ETCD_INITIAL_CLUSTER_STATE="new"EOF 在所有etcd集群节点上启动etcd并设置开机自启 123456systemctl daemon-reloadsystemctl enable etcdsystemctl start etcd#注：在第一台节点上执行start后会一直卡着无法返回命令提示符，这是因为在等待其他节点准备就绪，继续启动其余节点即可systemctl status etcd 在任意etcd节点上执行如下指令查看集群状态，若所有节点均处于healthy状态则表示etcd集群部署成功 1/opt/etcd/bin/etcdctl --ca-file=/opt/etcd/ssl/ca.pem --cert-file=/opt/etcd/ssl/etcd.pem --key-file=/opt/etcd/ssl/etcd-key.pem --endpoints="https://10.211.55.4:2379,https://10.211.55.5:2379,https://10.211.55.6:2379" cluster-health 部署etcd3.4版本访问https://github.com/etcd-io/etcd/releases下载etcd3.4版本的二进制包（本文以3.4.3为例），并上传到其中一台etcd节点的/root目录下，然后执行如下指令解压并创建etcd相关目录和配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#解压到/optcd /root/tar zxf etcd-v3.4.3-linux-amd64.tar.gz -C /opt/mv /opt/etcd-v3.4.3-linux-amd64/ /opt/etcd#创建二进制文件存放目录、配置文件存放目录、证书存放目录mkdir /opt/etcd/binmkdir /opt/etcd/cfgmkdir /opt/etcd/ssl#拷贝二进制文件到bin目录下cp -a /opt/etcd/etcd* /opt/etcd/bin/#拷贝上一步生成的自签证书到ssl目录下cp -a /root/etcd-cert/&#123;ca,etcd,etcd-key&#125;.pem /opt/etcd/ssl/#创建etcd集群配置文件，标注部分按实际情况进行修改cat &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; EOF#[Member]#自定义此etcd节点的名称，集群内唯一ETCD_NAME="etcd-1"#定义etcd数据存放目录ETCD_DATA_DIR="/var/lib/etcd/default.etcd"#定义本机和成员之间通信的地址ETCD_LISTEN_PEER_URLS="https://10.211.55.4:2380" #定义etcd对外提供服务的地址ETCD_LISTEN_CLIENT_URLS="https://10.211.55.4:2379,http://127.0.0.1:2379"#[Clustering]#定义该节点成员对等URL地址，且会通告集群的其余成员节点ETCD_INITIAL_ADVERTISE_PEER_URLS="https://10.211.55.4:2380"#此成员的客户端URL列表，用于通告群集的其余部分ETCD_ADVERTISE_CLIENT_URLS="https://10.211.55.4:2379"#集群中所有节点的信息ETCD_INITIAL_CLUSTER="etcd-1=https://10.211.55.4:2380,etcd-2=https://10.211.55.5:2380,etcd-3=https://10.211.55.6:2380"#创建集群的token，这个值每个集群保持唯一ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"#设置new为初始静态或DNS引导期间出现的所有成员。如果将此选项设置为existing，则etcd将尝试加入现有群集ETCD_INITIAL_CLUSTER_STATE="new"#flannel操作etcd使用的是v2的API，而kubernetes操作etcd使用的v3的API，在最新版ETCD3.4版本中默认关闭v2版本，所以为了兼容flannel，要设置开启v2的APIETCD_ENABLE_V2="true"EOF#创建etcd的systemd unit文件vim /usr/lib/systemd/system/etcd.service[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \ --cert-file=/opt/etcd/ssl/etcd.pem \ --key-file=/opt/etcd/ssl/etcd-key.pem \ --peer-cert-file=/opt/etcd/ssl/etcd.pem \ --peer-key-file=/opt/etcd/ssl/etcd-key.pem \ --trusted-ca-file=/opt/etcd/ssl/ca.pem \ --peer-trusted-ca-file=/opt/etcd/ssl/ca.pemRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target 将etcd目录和systemd unit文件拷贝到其余etcd集群节点上，并修改etcd配置文件中的名称和IP地址 123456789101112131415161718192021222324252627282930#拷贝etcd目录和etcd.service到其余etcd集群节点上scp -r /opt/etcd/ k8s-node1:/opt/scp -r /usr/lib/systemd/system/etcd.service k8s-node1:/usr/lib/systemd/system/#修改etcd集群配置文件vim /opt/etcd/cfg/etcd.conf#[Member]#自定义此etcd节点的名称，集群内唯一ETCD_NAME="etcd-1"#定义etcd数据存放目录ETCD_DATA_DIR="/var/lib/etcd/default.etcd"#定义本机和成员之间通信的地址ETCD_LISTEN_PEER_URLS="https://10.211.55.4:2380" #定义etcd对外提供服务的地址ETCD_LISTEN_CLIENT_URLS="https://10.211.55.4:2379,http://127.0.0.1:2379"#[Clustering]#定义该节点成员对等URL地址，且会通告集群的其余成员节点ETCD_INITIAL_ADVERTISE_PEER_URLS="https://10.211.55.4:2380"#此成员的客户端URL列表，用于通告群集的其余部分ETCD_ADVERTISE_CLIENT_URLS="https://10.211.55.4:2379"#集群中所有节点的信息ETCD_INITIAL_CLUSTER="etcd-1=https://10.211.55.4:2380,etcd-2=https://10.211.55.5:2380,etcd-3=https://10.211.55.6:2380"#创建集群的token，这个值每个集群保持唯一ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"#设置new为初始静态或DNS引导期间出现的所有成员。如果将此选项设置为existing，则etcd将尝试加入现有群集ETCD_INITIAL_CLUSTER_STATE="new"#flannel操作etcd使用的是v2的API，而kubernetes操作etcd使用的v3的API，在最新版ETCD3.4版本中默认关闭v2版本，所以为了兼容flannel，要设置开启v2的APIETCD_ENABLE_V2="true"EOF 在所有etcd集群节点上设置etcd开机自启并启动etcd 123456systemctl daemon-reloadsystemctl enable etcdsystemctl start etcd#注：在第一台节点上执行start后会一直卡着无法返回命令提示符，这是因为在等待其他节点准备就绪，继续启动其余节点即可systemctl status etcd 在任意etcd节点上执行如下指令查看集群状态，若所有节点均处于healthy状态则表示etcd集群部署成功 1/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/etcd.pem --key=/opt/etcd/ssl/etcd-key.pem --endpoints="https://10.211.55.4:2379,https://10.211.55.5:2379,https://10.211.55.6:2379" endpoint health 卸载etcd若安装失败需要卸载重新安装，在所有etcd节点上执行如下指令即可: 12345systemctl stop etcdsystemctl disable etcdrm -rf /opt/etcd/rm -rf /usr/lib/systemd/system/etcd.servicerm -rf /var/lib/etcd/ 部署Master组件 使用cfssl为apiserver和kube-proxy生成自签证书在安装了cfssl工具的节点上执行如下指令为apiserver和kube-proxy创建对应的ca机构并生成自签证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#创建工作目录mkdir /root/k8s-cert &amp;&amp; cd /root/k8s-cert#配置ca-csr.jsoncat &gt; ca-csr.json &lt;&lt; EOF&#123; "CN": "kubernetes", "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "ShenZhen", "ST": "ShenZhen", "O": "k8s", "OU": "System" &#125; ]&#125;EOF#创建ca-config.json文件#配置证书生成策略，让CA软件知道颁发什么样的证书#ca-config.json：定义多个profiles,分别指定不同的过期时间，使用场景等参数，这里我们只定义了etcd一个profile#signing：表示该证书可用于签名其它证书#server auth：表示client可以使用该CA对server提供的证书进行验证#client auth：表示server可以用该CA对client提供的证书进行验证cat &gt; ca-config.json &lt;&lt; EOF&#123; "signing": &#123; "default": &#123; "expiry": "876000h" &#125;, "profiles": &#123; "kubernetes": &#123; "expiry": "876000h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] &#125; &#125; &#125;&#125;EOF#创建apiserver-csr.json文件#注：hosts字段需要把所有master节点、负载均衡节点的IP地址和VIP地址，还有规划的service-cluster-ip-range（在kube-apiserver.conf和kube-controller-manager.conf中配置）的第一个IP地址（本例中为10.0.0.1）都添加进去，其中的127.0.0.1和kubernetes.*部分不要修改cat &gt; apiserver-csr.json &lt;&lt; EOF&#123; "CN": "kubernetes", "hosts": [ "10.0.0.1", "127.0.0.1", "kubernetes", "kubernetes.default", "kubernetes.default.svc", "kubernetes.default.svc.cluster", "kubernetes.default.svc.cluster.local", "10.211.55.4", "10.211.55.5", "10.211.55.6", "10.211.55.7", "10.211.55.10" ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "ShenZhen", "ST": "ShenZhen", "O": "k8s", "OU": "System" &#125; ]&#125;EOF#创建kube-proxy-csr.json文件cat &gt; kube-proxy-csr.json &lt;&lt; EOF&#123; "CN": "system:kube-proxy", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "ShenZhen", "ST": "ShenZhen", "O": "k8s", "OU": "System" &#125; ]&#125;EOF#生成CA证书和私钥cfssl gencert -initca ca-csr.json | cfssljson -bare ca -#为apiserver生成自签证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes apiserver-csr.json | cfssljson -bare apiserver#为kube-proxy生成自签证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 部署apiserver、controller-manager和scheduler二进制包下载地址：https://github.com/kubernetes/kubernetes/releases 在每个release版本的CHANGELOG中有每个版本的二进制包下载列表，下载对应平台下的Server Binaries，上传到其中一台Master节点的/root目录下（本文以1.16.4为例） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#创建kubernetes工作目录mkdir /opt/kubernetesmkdir /opt/kubernetes/binmkdir /opt/kubernetes/cfgmkdir /opt/kubernetes/sslmkdir /opt/kubernetes/logs#解压master binaries并拷贝所需的二进制文件到/opt/kubernetes/bin目录下cd /root/tar zxf kubernetes-server-linux-amd64.tar.gzcp -a /root/kubernetes/server/bin/kube-apiserver /opt/kubernetes/bin/cp -a /root/kubernetes/server/bin/kube-controller-manager /opt/kubernetes/bin/cp -a /root/kubernetes/server/bin/kube-scheduler /opt/kubernetes/bin/cp -a /root/kubernetes/server/bin/kubectl /usr/local/bin/#拷贝自签证书到/opt/kubernetes/ssl目录下cp -a /root/k8s-cert/&#123;ca,ca-key,apiserver,apiserver-key&#125;.pem /opt/kubernetes/ssl/#创建kube-apiserver配置文件，标注部分按实际情况进行修改vim /opt/kubernetes/cfg/kube-apiserver.confKUBE_APISERVER_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--etcd-servers=https://10.211.55.4:2379,https://10.211.55.5:2379,https://10.211.55.6:2379 \--bind-address=10.211.55.4 \--secure-port=6443 \--advertise-address=10.211.55.4 \--allow-privileged=true \--service-cluster-ip-range=10.0.0.0/24 \--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \--authorization-mode=RBAC,Node \--enable-bootstrap-token-auth=true \--token-auth-file=/opt/kubernetes/cfg/token.csv \--service-node-port-range=30000-32767 \--kubelet-client-certificate=/opt/kubernetes/ssl/apiserver.pem \--kubelet-client-key=/opt/kubernetes/ssl/apiserver-key.pem \--tls-cert-file=/opt/kubernetes/ssl/apiserver.pem \--tls-private-key-file=/opt/kubernetes/ssl/apiserver-key.pem \--client-ca-file=/opt/kubernetes/ssl/ca.pem \--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \--etcd-cafile=/opt/etcd/ssl/ca.pem \--etcd-certfile=/opt/etcd/ssl/etcd.pem \--etcd-keyfile=/opt/etcd/ssl/etcd-key.pem \--audit-log-maxage=30 \--audit-log-maxbackup=3 \--audit-log-maxsize=100 \--audit-log-path=/opt/kubernetes/logs/k8s-audit.log" –logtostderr：日志是否输出到标准错误输出 –v=2：日志级别0-8，数字越大，日志越详细 –log-dir：设置日志存放目录 –etcd-servers：指定etcd服务的URL –bind-address：apiserver监听地址 –secure-port：apiserver监听端口，默认为6443 –advertise-address：通告地址，让其他节点通过此IP来连接apiserver –allow-privileged：开启容器的privileged权限 –service-cluster-ip-range：Kubernetes集群中Service的虚拟IP地址范围，以CIDR格式表示，例如169.169.0.0/16，该IP范围不能与部署机器的IP地址有重合 –enable-admission-plugins：Kubernetes集群的准入控制设置，各控制模块以插件的形式依次生效。 –authorization-mode：授权模式 –enable-bootstrap-token-auth：启用bootstrap token认证 –service-node-port-range：Kubernetes集群中Service可使用的端口号范围，默认值为30000～32767 –kubelet-client-certificate、–kubelet-client-key：连接kubelet使用的证书和私钥 –tls-cert-file、–tls-private-key-file、–client-ca-file、–service-account-key-file：apiserver启用https所用的证书和私钥 –etcd-cafile、–etcd-certfile、–etcd-keyfile：连接etcd所使用的证书 –audit-log-maxage、–audit-log-maxbackup、–audit-log-maxsize、–audit-log-path：日志轮转、日志路径 12345678910111213141516#创建kube-controller-manage配置文件，标注部分按实际情况进行修改vim /opt/kubernetes/cfg/kube-controller-manager.confKUBE_CONTROLLER_MANAGER_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--leader-elect=true \--master=127.0.0.1:8080 \--address=127.0.0.1 \--allocate-node-cidrs=true \--cluster-cidr=10.244.0.0/16 \--service-cluster-ip-range=10.0.0.0/24 \--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \--root-ca-file=/opt/kubernetes/ssl/ca.pem \--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \--experimental-cluster-signing-duration=876000h0m0s" –leader-elect：启用自动选举 –master：连接apiserver的IP，127.0.0.1:8080是apiserver默认监听的，用于让其他组件通过此地址连接 –address：配置controller-manager监听地址，不需要对外 –allocate-node-cidrs：允许安装CNI插件，自动分配IP –cluster-cidr：集群pod的IP段，要与与CNI插件的IP段一致 –service-cluster-ip-range：service cluster IP段，与apiserver中配置保持一致 –cluster-signing-cert-file、–cluster-signing-key-file：用于集群签名的ca证书和私钥 –root-ca-file、–service-account-private-key-file：签署service account的证书和私钥 –experimental-cluster-signing-duration：签发证书的有效期 12345678#创建kube-scheduler配置文件，标注部分按实际情况进行修改vim /opt/kubernetes/cfg/kube-scheduler.confKUBE_SCHEDULER_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--leader-elect \--master=127.0.0.1:8080 \--address=127.0.0.1" –leader-elect：启用自动选举 123456789101112131415161718192021222324252627282930313233343536373839404142434445#创建kube-apiserver的systemd unit文件vim /usr/lib/systemd/system/kube-apiserver.service[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.confExecStart=/opt/kubernetes/bin/kube-apiserver $KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target#创建kube-controller-manager的systemd unit文件vim /usr/lib/systemd/system/kube-controller-manager.service[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.confExecStart=/opt/kubernetes/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target#创建kube-scheduler的systemd unit文件vim /usr/lib/systemd/system/kube-scheduler.service[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.confExecStart=/opt/kubernetes/bin/kube-scheduler $KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target 随机生成一个32位字符串，用以创建token.csv文件 123token=`head -c 16 /dev/urandom | od -An -t x | tr -d ' '`echo "$token,kubelet-bootstrap,10001,'system:node-bootstrapper'" &gt; /opt/kubernetes/cfg/token.csv#token.csv文件的格式为：(第一列)随机字符串，(第二列)用户名，(第三列)UID，(第四列)用户组 注：此处apiserver配置的token（32位随机字符串）必须要与后面node节点bootstrap.kubeconfig配置里的token一致 设置api-server、controller-manager、scheduler开机自启并启动 12345678910systemctl daemon-reloadsystemctl enable kube-apiserversystemctl enable kube-controller-managersystemctl enable kube-schedulersystemctl start kube-apiserversystemctl start kube-controller-managersystemctl start kube-schedulersystemctl status kube-apiserversystemctl status kube-controller-managersystemctl status kube-scheduler 在其中一台master上执行如下指令为kubectl TLS Bootstrapping授权 1kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap 此时你可以通过执行kubectl get cs获取k8s的各服务端组件状态看是否Healthy，但是如果你安装的是1.16版本，你会发现你的输出内容有一些变化，类似如下： 1234567# kubectl get csNAME AGEcontroller-manager &lt;unknown&gt;scheduler &lt;unknown&gt;etcd-0 &lt;unknown&gt;etcd-2 &lt;unknown&gt;etcd-1 &lt;unknown&gt; 起初可能会以为集群部署有问题，但是通过kubectl get cs -o yaml发现status、message等信息都有，只是没有打印出来。所以在网上搜索相关文章，最后在这里找到了原因，原来这是1.16的bug！！！坐等官方修复吧，当然针对此问题，大佬也给出了临时解决办法，参考下方： 1kubectl get cs -o=go-template='&#123;&#123;printf "|NAME|STATUS|MESSAGE|\n"&#125;&#125;&#123;&#123;range .items&#125;&#125;&#123;&#123;$name := .metadata.name&#125;&#125;&#123;&#123;range .conditions&#125;&#125;&#123;&#123;printf "|%s|%s|%s|\n" $name .status .message&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;' 部署Node组件 安装Docker二进制包下载地址：https://download.docker.com/linux/static/stable/ 到对应平台的目录下载所需版本的Docker二进制包，并上传到Node节点的/root目录下（本文以x86平台下的Docker18.09.9为例） 123456789101112131415161718192021222324252627282930313233343536373839#解压并拷贝二进制文件到对应目录下cd /root/tar zxf docker-18.09.9.tgzcp -a docker/* /usr/bin/chmod 755 /usr/bin/&#123;containerd,containerd-shim,ctr,docker,dockerd,docker-init,docker-proxy,runc&#125;#创建docker的systemd unit文件vim /etc/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.service containerd.serviceWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDTimeoutSec=0RestartSec=2Restart=alwaysStartLimitBurst=3StartLimitInterval=60sLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTasksMax=infinityDelegate=yesKillMode=process[Install]WantedBy=multi-user.target#设置docker开机自启并启动systemctl daemon-reloadsystemctl start dockersystemctl enable dockersystemctl status docker 部署kubelet和kube-proxy二进制包下载地址：https://github.com/kubernetes/kubernetes/releases 在每个release版本的CHANGELOG中有每个版本的二进制包下载列表，下载对应平台下的Node Binaries，上传到Node节点的/root目录下（本文以1.16.4为例） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#创建kubernetes工作目录mkdir /opt/kubernetesmkdir /opt/kubernetes/binmkdir /opt/kubernetes/cfgmkdir /opt/kubernetes/sslmkdir /opt/kubernetes/logs#解压node binaries并拷贝所需的二进制文件到/opt/kubernetes/bin目录下cd /root/tar zxf kubernetes-node-linux-amd64.tar.gzcp -a /root/kubernetes/node/bin/kubelet /opt/kubernetes/bin/cp -a /root/kubernetes/node/bin/kube-proxy /opt/kubernetes/bin/#创建kubelet.conf配置文件，标注部分按实际情况进行修改#--hostname-override：当前节点注册到k8s显示的名称，集群内唯一#--network-plugin：启用网络插件vim /opt/kubernetes/cfg/kubelet.confKUBELET_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--hostname-override=k8s-node1 \--network-plugin=cni \--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \--config=/opt/kubernetes/cfg/kubelet-config.yml \--cert-dir=/opt/kubernetes/ssl"#创建bootstrap.kubeconfig配置文件#server字段设置master节点的IP地址和端口#token字段需要与master节点apiserver的token.csv文件中指定的token值一致vim /opt/kubernetes/cfg/bootstrap.kubeconfigapiVersion: v1clusters:- cluster: certificate-authority: /opt/kubernetes/ssl/ca.pem server: https://10.211.55.4:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kubelet-bootstrap name: defaultcurrent-context: defaultkind: Configpreferences: &#123;&#125;users:- name: kubelet-bootstrap user: token: 65cc0bcbe77f4877f288e5604529f384#创建kubelet-config.yml配置文件，vim /opt/kubernetes/cfg/kubelet-config.ymlkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS:- 10.0.0.2clusterDomain: cluster.local failSwapOn: falseauthentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /opt/kubernetes/ssl/ca.pem authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110#创建kube-proxy.conf配置文件vim /opt/kubernetes/cfg/kube-proxy.confKUBE_PROXY_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--config=/opt/kubernetes/cfg/kube-proxy-config.yml"#创建kube-proxy.kubeconfig配置文件#server字段设置master节点的IP地址和端口vim /opt/kubernetes/cfg/kube-proxy.kubeconfigapiVersion: v1clusters:- cluster: certificate-authority: /opt/kubernetes/ssl/ca.pem server: https://10.211.55.4:6443 name: kubernetescontexts:- context: cluster: kubernetes user: kube-proxy name: defaultcurrent-context: defaultkind: Configpreferences: &#123;&#125;users:- name: kube-proxy user: client-certificate: /opt/kubernetes/ssl/kube-proxy.pem client-key: /opt/kubernetes/ssl/kube-proxy-key.pem#创建kube-proxy-config.yml配置文件#hostnameOverride字段配置当前节点注册到k8s显示的名称，集群内唯一#mode字段配置kube-proxy使用的模式，iptables or ipvsvim /opt/kubernetes/cfg/kube-proxy-config.ymlkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1address: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection: kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfighostnameOverride: k8s-node1clusterCIDR: 10.0.0.0/24mode: ipvsipvs: scheduler: "rr"iptables: masqueradeAll: true#创建kubelet的systemd unit文件vim /usr/lib/systemd/system/kubelet.service[Unit]Description=Kubernetes KubeletAfter=docker.serviceBefore=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubelet.confExecStart=/opt/kubernetes/bin/kubelet $KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target#创建kube-proxy的systemd unit文件vim /usr/lib/systemd/system/kube-proxy.service[Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.confExecStart=/opt/kubernetes/bin/kube-proxy $KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target 从上面安装了cfssl工具的主机上拷贝ca证书和kube-proxy的自签证书和私钥到Node节点的/opt/kubernetes/ssl目录下 12cd /root/k8s-cert/scp -r ca.pem kube-proxy.pem kube-proxy-key.pem k8s-node1:/opt/kubernetes/ssl/ 设置kubelet和kube-proxy开机自启并启动 1234567systemctl daemon-reloadsystemctl enable kubeletsystemctl enable kube-proxysystemctl start kubeletsystemctl start kube-proxysystemctl status kubeletsystemctl status kube-proxy 允许给Node颁发证书当kubelet和kube-proxy成功启动后，此时在master上执行kubectl get csr可以看到有新的节点请求颁发证书(CONDITION字段处于Pending状态)，执行如下指令允许给Node颁发证书 1kubectl certificate approve node-csr-vCjAOsDYkXe4Af4gR-NBikSm4yIG00XV5zLjBZgzmQk 补充知识点 若kubectl或kube-proxy配置文件中的hostname-override配置参数漏修改，导致授权后master无法正常获取到Node节点信息，除了修改kubelet.conf的–hostname-override配置和kube-proxy-config.yml的hostnameOverride配置外，还需要将kubelet.kubeconfig文件（这个文件是master认证后客户端自动生成的）删除，才可重新申请授权，否则报错信息类似如下： kubelet_node_status.go:94] Unable to register node “k8s-node2” with API server: nodes “k8s-node2” is forbidden: node “k8s-node1” is not allowed to modify node “k8s-node2” TLS Bootstrapping 机制流程（Kubelet） 如何删除一个Node节点并重新接入集群 在Master节点操作 12kubectl drain 10.211.55.6 --delete-local-datakubectl delete node 10.211.55.6 在Node节点操作 1234rm -rf /opt/kubernetes/cfg/kubelet.kubeconfigrm -rf /opt/kubernetes/ssl/kubelet*systemctl restart kubeletsystemctl restart kube-proxy 在Master节点重新授权 12kubectl get csrkubectl certificate approve xxxx 部署CNI网络二进制下载地址：https://github.com/containernetworking/plugins/releases 下载所需平台的最新版本的CNI二进制包并上传到node节点的/root目录下 1234567#创建cni的工作目录mkdir -p /opt/cni/binmkdir -p /etc/cni/net.d#解压到对应目录下cd /root/tar zxf cni-plugins-linux-amd64-v0.8.3.tgz -C /opt/cni/bin/ 确保kubelet启用CNI 12cat /opt/kubernetes/cfg/kubelet.conf |grep network-plugin--network-plugin=cni \ 在任意一台master节点执行如下指令下载网络yaml文件，k8s支持多种网络类型，本文安装的是flannel网络，更多网络类型可参考https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network 12cd /root/wget https://raw.githubusercontent.com/coreos/flannel/2140ac876ef134e0ed5af15c65e414cf26827915/Documentation/kube-flannel.yml 根据实际环境情况修改kube-flannel.yml文件，比如Network、Backend、hostNetwork配置等等，修改完成后进行安装 12cd /root/kubectl apply -f kube-flannel.yml 查看flannel的pod创建情况，等待到所有node节点上的flannel pod都处于running状态后表示cni部署完成 1kubectl get pods -n kube-system -o wide 授权apiserver访问kubelet为提供安全性，kubelet禁止匿名访问，必须授权才可以。一个常见的表现就是无法通过kubectl logs查看pod的日志，错误输出类似如下： Error from server (Forbidden): Forbidden (user=kubernetes, verb=get, resource=nodes, subresource=proxy) ( pods/log kube-flannel-ds-amd64-cdmcd) 在任意一台master节点上执行如下指令进行授权 12345678910111213141516171819202122232425262728293031323334353637383940#创建apiserver-to-kubelet-rbac.yaml文件cat &gt; /root/apiserver-to-kubelet-rbac.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: "true" labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubeletrules: - apiGroups: - "" resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics - pods/log verbs: - "*"---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: system:kube-apiserver namespace: ""roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubeletsubjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetesEOFkubectl apply -f /root/apiserver-to-kubelet-rbac.yaml 环境测试验证在任意一个master节点上执行如下指令创建一个nginx pod并暴露端口测试是否可以从外部正常访问 12345678910#创建nginx deploymentkubectl create deployment web --image=nginx#暴露端口kubectl expose deployment web --port=80 --type=NodePort#查看对应的访问端口kubectl get serviceNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEweb NodePort 10.0.0.200 &lt;none&gt; 80:30174/TCP 4s 浏览器访问：http://&lt;Node_IP&gt;:30174若能正常返回nginx欢迎页面，则表示环境一切正常。 部署Web UI和DNS Web UIGithub地址：https://github.com/kubernetes/dashboard官方地址：https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/ 在任意一台master节点上下载Web UI的yaml文件到/root目录下 12cd /root/wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta6/aio/deploy/recommended.yaml 编辑recommended.yaml文件，找到kubernetes-dashboard这个Service的部分，设置其type为NodePort，nodePort为30001（可自定义） 12345678910111213141516171819......kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30001 selector: k8s-app: kubernetes-dashboard...... 修改完成后，执行如下指令开始部署Web UI 123456789101112kubectl apply -f /root/recommended.yaml#查看kubernetes-dashboard的pod，确认pod的STATUS均为running再继续下面的步骤kubectl get pods -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-76585494d8-v4gd9 1/1 Running 0 63skubernetes-dashboard-b65488c4-pwkc2 1/1 Running 0 63s#查看对应的servicekubectl get service -n kubernetes-dashboardNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes-dashboard NodePort 10.0.0.122 &lt;none&gt; 443:30001/TCP 2m45s 创建service account并绑定默认cluster-admin管理员集群角色 123456789101112131415161718192021222324#创建授权的yaml文件cat &gt; /root/dashboard-adminuser.yaml &lt;&lt; EOFapiVersion: v1kind: ServiceAccountmetadata: name: admin-user namespace: kubernetes-dashboard---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: admin-userroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: admin-user namespace: kubernetes-dashboardEOF#执行授权kubectl apply -f /root/dashboard-adminuser.yaml 获取token 1kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '&#123;print $1&#125;') 浏览器访问地址：https://&lt;NODE_IP&gt;:30001 使用上面输出的token登录dashboard，注意协议一定要用https 注：若打开dashboard出现如下页面，没有”继续前往x.x.x.x（不安全）”的选项，则请参考下面的步骤进行处理 出现这个问题主要是因为之前版本部署的时候默认命名空间是kube-system，而新版的是kubernetes-dashboard导致，解决办法如下： 1.在刚执行指令部署Web UI的master节点上执行如下指令删除默认的secret，并用自签证书创建新的secret（注意修改自签证书的路径是否与实际环境一致） 12kubectl delete secret kubernetes-dashboard-certs -n kubernetes-dashboardkubectl create secret generic kubernetes-dashboard-certs --from-file=/opt/kubernetes/ssl/apiserver-key.pem --from-file=/opt/kubernetes/ssl/apiserver.pem -n kubernetes-dashboard 2.修改/root/recommended.yaml文件，在args下面增加证书两行（搜索auto-generate-certificates即可跳转到对应位置） 12345args: # PLATFORM-SPECIFIC ARGS HERE - --auto-generate-certificates - --tls-key-file=apiserver-key.pem - --tls-cert-file=apiserver.pem 3.重新应用recommended.yaml 1kubectl apply -f /root/recommended.yaml 4.重新访问https://&lt;NODE_IP&gt;:30001，注意协议一定要用https DNSGithub地址：https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns/coredns 部署DNS主要是为了给k8s的Service提供DNS解析服务，使得程序可以通过service的名称进行访问 DNS服务监视Kubernetes API，为每一个Service创建DNS记录用于域名解析。 ClusterIP A记录格式：&lt;service-name>.&lt;namespace-name>.svc.cluster.local，示例：my-svc.my-namespace.svc.cluster.local 使用kubeadm方式部署的k8s会自动安装CoreDNS，二进制部署方式则需要自行安装 从Github地址上下载coredns.yaml.base文件到任意master节点的/root/目录下，并重命名为coredns.yaml，然后参考下方标注修改其中的部分参数 __MACHINE_GENERATED_WARNING__替换为This is a file generated from the base underscore template file: coredns.yaml.base __PILLAR__DNS__DOMAIN__替换为cluster.local,一般不修改，若要修改记得要与node节点上kubelet-config.yml文件中的clusterDomain的值一致，并要调整api-server证书中的hosts字段值并重新生产证书 __PILLAR__DNS__MEMORY__LIMIT__替换为170Mi，此内存限制的值可根据实际环境资源进行调整 __PILLAR__DNS__SERVER__替换为10.0.0.2，此IP地址需要与Node节点上/opt/kubernetes/cfg/kubelet-config.yml文件中配置的clusterDNS字段的IP一致 以下为我替换后最终的文件内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201# This is a file generated from the base underscore template file: coredns.yaml.baseapiVersion: v1kind: ServiceAccountmetadata: name: coredns namespace: kube-system labels: kubernetes.io/cluster-service: "true" addonmanager.kubernetes.io/mode: Reconcile---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: Reconcile name: system:corednsrules:- apiGroups: - "" resources: - endpoints - services - pods - namespaces verbs: - list - watch- apiGroups: - "" resources: - nodes verbs: - get---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: "true" labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: EnsureExists name: system:corednsroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:corednssubjects:- kind: ServiceAccount name: coredns namespace: kube-system---apiVersion: v1kind: ConfigMapmetadata: name: coredns namespace: kube-system labels: addonmanager.kubernetes.io/mode: EnsureExistsdata: Corefile: | .:53 &#123; errors health &#123; lameduck 5s &#125; ready kubernetes cluster.local in-addr.arpa ip6.arpa &#123; pods insecure fallthrough in-addr.arpa ip6.arpa ttl 30 &#125; prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance &#125;---apiVersion: apps/v1kind: Deploymentmetadata: name: coredns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: "true" addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: "CoreDNS"spec: # replicas: not specified here: # 1. In order to make Addon Manager do not reconcile this replicas parameter. # 2. Default is 1. # 3. Will be tuned in real time if DNS horizontal auto-scaling is turned on. strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 selector: matchLabels: k8s-app: kube-dns template: metadata: labels: k8s-app: kube-dns annotations: seccomp.security.alpha.kubernetes.io/pod: 'runtime/default' spec: priorityClassName: system-cluster-critical serviceAccountName: coredns tolerations: - key: "CriticalAddonsOnly" operator: "Exists" nodeSelector: beta.kubernetes.io/os: linux containers: - name: coredns image: k8s.gcr.io/coredns:1.6.5 imagePullPolicy: IfNotPresent resources: limits: memory: 170Mi requests: cpu: 100m memory: 70Mi args: [ "-conf", "/etc/coredns/Corefile" ] volumeMounts: - name: config-volume mountPath: /etc/coredns readOnly: true ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9153 name: metrics protocol: TCP livenessProbe: httpGet: path: /health port: 8080 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 readinessProbe: httpGet: path: /ready port: 8181 scheme: HTTP securityContext: allowPrivilegeEscalation: false capabilities: add: - NET_BIND_SERVICE drop: - all readOnlyRootFilesystem: true dnsPolicy: Default volumes: - name: config-volume configMap: name: coredns items: - key: Corefile path: Corefile---apiVersion: v1kind: Servicemetadata: name: kube-dns namespace: kube-system annotations: prometheus.io/port: "9153" prometheus.io/scrape: "true" labels: k8s-app: kube-dns kubernetes.io/cluster-service: "true" addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: "CoreDNS"spec: selector: k8s-app: kube-dns clusterIP: 10.0.0.2 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP - name: metrics port: 9153 protocol: TCP 执行如下指令进行安装 1234kubectl apply -f /root/coredns.yaml#确认dns相关的pod均为running状态kubectl get pod -n kube-system 测试验证 在任意master节点上执行如下指令创建一个busybox容器，在容器中ping service的名称看是否可以正常解析到IP地址并通信正常，如果可以则说明DNS服务部署成功。 1234567891011121314151617181920212223242526272829303132333435363738cat &gt; /root/bs.yaml &lt;&lt; EOFapiVersion: v1kind: Podmetadata: name: busybox namespace: defaultspec: containers: - image: busybox:1.28.4 command: - sleep - "3600" imagePullPolicy: IfNotPresent name: busybox restartPolicy: AlwaysEOFkubectl apply -f /root/bs.yamlkubectl get pods#待pod处于running状态后运行如下指令进入容器中kubectl exec -ti busybox sh#在容器中执行如下指令若出现类似输出则说明解析正常/ # nslookup kubernetesServer: 10.0.0.2Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.localName: kubernetesAddress 1: 10.0.0.1 kubernetes.default.svc.cluster.local/ # ping kubernetesPING kubernetes (10.0.0.1): 56 data bytes64 bytes from 10.0.0.1: seq=0 ttl=64 time=0.042 ms64 bytes from 10.0.0.1: seq=1 ttl=64 time=0.129 ms^C--- kubernetes ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.042/0.085/0.129 ms 到目前为止一套单Master+2个Node的K8S集群全部搭建完成，但是Master存在单点故障，因此在实际生产环境，我们需要部署多个Master节点，并在Master之前增加一层负载均衡（可通过Nginx、LVS、HAproxy实现），同时为了避免负载均衡存在单点故障，通过Keepalived来实现负载均衡的主备，这样就能保证整个集群不存在单点故障，所有组件均有高可用。 接下来我们将扩容一台Master节点，并通过Nginx和Keepalived实现高可用的负载均衡。 Master高可用 部署Master组件（同Master1一致）注新Master节点的系统初始化操作请参考之前章节进行，此处不再赘述 将Master1上的kubernetes工作目录、etc工作目录下的ssl目录（证书和私钥文件）、Master组件的systemd unit文件和kubectl二进制文件拷贝到新增Master节点的对应目录下 123456scp -r /opt/kubernetes/ k8s-master2:/opt/ssh k8s-master2 rm -rf /opt/kubernetes/logs/*ssh k8s-master2 mkdir /opt/etcdscp -r /opt/etcd/ssl/ k8s-master2:/opt/etcd/scp -r /usr/lib/systemd/system/&#123;kube-apiserver,kube-controller-manager,kube-scheduler&#125;.service k8s-master2:/usr/lib/systemd/system/scp -r /usr/local/bin/kubectl k8s-master2:/usr/local/bin/ 修改新Master节点上apiserver配置文件中的–bind-address和–advertise-address参数为本机IP 12345678910111213141516171819202122232425262728vim /opt/kubernetes/cfg/kube-apiserver.confKUBE_APISERVER_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--etcd-servers=https://10.211.55.4:2379,https://10.211.55.5:2379,https://10.211.55.6:2379 \--bind-address=10.211.55.7 \--secure-port=6443 \--advertise-address=10.211.55.7 \--allow-privileged=true \--service-cluster-ip-range=10.0.0.0/24 \--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \--authorization-mode=RBAC,Node \--enable-bootstrap-token-auth=true \--token-auth-file=/opt/kubernetes/cfg/token.csv \--service-node-port-range=30000-32767 \--kubelet-client-certificate=/opt/kubernetes/ssl/apiserver.pem \--kubelet-client-key=/opt/kubernetes/ssl/apiserver-key.pem \--tls-cert-file=/opt/kubernetes/ssl/apiserver.pem \--tls-private-key-file=/opt/kubernetes/ssl/apiserver-key.pem \--client-ca-file=/opt/kubernetes/ssl/ca.pem \--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \--etcd-cafile=/opt/etcd/ssl/ca.pem \--etcd-certfile=/opt/etcd/ssl/etcd.pem \--etcd-keyfile=/opt/etcd/ssl/etcd-key.pem \--audit-log-maxage=30 \--audit-log-maxbackup=3 \--audit-log-maxsize=100 \--audit-log-path=/opt/kubernetes/logs/k8s-audit.log" 设置api-server、controller-manager、scheduler开机自启并启动 12345678910systemctl daemon-reloadsystemctl enable kube-apiserversystemctl enable kube-controller-managersystemctl enable kube-schedulersystemctl start kube-apiserversystemctl start kube-controller-managersystemctl start kube-schedulersystemctl status kube-apiserversystemctl status kube-controller-managersystemctl status kube-scheduler 在新Master节点上执行如下指令若能正常获取到node节点信息说明新Master节点新增成功 1kubectl get nodes 部署Nginx负载均衡Nginx RPM下载地址：http://nginx.org/packages/rhel/7/x86_64/RPMS/ 下载Nginx安装包并上传到规划部署Nginx的机器的/root目录下，并进行安装 12cd /root/rpm -ivh nginx-1.16.1-1.el7.ngx.x86_64.rpm 配置Nginx配置文件 123456789101112131415161718192021222324252627282930vim /etc/nginx/nginx.conf......events &#123; worker_connections 1024;&#125;#新增如下stream部分#upstream中依此列出所有master节点的IP:Port#listen字段如果Nginx是和apiserver部署在同一台服务器上，需要使用非6443端口（本文使用8443），否则会产生端口冲突，若不是部署在同一台机器上则可以使用默认6443端口stream &#123; log_format main '$remote_addr $upstream_addr - [$time_local] $status $upstream_bytes_sent'; access_log /var/log/nginx/k8s-access.log main; upstream k8s-apiserver &#123; server 10.211.55.4:6443; server 10.211.55.7:6443; &#125; server &#123; listen 8443; proxy_pass k8s-apiserver; &#125;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream;...... 设置Nginx开机自启并启动 123systemctl enable nginxsystemctl start nginxsystemctl status nginx 部署Keepalived主节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253yum install keepalived -ycp -a /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak#配置keepalived配置文件cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id NGINX_MASTER&#125;vrrp_script check_nginx &#123; script "/etc/keepalived/check_nginx.sh"&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 # 接口名称 virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 priority 100 # 优先级，备服务器设置 90 advert_int 1 # 指定VRRP 心跳包通告间隔时间，默认1秒 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.211.55.10/24 &#125; track_script &#123; check_nginx &#125;&#125;EOF#创建Nginx检测脚本vim /etc/keepalived/check_nginx.sh#!/bin/bashcount=$(ps -ef |grep nginx |egrep -cv "grep|$$")if [ "$count" -eq 0 ];then exit 1else exit 0fi#授予Nginx检测脚本可执行权限chmod +x /etc/keepalived/check_nginx.sh 设置Keepalived开机自启并启动 123systemctl enable keepalivedsystemctl start keepalivedsystemctl status keepalived 备节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253yum install keepalived -ycp -a /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak#配置keepalived配置文件cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id NGINX_BACKUP&#125; vrrp_script check_nginx &#123; script "/etc/keepalived/check_nginx.sh"&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 # 接口名称 virtual_router_id 51 # VRRP 路由 ID实例，每个实例是唯一的 priority 90 # 优先级，备服务器设置 90 advert_int 1 # 指定VRRP 心跳包通告间隔时间，默认1秒 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.211.55.10/24 &#125; track_script &#123; check_nginx &#125; &#125;EOF#创建Nginx检测脚本vim /etc/keepalived/check_nginx.sh#!/bin/bashcount=$(ps -ef |grep nginx |egrep -cv "grep|$$")if [ "$count" -eq 0 ];then exit 1else exit 0fi#授予Nginx检测脚本可执行权限chmod +x /etc/keepalived/check_nginx.sh 设置Keepalived开机自启并启动 123systemctl enable keepalivedsystemctl start keepalivedsystemctl status keepalived 修改Node连接VIP修改所有node节点上k8s的bootstrap.kubeconfig、kubelet.kubeconfig和kube-proxy.kubeconfig配置文件中的server字段的IP和Port信息，IP替换为VIP、Port替换为Nginx中配置的监听端口，然后重启kubelet和kube-proxy服务 123456sed -i &quot;s/10.211.55.4:6443/10.211.55.10:8443/g&quot; /opt/kubernetes/cfg/*systemctl restart kubeletsystemctl restart kube-proxy#确认node节点是否处于Ready状态kubectl get nodes 测试VIP是否正常工作在任意节点上执行如下指令调用API看是否可以正常查看版本信息。其中token替换为token.csv中的token值，IP替换为VIP，Port替换为Nginx中配置的监听端口 若VIP可以正常工作，可以尝试关闭其中一台Nginx，确认VIP是否可以正常漂移到backup节点，然后再次测试调用API是否正常，验证是否可以达到故障切换的效果 12345678910111213curl -k --header "Authorization: Bearer 65cc0bcbe77f4877f288e5604529f384" https://10.211.55.10:8443/version#返回类似如下输出一切正常&#123; "major": "1", "minor": "16", "gitVersion": "v1.16.4", "gitCommit": "224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba", "gitTreeState": "clean", "buildDate": "2019-12-11T12:37:43Z", "goVersion": "go1.12.12", "compiler": "gc", "platform": "linux/amd64"&#125; 至此一套高可用架构的Kubernetes集群就部署完成了，架构图如下所示。若还需要再安装Helm、ingress-nginx、配置k8s对接外部存储做持久化存储，比如Ceph，可继续参考如下内容。 安装helm helm官网：https://helm.sh/ helm github：https://github.com/helm/helm 下载所需版本的helm安装包（本文以2.16.1版本为例），上传到所有的master节点的/root/helm目录下(若没有此目录先创建)，执行如下指令安装helm客户端 1234cd /root/helmtar zxf helm-v2.16.1-linux-amd64.tar.gzcd linux-amd64/cp -a helm /usr/local/bin/ 在其中一台master运行如下指令安装helm服务端 1helm init 执行如下指令设置tiller的rbac权限 123456789kubectl create serviceaccount -n kube-system tillerkubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tillerkubectl --namespace kube-system patch deploy tiller-deploy -p '&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'helm init --upgrade --service-account tiller#稍等片刻待tiller的pod处于均Ready后执行helm list看是否可以正常列出所有的releasekubectl get pods -n kube-system |grep tillerhelm listhelm version 若执行helm version出现类似如下报错 12Client: &amp;version.Version&#123;SemVer:"v2.16.1", GitCommit:"bbdfe5e7803a12bbdf97e94cd847859890cf4050", GitTreeState:"clean"&#125;E1213 15:58:40.605638 10274 portforward.go:400] an error occurred forwarding 34583 -&gt; 44134: error forwarding port 44134 to pod 1e92153b279110f9464193c4ea7d6314ac69e70ce60e7319df9443e379b52ed4, uid : unable to do port forwarding: socat not found 解决办法： 在所有node节点上安装socat 1yum install socat -y 安装ingress-nginx ingress-nginx官网：https://kubernetes.github.io/ingress-nginx/ ingress-nginx github：https://github.com/kubernetes/ingress-nginx 在任意一台master节点上下载ingress-nginx的yaml文件到/root目录下 12cd /root/wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml 编辑mandatory.yaml文件，设置ingress-nginx的部署模式，本文采用hostNetwork模式 12345678910111213141516171819202122232425262728293031...apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginxspec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: "10254" prometheus.io/scrape: "true" spec: hostNetwork: true #添加此行设置ingress-nginx的部署模式为hostNetwork # wait up to five minutes for the drain of connections terminationGracePeriodSeconds: 300 serviceAccountName: nginx-ingress-serviceaccount nodeSelector: kubernetes.io/os: linux... 运行如下指令安装ingress-nginx 12345cd /root/kubectl apply -f mandatory.yaml#确认ingress-nginx的pod是否正常启动，处于running状态kubectl get pods -n ingress-nginx 配置rbd-provisioner K8S要对接Ceph RBD存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考Ceph官网文档进行。 Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/rbd-provisioner目录下，并执行如下指令创建rbd-provisioner所需的yaml文件，标注部分根据实际情况进行修改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154mkdir /root/rbd-provisionercd /root/rbd-provisionercat &gt; clusterrole.yaml &lt;&lt; EOFkind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: rbd-provisionerrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"] - apiGroups: [""] resources: ["services"] resourceNames: ["kube-dns","coredns"] verbs: ["list", "get"] - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; clusterrolebinding.yaml &lt;&lt; EOFkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: rbd-provisionersubjects: - kind: ServiceAccount name: rbd-provisioner namespace: cephroleRef: kind: ClusterRole name: rbd-provisioner apiGroup: rbac.authorization.k8s.ioEOFcat &gt; deployment.yaml &lt;&lt; EOFapiVersion: apps/v1kind: Deploymentmetadata: name: rbd-provisioner namespace: cephspec: progressDeadlineSeconds: 600 revisionHistoryLimit: 10 replicas: 1 selector: matchLabels: app: rbd-provisioner strategy: type: Recreate template: metadata: labels: app: rbd-provisioner spec: containers: - name: rbd-provisioner imagePullPolicy: IfNotPresent image: "quay.io/external_storage/rbd-provisioner:latest" env: - name: PROVISIONER_NAME value: ceph.com/rbd serviceAccount: rbd-provisioner restartPolicy: AlwaysEOFcat &gt; role.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: rbd-provisioner namespace: cephrules:- apiGroups: [""] resources: ["secrets"] verbs: ["get"]- apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; rolebinding.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: rbd-provisioner namespace: cephroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: rbd-provisionersubjects:- kind: ServiceAccount name: rbd-provisioner namespace: cephEOFcat &gt; serviceaccount.yaml &lt;&lt; EOFapiVersion: v1kind: ServiceAccountmetadata: name: rbd-provisioner namespace: cephEOFcat &gt; storageclass.yaml &lt;&lt; EOFkind: StorageClassapiVersion: storage.k8s.io/v1metadata: annotations: storageclass.beta.kubernetes.io/is-default-class: "true" name: rbdprovisioner: ceph.com/rbdparameters: monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789 #配置Ceph集群的monitor节点信息 pool: k8s #配置要连接的pool，若没有需要先在ceph集群上创建 adminId: admin adminSecretNamespace: ceph adminSecretName: ceph-secret fsType: ext4 userId: admin userSecretNamespace: ceph userSecretName: ceph-secret imageFormat: "2" imageFeatures: layeringreclaimPolicy: DeletevolumeBindingMode: ImmediateEOFcat &gt; secrets.yaml &lt;&lt; EOFapiVersion: v1kind: Secretmetadata: name: ceph-secret namespace: cephtype: "ceph.com/rbd"data: # ceph auth add client.kube mon 'allow r' osd 'allow rwx pool=kube' # ceph auth get-key client.admin | base64 key: QVFEcTN5VmRvK28xRHhBQUlKNW5zQ0xwcTd3N0Q5OTJENm9YeGc9PQ== #配置Ceph集群的kering，此处填的是经过base64编码后的值EOF 执行如下执行创建rbd storageclass 1234cd /root/rbd-provisionerkubectl create namespace cephkubectl apply -f storageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding.yaml -f role.yaml -f secrets.yaml -f serviceaccount.yamlkubectl get pods -n ceph | grep rbd-provisioner 配置cephfs-provisioner K8S要对接CephFS存储做持久化存储，首先必须要搭建Ceph存储集群，并在K8S的所有节点上安装对应版本的ceph-common客户端命令。关于Ceph集群的搭建和ceph-common此处不进行赘述，可参考Ceph官网文档进行。 Ceph集群和ceph-common安装都完成后，在其中一台master上创建/root/cephfs-provisioner目录下，并执行如下指令创建cephfs-provisioner所需的yaml文件，标注部分根据实际情况进行修改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139mkdir /root/cephfs-provisionercd /root/cephfs-provisionercat &gt; clusterrole.yaml &lt;&lt; EOFkind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: cephfs-provisioner namespace: cephrules: - apiGroups: [""] resources: ["persistentvolumes"] verbs: ["get", "list", "watch", "create", "delete"] - apiGroups: [""] resources: ["persistentvolumeclaims"] verbs: ["get", "list", "watch", "update"] - apiGroups: ["storage.k8s.io"] resources: ["storageclasses"] verbs: ["get", "list", "watch"] - apiGroups: [""] resources: ["events"] verbs: ["create", "update", "patch"] - apiGroups: [""] resources: ["services"] resourceNames: ["kube-dns","coredns"] verbs: ["list", "get"]EOFcat &gt; clusterrolebinding.yaml &lt;&lt; EOFkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: cephfs-provisionersubjects: - kind: ServiceAccount name: cephfs-provisioner namespace: cephroleRef: kind: ClusterRole name: cephfs-provisioner apiGroup: rbac.authorization.k8s.ioEOFcat &gt; deployment.yaml &lt;&lt; EOFapiVersion: apps/v1kind: Deploymentmetadata: name: cephfs-provisioner namespace: cephspec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: cephfs-provisioner strategy: type: Recreate template: metadata: labels: app: cephfs-provisioner spec: containers: - name: cephfs-provisioner image: "quay.io/external_storage/cephfs-provisioner:latest" imagePullPolicy: IfNotPresent env: - name: PROVISIONER_NAME value: ceph.com/cephfs - name: PROVISIONER_SECRET_NAMESPACE value: ceph command: - "/usr/local/bin/cephfs-provisioner" args: - "-id=cephfs-provisioner-1" - "-disable-ceph-namespace-isolation=true" - "-enable-quota=true" serviceAccount: cephfs-provisioner restartPolicy: Always terminationGracePeriodSeconds: 30EOFcat &gt; role.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: cephfs-provisioner namespace: cephrules: - apiGroups: [""] resources: ["secrets"] verbs: ["create", "get", "delete"] - apiGroups: [""] resources: ["endpoints"] verbs: ["get", "list", "watch", "create", "update", "patch"]EOFcat &gt; rolebinding.yaml &lt;&lt; EOFapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: cephfs-provisioner namespace: cephroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: cephfs-provisionersubjects:- kind: ServiceAccount name: cephfs-provisionerEOFcat &gt; serviceaccount.yaml &lt;&lt; EOFapiVersion: v1kind: ServiceAccountmetadata: name: cephfs-provisioner namespace: cephEOFcat &gt; storageclass.yaml &lt;&lt; EOFkind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: cephfsprovisioner: ceph.com/cephfsparameters: monitors: 10.211.55.4:6789,10.211.55.5:6789,10.211.55.6:6789 #配置Ceph集群的monitor节点信息 adminId: admin adminSecretName: ceph-secret adminSecretNamespace: "ceph"reclaimPolicy: DeletevolumeBindingMode: ImmediateEOF 执行如下指令创建cephfs storageclass 123cd /root/cephfs-provisionerkubectl apply -f storageclass.yaml -f clusterrolebinding.yaml -f clusterrole.yaml -f deployment.yaml -f rolebinding.yaml -f role.yaml -f serviceaccount.yamlkubectl get pods -n ceph | grep cephfs-provisioner EOF 本文作者：Koen 参考链接： https://blog.csdn.net/snipercai/article/details/101012124 https://segmentfault.com/a/1190000020912684]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS/RedHat下Postfix邮件服务器搭建]]></title>
    <url>%2Fck74yvgnv0001dhkc6oq725ka.html</url>
    <content type="text"><![CDATA[作为邮件服务器的机器需要具备访问互联网权限 验证互联网访问权限 12echo &apos;nameserver 114.114.114.114&apos; &gt;&gt; /etc/resolv.confping www.baidu.com 若无法访问互联网请先开通相关策略继续下面的操作 基础配置 123456iptables -Fsystemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configreboot 设置主机名并添加本地host解析12345678910CentOS/RedHat6.xhostname &lt;postfix.example.com&gt;永久设置需改/etc/sysconfig/network中的HOSTNAME参数CentOS/RedHat7.xhostnamectl set-hostname &lt;postfix.example.com&gt;添加本地解析cat /etc/hostsx.x.x.x &lt;postfix.example.com&gt; 安装postfix 1yum install postfix -y 配置postfix12345678cp -a /etc/postfix/main.cf /etc/postfix/main.cf.bakpostconf -e myhostname=postfix.example.compostconf -e inet_interfaces=allpostconf -e inet_protocols=ipv4postconf -e mydestination=$myhostname,localhost.$mydomain,localhostpostconf -e unknown_local_recipient_reject_code=550postconf -e mynetworks_style=subnetpostconf -e mynetworks=172.18.0.0/16,127.0.0.0/8 配置参数说明： myhostname：主机名 inet_interfaces：监听的网卡接口 inet_protocols：设置postfix只使用IPv4 mydestination：可接受邮件地址域名 unknown_local_recipient_reject_code：当客户端试图寄信给不存在的本地网域用户时,postfix用于拒绝客户端的smtp 响应码 mynetworks_style：设置局域网网络类型，默认为subnet，subnet 代表是子网络，当设定为subnet时，postfix将会自行根据 ifconfig 上登记的 IP 和 网络屏蔽作运算，自动求出子网络的范围；如果设定成 class，则是不理会屏蔽，自动信任同一个 class 等级的计算机，如果该服务器使用拨接上网，这样设定将使得同一家 ISP 的拨接用户，都可以利用本服务器转信，这是非常危险的（除非你是 ISP 公司）；设定host 则仅该单机可以寄信。 mynetworks：需要收发的客户端的地址，根据实际环境修改 启动postfix 1234567CentOS/RedHat6.xservice postfix statuschkconfig postfix onCentOS/RedHat7.xsystemctl restart postfixsystemctl enable postfix 测试发送邮件 123456789101112131415161718yum install telnet -ytelnet localhost 25 Trying 127.0.0.1...Connected to localhost.Escape character is &apos;^]&apos;.220 postfix.example.com ESMTP Postfixmail from: test@postfix.com //发件人邮箱250 2.1.0 Okrcpt to: 379148058@qq.com //收件人邮箱250 2.1.5 Okdata //邮件内容354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;test mail. //以“.”结束250 2.0.0 Ok: queued as 6D75940F10quit //退出221 2.0.0 ByeConnection closed by foreign host. 登录收件人邮箱查看是否正常接收到测试邮件，若在收件箱中未找到，看下是否在垃圾箱中。若同样未有，则可在邮件服务器上运行mailq查看邮件发送进度和相关报错。 EOF 本文作者：Koen]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CENTOS/RHEL7系统中设置SYSTEMD SERVICE的ULIMIT资源限制]]></title>
    <url>%2Fck74yvgny0003dhkcy2wyhh9k.html</url>
    <content type="text"><![CDATA[在bash中，有个ulimit命令，提供了对shell及该shell启动的进程的可用资源控制。主要包括打开文件描述符数量、用户的最大进程数量、coredump文件的大小等。 在centos 5/6 等版本中，资源限制的配置可以在 /etc/security/limits.conf 设置，针对root/user等各个用户或者*代表所有用户来设置。 当然，/etc/security/limits.d/ 中也可以配置，系统是先加载limits.conf然后按照英文字母顺序加载limits.d目录下的配置文件，后加载配置覆盖之前的配置。 一个配置示例如下： 123456* soft nofile 100000* hard nofile 100000* soft nproc 100000* hard nproc 100000* soft core 100000* hard core 100000 不过，在CentOS 7 / RHEL 7的系统中，使用Systemd替代了之前的SysV，因此 /etc/security/limits.conf 文件的配置作用域缩小了一些。limits.conf这里的配置，只适用于通过PAM认证登录用户的资源限制，它对systemd的service的资源限制不生效。登录用户的限制，与上面讲的一样，通过 /etc/security/limits.conf 和 limits.d 来配置即可。对于systemd service的资源限制，如何配置呢？ 全局的配置，放在文件 /etc/systemd/system.conf 和 /etc/systemd/user.conf。 同时，也会加载两个对应的目录中的所有.conf文件 /etc/systemd/system.conf.d/.conf 和 /etc/systemd/user.conf.d/.conf 其中，system.conf 是系统实例使用的，user.conf用户实例使用的。一般的sevice，使用system.conf中的配置即可，在[Service]模块下添加如下内容。systemd.conf.d/*.conf中配置会覆盖system.conf。 123DefaultLimitCORE=infinityDefaultLimitNOFILE=100000DefaultLimitNPROC=100000 注：修改了system.conf后，需要重启系统才会生效。 针对单个Service，也可以设置，以nginx为例。 编辑 /usr/lib/systemd/system/nginx.service 文件，或者 /usr/lib/systemd/system/nginx.service.d/my-limit.conf 文件，在[Service]模块下添加如下内容： 123LimitCORE=infinityLimitNOFILE=100000LimitNPROC=100000 然后运行如下命令，才能生效。 12systemctl daemon-reloadsystemctl restart nginx.service 查看一个进程的limit设置：cat /proc/YOUR-PID/limits 例如我的一个nginx service的配置效果： 123456789101112131415161718# cat /proc/$(cat /var/run/nginx.pid)/limitsLimit Soft Limit Hard Limit UnitsMax cpu time unlimited unlimited secondsMax file size unlimited unlimited bytesMax data size unlimited unlimited bytesMax stack size 8388608 unlimited bytesMax core file size unlimited unlimited bytesMax resident set unlimited unlimited bytesMax processes 100000 100000 processesMax open files 100000 100000 filesMax locked memory 65536 65536 bytesMax address space unlimited unlimited bytesMax file locks unlimited unlimited locksMax pending signals 1030606 1030606 signalsMax msgqueue size 819200 819200 bytesMax nice priority 0 0Max realtime priority 0 0Max realtime timeout unlimited unlimited us 另外，CentOS7自带的/etc/security/limits.d/20-nproc.conf文件里面默认设置了非root用户的最大进程数为4096，因此若只在limits.conf中做设置并没有效果，会被limit.d目录中的配置所覆盖。 EOF 转载链接：http://smilejay.com/2016/06/centos-7-systemd-conf-limits/]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何制作Openstack Windows镜像]]></title>
    <url>%2Fck74yvgp1002xdhkcnvngw616.html</url>
    <content type="text"><![CDATA[在上一篇文章如何制作Openstack Linux镜像中我们以CentOS7.1为例，介绍了手动制作Openstack Linux镜像的详细步骤，本文我们将继续以制作Windows Server 2008 R2镜像为例，介绍手动制作Openstack Windows镜像的详细步骤。 手动制作Openstack Windows镜像 下载镜像访问官网镜像下载地址，进入后点击“操作系统”，选择Windows Server 2008 R2，选择需要的相应的语言和版本进行下载并上传到/tvm下。 下载virtio驱动访问virtio官方下载地址，下载virtio驱动 创建虚拟机首先创建一个raw格式镜像文件，用于虚拟机的根磁盘，大小30G就够了。（镜像文件大小可根据实际情况自行调整，此处以30G为例） 12cd /tvm/qemu-img create -f raw Windows2008_R2.raw 30G 修改/tvm/templates.xml，将图中红色方框处改成虚拟机镜像文件所在绝对路径，并指定相应ISO文件绝对路径，同时新增一个cdrom设备，将virtio驱动的iso镜像挂载到虚拟机中。 启动虚拟机 12cd /tvm/virsh create templates.xml 启动完成后，使用vnc client连接到虚拟机控制台。 安装OS进入虚拟机控制台可以看到虚拟机正在加载文件，加载完成后选择语言，点击“下一步”，点击“现在安装” 待安装程序启动后，选择要安装的操作系统，此处选择安装的是“Windows Server 2008 R2 Enterprise （完全安装）”，然后点击“下一步” 勾选“我接受许可条款(A)”，点击“下一步” 选择“自定义(高级)(C)” 此时会看到提示说“未找到任何驱动器”。因为KVM下windows虚拟机默认disk使用的是Qemu IDE硬盘，默认网卡是100M网卡，为了使KVM主机在相同的配置下有更好的效率，我们在xml文件中设置了bus=’virtio’，使硬盘工作在SCSI模式，但因缺少virtio驱动，识别不到硬盘，所以我们需要用刚挂载的virtio驱动的ISO文件安装相应的virtio驱动。 点击“加载驱动程序(L)” 点击“浏览” 选择virtio所在驱动器的viostor/2k8R2/amd64目录，点击“确定”。（2k8R2代表Windows Server 2008 R2，若安装的为其他操作系统版本，记得自行更换到对应的目录） 在找到相应的SCSI驱动后，点击“下一步” 进行磁盘分区，此处将所有空间划分到C盘，然后点击“下一步”，等待操作系统安装完成 配置OS注：系统安装完成后首次登陆要求修改administrator密码 安装网卡驱动 打开“服务器管理器”，点击“诊断”，点击“设备管理器”，看到以太网控制器处显示有一个黄色感叹号，右单击，选择”更新驱动程序软件(O)…” 选择”浏览计算机以查找驱动程序软件(R)” 点击“浏览” 选择virtio所在的驱动器，点击“确定” 点击“下一步” 勾选“始终信任来自”Red Hat,Inc.”的软件(A)”，点击“安装” 点击“关闭”，完成网卡驱动安装。若有多张网卡，需重复上述步骤安装网卡驱动。 开启远程桌面服务 启动任务管理器，打开“服务”，找到“Remote Desktop Services”，点击“启动”。 右单击“Remote Desktop Services”服务，选择“属性”，将启动类型改成“自动”，并点击“确定” 点击“开始”菜单，对“计算机”右单击，选择“属性”，点击“远程设置”，选择“允许运行任意版本远程桌面的计算机连接(较不安全)(L)”，点击“确定” 关闭防火墙 点击“开始”菜单，打开“控制面板”，点击“系统和安全” 点击“Windows防火墙” 点击“打开或关闭Windows防火墙” 勾选“家庭或工作(专用)网络位置设置”和“公用网络位置设置”的“关闭Windows防火墙(不推荐)”选项，点击“确定” 关闭自动更新 点击“开始”菜单，打开“控制面板”，点击“系统和安全” 点击“Windows Update” 点击“更改设置” 选择“从不检查更新(不推荐)”，点击“确定” 安装Ec2Config Ec2Config下载链接：https://share.weiyun.com/5HDPp6h 密码：i7d3cj 下载完成后通过远程桌面将Ec2Config安装包上传到虚拟机中，并以管理员身份运行 注：若出现“当前系统没有安装Microsoft .NET Framework 3.5，要转到它的下载页面吗？”的提示，点击“否(N)”，然后按照此教程安装.NET Framework 3.5 点击“下一步” 勾选”启动服务”，点击“下一步” 安装路径默认即可，点击“安装” 不勾选“运行Ec2Config服务配置(R)”，点击“完成” 删除Ec2Config安装包，并清空回收站 配置镜像administrator用户默认密码 用记事本打开C:\Program Files\Bingosoft\Ec2Config\Scripts\SysPrepInit.cmd，将ScramblePassword.exe -u Administrator这行改为net user administrator xxxxxx （xxxxxx为你要设置的密码），将sc config Ec2Config start= auto这行改为sc config Ec2Config start= disabled，然后保存退出 1234567891011原文件内容如下：@echo offScramblePassword.exe -u Administratornet user Administrator /ACTIVE:YES /LOGONPASSWORDCHG:NO /EXPIRES:NEVER /PASSWORDREQ:YESsc config Ec2Config start= auto修改后的内容如下：@echo offnet user administrator 123456net user Administrator /ACTIVE:YES /LOGONPASSWORDCHG:NO /EXPIRES:NEVER /PASSWORDREQ:YESsc config Ec2Config start= disabled 清理系统日志 打开“服务器管理器”，点击“诊断”，打开“事件查看器” 双击”Windows日志”，对“应用程序”右单击，点击“清除日志(C)…”,点击“清除(C)” 重复上述步骤清除“安全”、“Setup”、“系统”、“转发事件”中的日志 运行sysprep封装镜像 点击“开始”菜单，打开“Ec2ConfigService Settings” 确认“Set Password”的两个选项均未勾选，然后切换到“Bundle”选项卡 点击“Run Sysprep and Shutdown Now” 点击“是” 点击“是” 以上为几个常用的配置，其他的配置可以根据情况进行进行设置。 转换镜像格式将raw格式镜像文件转换成qcow2格式镜像文件，压缩空间便于传输。 1qemu-img convert -f raw Windows2008_R2.raw -O qcow2 Windows2008_R2.qcow2 上传镜像 Openstack Wndows镜像制作完成后，需要将最终生成的qcow2镜像文件上传到Openstack控制节点，并通过glance命令将镜像上传到glance服务中才可以正常使用。命令如下： 1glance image-create --name &quot;Windows2008_R2&quot; --file /tvm/Windows2008_R2.qcow2 --disk-format qcow2 --container-format bare --is-public True --progress EOF 本文作者：Koen]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何制作Openstack Linux镜像]]></title>
    <url>%2Fck74yvgoy002pdhkc9j6x7g8b.html</url>
    <content type="text"><![CDATA[在上一篇文章构建Openstack镜像的环境搭建中我们介绍了如何在自己的笔记本或台式机上搭建一个可以用于制作Openstack镜像的环境，本文我们将利用这个环境，以制作CentOS7.1镜像为例，介绍手动制作Openstack Linux镜像的详细步骤。 手动制作Openstack Linux镜像 下载镜像访问镜像下载地址，进入后选择版本为7.1.1503，在isos目录下下载x86_64的Minimal镜像，并上传到/tvm下。如果网速不给力，最好不要选择下载Netinstall镜像，因为这会在安装时联网下载大量的软件包，重新安装时需要重新下载这些软件包。 创建虚拟机首先创建一个raw格式镜像文件，用于虚拟机的根磁盘，大小30G就够了。（镜像文件大小可根据实际情况自行调整，此处以30G为例） 12cd /tvm/qemu-img create -f raw CentOS7.1.raw 30G 修改/tvm/templates.xml，将图中红色方框处改成虚拟机镜像文件所在绝对路径，并指定相应ISO文件绝对路径。 启动虚拟机 12cd /tvm/virsh create templates.xml 启动完成后，使用vnc client连接到虚拟机控制台。 安装OS进入虚拟机控制台可以看到CentOS的启动菜单，选择“Install CentOS 7”，继续选择语言后将进入INSTALL SUMMARY，其中大多数配置默认即可，时区选择“Asia/Shanghai”，“SOFTWARE SELECTION”选择“Minimal Install”，“INSTALLATION DESTINATION”需要选择手动配置分区，我们只需要一个根分区即可，不需要swap分区，Device Type选择Standard Partition（务必选择此选项，因为cloud-init只支持标准分区的自动扩展），文件系统选择ext4或者xfs，存储驱动选择Virtio Block Device，如图： 配置完成后就可以开始安装了，在CONFIGURATION中设置root用户密码。大约几分钟后，即可自动完成安装配置工作，最后点击右下角的reboot重启退出虚拟机。 注：此时你会发现虚拟机重启后又再次进入了CentOS的启动菜单，因此需要先终止掉此虚拟机进程，然后修改/tvm/templates.xml，将文件中指定的ISO文件路径清空，然后再次启动虚拟机，此时虚拟机就会直接从硬盘中启动系统。 1234567[root@koenli tvm]# virsh list Id Name State---------------------------------------------------- 3 koenli running[root@koenli tvm]# virsh destroy 3 Domain 3 destroyed 配置OS配置网卡配置文件配置网卡配置文件ifcfg-eth0,ifcfg-eth1，删除mac地址和UUID相关配置项，IP为dhcp获取，开机自启动 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647CentOS6.x/RedHat6.x操作如下：cat &gt; /etc/sysconfig/network-scripts/ifcfg-eth0 &lt;&lt; EOFDEVICE=eth0TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=dhcpEOFcat &gt; /etc/sysconfig/network-scripts/ifcfg-eth1 &lt;&lt; EOFDEVICE=eth1TYPE=EthernetONBOOT=noNM_CONTROLLED=yesBOOTPROTO=dhcpEOF/etc/init.d/network restartCentOS7.x/RedHat7.x操作如下:cat &gt; /etc/sysconfig/network-scripts/ifcfg-eth0 &lt;&lt; EOFTYPE=EthernetBOOTPROTO=dhcpDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noNAME=eth0DEVICE=eth0ONBOOT=yesEOFcat &gt; /etc/sysconfig/network-scripts/ifcfg-eth1 &lt;&lt; EOFTYPE=EthernetBOOTPROTO=dhcpDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noNAME=eth1DEVICE=eth1ONBOOT=noEOFsystemctl stop NetworkManagersystemctl disable NetworkManagersystemctl restart network 配置sshd服务关闭sshd服务的UseDNS和GSSAPIAuthentication选项 123456789CentOS6.x/RedHat6.x操作如下：sed -i &apos;s/#UseDNS yes/UseDNS no/g&apos; /etc/ssh/sshd_configsed -i &apos;s/GSSAPIAuthentication yes/GSSAPIAuthentication no/g&apos; /etc/ssh/sshd_config/etc/init.d/sshd restartCentOS7.x/RedHat7.x操作如下:sed -i &apos;s/#UseDNS yes/UseDNS no/g&apos; /etc/ssh/sshd_configsed -i &apos;s/GSSAPIAuthentication yes/GSSAPIAuthentication no/g&apos; /etc/ssh/sshd_configsystemctl restart sshd 配置iptables和selinux关闭iptables和selinux，并设置开机不自启（需重启生效） 12345678910111213CentOS6.x/RedHat6.x操作如下：/etc/init.d/iptables stopchkconfig iptables offsetenforce 0sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configrebootCentOS7.x/RedHat7.x操作如下:systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configreboot 系统参数和内核参数优化设置系统文件句柄数限制和进程数限制（需重启生效） 12345678CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOF* soft nproc 655360* hard nproc 655360* soft nofile 655360* hard nofile 655360EOFreboot 设置系统内核参数 123456789101112CentOS6.x/RedHat6.x操作如下：cp -a /etc/sysctl.conf /etc/sysctl.conf.bakecho &quot;net.ipv4.ip_forward=1&quot; &gt; /etc/sysctl.confecho &quot;net.ipv4.conf.default.rp_filter=0&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.conf.all.rp_filter=0&quot; &gt;&gt; /etc/sysctl.confsysctl -pCentOS7.x/RedHat7.x操作如下:echo &quot;net.ipv4.ip_forward=1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.conf.default.rp_filter=0&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.conf.all.rp_filter=0&quot; &gt;&gt; /etc/sysctl.confsysctl -p 设置history历史命令显示格式123CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:echo &apos;HISTTIMEFORMAT=&quot;[%Y-%m-%d %H:%M:%S $USER] &quot;&apos; &gt;&gt; /etc/profilesource /etc/profile 上传iso文件配置本地yum源此步可参考CentOS6.X/CentOS7.X配置本地yum源教程，此处不再赘述。 安装基础软件包12CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:yum install -y vim net-tools lrzsz unzip dos2unix telnet sysstat iotop pciutils lsof tcpdump wget strace ipmitool psmisc tree bc 安装epel源到https://fedoraproject.org/wiki/EPEL/zh-cn下载对应操作系统版本的epel-release包的最新版本，然后上传到虚拟机的/root目录下并安装 123456789CentOS6.x/RedHat6.x操作如下：cd /root/rpm -ivh epel-release-latest-6.noarch.rpmrm -rf epel-release-latest-6.noarch.rpmCentOS7.x/RedHat7.x操作如下：cd /root/rpm -ivh epel-release-latest-7.noarch.rpmrm -rf epel-release-latest-7.noarch.rpm 安装cloud-utils-growpart安装cloud-utils-growpart工具，实现根分区自动扩展 123456CentOS6.x/RedHat6.x操作如下：yum install cloud-utils-growpart dracut-modules-growroot -ydracut -fCentOS7.x/RedHat7.x操作如下:yum install cloud-utils-growpart -y 安装cloud-init到https://share.weiyun.com/5gNv58k 密码：k6wnsx 下载对应操作系统版本的cloud-init安装包，并上传到虚拟机的/root/cloud-init目录下并安装（/root/cloud-init目录通过执行mkdir /root/cloud-init新建） 1234567CentOS6.x/RedHat6.x操作如下：cd /root/cloud-init/yum localinstall *.rpm -yCentOS7.x/RedHat7.x操作如下:cd /root/cloud-init/yum localinstall *.rpm -y 编辑/etc/cloud/cloud.cfg，将disable_root参数设为0（允许root用户ssh远程登录），ssh_pwauth参数设为1（允许password认证），保存退出 12345678CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:vim /etc/cloud/cloud.cfgusers: - defaultdisable_root: 0ssh_pwauth: 1... 启动cloud-init并设置开机自启，因为做镜像的环境是无法访问到openstack的元数据服务的，故此次启动cloud-init时间会比较长，可以新开一个窗口执行tail -f /var/log/messages查看启动进度。 1234567CentOS6.x/RedHat6.x操作如下：chkconfig cloud-init on/etc/init.d/cloud-init restartCentOS7.x/RedHat7.x操作如下:systemctl enable cloud-initsystemctl restart cloud-init CentOS7.x/RedHat7.x上若cloud-init启动失败，执行systemctl status cloud-init查看服务状态，若出现类似如下报错，则执行下面的指令更新six，然后再次启动 12345678910111213141516Dec 12 00:12:59 localhost.localdomain cloud-init[1989]: File &quot;/usr/lib/python2.7/site-packages/cloudinit/cmd/main.py&quot;, line 2...dule&gt;Dec 12 00:12:59 localhost.localdomain cloud-init[1989]: from cloudinit import netinfoDec 12 00:12:59 localhost.localdomain cloud-init[1989]: File &quot;/usr/lib/python2.7/site-packages/cloudinit/netinfo.py&quot;, line 14...dule&gt;Dec 12 00:12:59 localhost.localdomain cloud-init[1989]: from cloudinit import utilDec 12 00:12:59 localhost.localdomain cloud-init[1989]: File &quot;/usr/lib/python2.7/site-packages/cloudinit/util.py&quot;, line 37, i...dule&gt;Dec 12 00:12:59 localhost.localdomain cloud-init[1989]: from six.moves.urllib import parse as urlparseDec 12 00:12:59 localhost.localdomain cloud-init[1989]: ImportError: No module named urllibDec 12 00:12:59 localhost.localdomain systemd[1]: cloud-init.service: main process exited, code=exited, status=1/FAILUREDec 12 00:12:59 localhost.localdomain systemd[1]: Failed to start Initial cloud-init job (metadata service crawler).Dec 12 00:12:59 localhost.localdomain systemd[1]: Unit cloud-init.service entered failed state.解决方法：yum install python-pip -ypip install --upgrade sixsystemctl enable cloud-initsystemctl restart cloud-init CentOS7.x/RedHat7.x需再次编辑网卡配置文件，将网卡配置文件（/etc/sysconfig/network-scripts/ifcfg-eth0）中的HWADDR一行删除并保存退出。 安装qemu-guest-agent123456CentOS6.x/RedHat6.x操作如下：yum install qemu-guest-agent -ychkconfig qemu-ga onCentOS7.x/RedHat7.x操作如下:yum install qemu-guest-agent -y 禁用zeroconf编辑/etc/sysconfig/network-scripts/ifup-eth注释掉以下部分，禁用zeroconf，否则zeroconf router在虚拟机开机时会自动生成路由169.254.0.0/16 0 0 0 0导致虚拟机无法与元数据通信 1234567891011原内容# Add Zeroconf route.if [ -z &quot;$&#123;NOZEROCONF&#125;&quot; -a &quot;$&#123;ISALIAS&#125;&quot; = &quot;no&quot; -a &quot;$&#123;REALDEVICE&#125;&quot; != &quot;lo&quot; ]; then ip route add 169.254.0.0/16 dev $&#123;REALDEVICE&#125; metric $((1000 + $(cat /sys/class/net/$&#123;REALDEVICE&#125;/ifindex))) scope linkfi注释后：# Add Zeroconf route.#if [ -z &quot;$&#123;NOZEROCONF&#125;&quot; -a &quot;$&#123;ISALIAS&#125;&quot; = &quot;no&quot; -a &quot;$&#123;REALDEVICE&#125;&quot; != &quot;lo&quot; ]; then# ip route add 169.254.0.0/16 dev $&#123;REALDEVICE&#125; metric $((1000 + $(cat /sys/class/net/$&#123;REALDEVICE&#125;/ifindex))) scope link#fi 设置NTP（可选）123456789101112131415CentOS6.x/RedHat6.x操作如下：yum install ntp ntpdate -ysed -i &quot;s%^server%#server%g&quot; /etc/ntp.confecho &quot;server &lt;ntpserver_ip&gt;&quot; &gt;&gt; /etc/ntp.conf #&lt;ntpserver_ip&gt;替换为ntpserver的IP地址/etc/init.d/ntpd restartchkconfig ntpd onCentOS7.x/RedHat7.x操作如下:yum install ntp ntpdate -ysed -i &quot;s%^server%#server%g&quot; /etc/ntp.confecho &quot;server &lt;ntpserver_ip&gt;&quot; &gt;&gt; /etc/ntp.conf #&lt;ntpserver_ip&gt;替换为ntpserver的IP地址systemctl restart ntpdsystemctl enable ntpdsystemctl stop chronydsystemctl disable chronyd 清理文件12345CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:rm -rf /root/cloud-init/rpm -e `rpm -qa |grep epel`yum clean allrm -rf /etc/udev/rules.d/70-persistent-net.rules 清理命令历史记录并关机123456CentOS6.x/RedHat6.x/CentOS7.x/RedHat7.x操作如下:echo &gt; /var/log/wtmpecho &gt; /var/log/btmpecho &gt; ~/.bash_historyhistory -cshutdown -h now 以上为几个比较常用的配置，更多自定义配置可以参考此文 转换镜像格式将raw格式镜像文件转换成qcow2格式镜像文件，压缩空间便于传输。 1qemu-img convert -f raw CentOS7.1.raw -O qcow2 CentOS7.1.qcow2 上传镜像 Openstack Linux镜像制作完成后，将最终生成的qcow2镜像文件上传到Openstack控制节点，先转成raw镜像文件，然后通过glance命令上传镜像，最后设置镜像的hw_qemu_guest_agent属性为yes即可。相关命令如下： 123qemu-img convert -f qcow2 CentOS7.1.qcow2 -O raw CentOS7.1.rawglance image-create --name &quot;CentOS7.1&quot; --file /tvm/CentOS7.1.raw --disk-format raw --container-format bare --is-public True --progressglance image-update --property hw_qemu_guest_agent=yes &lt;image_id&gt; EOF 本文作者：Koen 参考链接：https://xiexianbin.cn/openstack/2016/12/14/centos-root-partition-auto-grow]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建Openstack镜像的环境搭建]]></title>
    <url>%2Fck74yvgp7003hdhkcie0po7en.html</url>
    <content type="text"><![CDATA[虽然Openstack官方文档上有提供了各类操作系统的Openstack镜像，但我们往往需要根据实际情况进行一些自定义设置，因此本文主要介绍如何在自己的笔记本或台式机上通过VMware构建一个可以用于制作Openstack镜像的环境，以便可以快速的制作自定义的Openstack镜像。 环境介绍 宿主机操作系统：Windows7旗舰版 软件：VMware WorkStation12 Pro 虚拟机操作系统：CentOS7.1 虚拟机配置：2核4G 虚拟机IP：192.168.128.129 网卡模式：NAT 镜像：CentOS-7-x86_64-Minimal-1503-01.iso 镜像下载链接：http://archive.kernel.org/centos-vault/ VMware虚拟机操作系统安装 此步请参考之前的文章如何在VMware下安装RedHat6.X虚拟机 注：记得在VMware里将虚拟机处理器中的“虚拟化Intel VT-x/EPT 或 AMD-V/RVI(V)”选项勾选 初始化配置 123456iptables -Fsystemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configreboot 安装epel源 到https://fedoraproject.org/wiki/EPEL/zh-cn下载对应操作系统版本的epel-release包的最新版本，然后上传到虚拟机并安装 1rpm -ivh epel-release-latest-7.noarch.rpm 安装KVM 1234yum install libcanberra-gtk2 qemu-kvm.x86_64 qemu-kvm-tools.x86_64 libvirt.x86_64 libvirt-cim.x86_64 libvirt-client.x86_64 libvirt-java.noarch libvirt-python.x86_64 dbus-devel virt-clone virt-manager libvirt libvirt-python -yyum groupinstall &quot;Virtualization Host&quot; -yyum install qemu-system* -y systemctl restart libvirtd 修改网卡配置文件 修改网卡配置文件，重启网络服务，将虚拟机网卡桥接到br网桥上，此示例中虚拟机网卡名为eno16777736，对应的网卡配置文件如下： 12345678910111213141516171819202122232425cat &gt; /etc/sysconfig/network-scripts/ifcfg-eno16777736 &lt;&lt; EOF BOOTPROTO=staticNAME=eno16777736DEVICE=eno16777736ONBOOT=yesBRIDGE=brEOFcat &gt; /etc/sysconfig/network-scripts/ifcfg-br &lt;&lt; EOFTYPE=BridgeBOOTPROTO=staticIPADDR=192.168.128.129NETMASK=255.255.255.0GATEWAY=192.168.128.2DNS1=192.168.128.2NAME=brDEVICE=brONBOOT=yesEOF DEVICE、NAME、IPADDR、NETMASK、GATEWAY参数请根据实际情况进行相应修改systemctl stop NetworkManagersystemctl disable NetworkManagersystemctl restart network 创建工作目录 12mkdir /tvm/cd /tvm/ 至此环境已经搭建完成，继续根据以下步骤启动一台虚拟机验证环境是否正常。 测试验证 上传虚拟机镜像到https://download.cirros-cloud.net/下载任意版本的cirros镜像文件(例如cirros-0.4.0-x86_64-disk.img)，并上传到/tvm目录下。如果你使用的镜像是qcow2格式的(可通过qemu-img info &lt;image_name&gt;查看file format字段)，先参考如下命令转换成raw格式的。 1qemu-img convert -f qcow2 cirros-0.4.0-x86_64-disk.img -O raw cirros-0.4.0-x86_64-disk.img.raw 编辑XML文件并启动虚拟机123456789101112131415161718192021222324252627282930# cat templates.xml&lt;domain type=&apos;kvm&apos;&gt; &lt;name&gt;koenli&lt;/name&gt; &lt;memory&gt;1048576&lt;/memory&gt; &lt;vcpu&gt;1&lt;/vcpu&gt; &lt;cpu mode=&apos;host-model&apos;&gt;&lt;model fallback=&apos;allow&apos;/&gt;&lt;topology sockets=&apos;1&apos; threads=&apos;1&apos; cores=&apos;4&apos; /&gt;&lt;/cpu&gt; &lt;os&gt;&lt;type arch=&apos;x86_64&apos; machine=&apos;pc-i440fx-2.0&apos;&gt;hvm&lt;/type&gt;&lt;boot dev=&apos;cdrom&apos;/&gt;&lt;boot dev=&apos;hd&apos;/&gt;&lt;/os&gt; &lt;features&gt;&lt;acpi/&gt;&lt;apic/&gt;&lt;pae/&gt;&lt;/features&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;devices&gt; &lt;emulator&gt;/usr/bin/qemu-system-x86_64&lt;/emulator&gt; &lt;disk type=&apos;file&apos;&gt;&lt;driver name=&apos;qemu&apos; type=&apos;raw&apos; cache=&apos;none&apos;/&gt;&lt;source file=&apos;/tvm/cirros-0.4.0-x86_64-disk.img.raw&apos;/&gt;&lt;target dev=&apos;vda&apos; bus=&apos;virtio&apos;/&gt;&lt;serial&gt;bc-system&lt;/serial&gt;&lt;/disk&gt; &lt;disk type=&apos;file&apos; device=&apos;cdrom&apos;&gt; &lt;target dev=&apos;hdc&apos; bus=&apos;ide&apos;/&gt; &lt;source file=&quot;&quot; /&gt; &lt;readonly/&gt; &lt;/disk&gt; &lt;graphics type=&apos;vnc&apos; port=&apos;22000&apos; passwd=&apos;123456&apos; autoport=&apos;no&apos; keymap=&apos;en-us&apos; listen=&apos;0.0.0.0&apos;/&gt; &lt;input type=&apos;tablet&apos; bus=&apos;usb&apos;/&gt; &lt;interface type=&apos;bridge&apos;&gt;&lt;source bridge=&apos;br&apos;/&gt;&lt;mac address=&apos;D0:0D:7C:DC:AA:4C&apos;/&gt;&lt;model type=&apos;virtio&apos;/&gt;&lt;/interface&gt; &lt;interface type=&apos;bridge&apos;&gt;&lt;source bridge=&apos;br&apos;/&gt;&lt;mac address=&apos;D0:0D:7C:DC:AA:4D&apos;/&gt;&lt;model type=&apos;virtio&apos;/&gt;&lt;/interface&gt; &lt;/devices&gt; &lt;clock offset=&quot;localtime&quot; /&gt;&lt;/domain&gt; 将图中红色方框处改成虚拟机镜像所在绝对路径，若需要给虚拟机挂载ISO文件进行操作系统安装，则在箭头处指定ISO文件的绝对路径。 123cd /tvm/virsh create templates.xmlvirsh list 通过vnc连接到虚拟机 密码：123456 EOF 本文作者：Koen]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS6.X/CentOS7.X配置本地yum源教程]]></title>
    <url>%2Fck74yvgo20007dhkcknc7opoo.html</url>
    <content type="text"><![CDATA[实验环境介绍 系统环境：CentOS6.5 ISO镜像：CentOS-6.5-x86_64-bin-DVD1.iso 镜像下载链接：http://archive.kernel.org/centos-vault/ 详细配置步骤 1、根据具体的系统版本下载对应版本的ISO文件，系统版本可通过cat /etc/redhat-release查看 2、将镜像上传到机器任意位置，若机器未设置IP，可通过U盘等外置设备将ISO文件拷贝到机器中，若机器已设置IP，可通过winscp或Xftp等支持SSH的SCP文件传输软件将ISO文件上传到机器中。示例中我将ISO文件（CentOS-6.5-x86_64-bin-DVD1.iso）上传到/usr/local目录下 3、建立/mnt/cdrom和/mnt/&lt;OS_Version&gt;两个目录，其中&lt;OS_Version&gt;替换为操作系统版本 12mkdir /mnt/cdrommkdir /mnt/CentOS6.5 4、将ISO文件挂载到/mnt/cdrom目录下，并将镜像中的所有文件拷贝到/mnt/&lt;OS_Version&gt;目录中 12345mount -o loop /usr/local/CentOS-6.5-x86_64-bin-DVD1.iso /mnt/cdrom/ls /mnt/cdrom/cp -r /mnt/cdrom/* /mnt/CentOS6.5/umount /mnt/cdrom/rm -r /mnt/cdrom/ 5、进入到/etc/yum.repos.d/，备份系统原有的repo文件 1234cd /etc/yum.repos.d/lsmkdir backupmv * backup/ 6、在/etc/yum.repos.d/新建repo文件（注：文件名一定要以.repo结尾，其他部分可自义定，例如a.repo,b.repo，此示例中为CentOS6.5.repo） 12345678910111213cat &gt; /etc/yum.repos.d/CentOS6.5.repo &lt;&lt; EOF[CentOS6.5]name=CentOS6.5baseurl=file:///mnt/CentOS6.5gpgcheck=0EOF注：[]中的内容可自定义name参数可自定义baseurl是服务器设置中最重要的部分，只有设置正确，才能从上面获取软件。它的格式是baseurl=url://server1/path/to/repository/其中url支持的协议有 http:// ftp:// file://三种，此示例中为file://，路径为/mnt/CentOS6.5（第4步中已将ISO中的所有文件拷贝到此目录下）gpgchkeck= 有1和0两个选择，分别代表是否是否进行gpg校验，此处设置为0，不进行gpg校验 7、执行yum clean all清楚yum缓存，然后执行yum list，如果能如下图正常列出可用的软件包，说明本地yum源配置成功了。 EOF 本文作者：Koen]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack Swift原理、架构与API介绍]]></title>
    <url>%2Fck74yvgok001gdhkclcxdwzfl.html</url>
    <content type="text"><![CDATA[背景与概览 Swift最初是由Rackspace公司开发的高可用分布式对象存储服务，并于2010年贡献给OpenStack开源社区作为其最初的核心子项目之一，为其Nova子项目提供虚机镜像存储服务。Swift构筑在比较便宜的标准硬件存储基础设施之上，无需采用RAID（磁盘冗余阵列），通过在软件层面引入一致性散列技术和数据冗余性，牺牲一定程度的数据一致性来达到高可用性和可伸缩性，支持多租户模式、容器和对象读写操作，适合解决互联网的应用场景下非结构化数据存储问题。 此项目是基于Python开发的，采用Apache 2.0许可协议，可用来开发商用系统。 基本原理 一致性散列（Consistent Hashing) 面对海量级别的对象，需要存放在成千上万台服务器和硬盘设备上，首先要解决寻址问题，即如何将对象分布到这些设备地址上。Swift是基于一致性散列技术，通过计算可将对象均匀分布到虚拟空间的虚拟节点上，在增加或删除节点时可大大减少需移动的数据量；虚拟空间大小通常采用2的n次幂，便于进行高效的移位操作；然后通过独特的数据结构Ring（环）再将虚拟节点映射到实际的物理存储设备上，完成寻址过程。 如上图所示，以逆时针方向递增的散列空间有4个字节长共32位，整数范围是[0~2^32-1]；将散列结果右移m位，可产生2^(32-m)个虚拟节点，例如m=29时可产生8个虚拟节点。在实际部署的时候需要经过仔细计算得到合适的虚拟节点数，以达到存储空间和工作负载之间的平衡。 数据一致性模型（Consistency Model） 按照Eric Brewer的CAP（Consistency，Availability，Partition Tolerance）理论，无法同时满足3个方面，Swift放弃严格一致性（满足ACID 事务级别），而采用最终一致性模型（Eventual Consistency），来达到高可用性和无限水平扩展能力。为了实现这一目标，Swift采用Quorum仲裁协议（Quorum有法定投票人数的含义）： 定义：N：数据的副本总数；W：写操作被确认接受的副本数量；R：读操作的副本数量 强一致性：R+W&gt;N，以保证对副本的读写操作会产生交集，从而保证可以读取到最新版本；如果W=N，R=1，则需要全部更新，适合大量读少量写操作场景下的强一致性；如果R=N，W=1，则只更新一个副本，通过读取全部副本来得到最新版本，适合大量写少量读场景下的强一致性。 弱一致性：R+W&lt;=N，如果读写操作的副本集合不产生交集，就可能会读到脏数据；适合对一致性要求比较低的场景。 Swift针对的是读写都比较频繁的场景，所以采用了比较折中的策略，即写操作需要满足至少一半以上成功W&gt;N/2，再保证读操作与写操作的副本集合至少产生一个交集，即R+W&gt;N。Swift默认配置是N=3，W=2&gt;N/2，R=1或2，即每个对象会存在3个副本，这些副本会尽量被存储在不同区域的节点上；W=2表示至少需要更新2个副本才算写成功；当R=1时意味着某一个读操作成功便立刻返回，此种情况下可能会读取到旧版本（弱一致性模型）；当R=2时，需要通过在读操作请求头中增加x-newest=true参数来同时读取2个副本的元数据信息，然后比较时间戳来确定哪个是最新版本（强一致性模型）；如果数据出现了不一致，后台服务进程会在一定时间窗口内通过检测和复制协议来完成数据同步，从而保证达到最终一致性。如下图所示： 环的数据结构 环是为了将虚拟节点（分区）映射到一组物理存储设备上，并提供一定的冗余度而设计的，其数据结构由以下信息组成： 存储设备列表、设备信息包括唯一标识号（id）、区域号（zone）、权重（weight）、IP 地址（ip）、端口（port）、设备名称（device）、元数据（meta） 分区到设备映射关系（replica2part2dev_id 数组) 计算分区号的位移(part_shift整数，即一致性散列图中的m) 以查找一个对象的计算过程为例： 使用对象的层次结构account/container/object作为键，使用MD5散列算法得到一个散列值，对该散列值的前4个字节进行右移操作得到分区索引号，移动位数由上面的part_shift设置指定；按照分区索引号在分区到设备映射表（replica2part2dev_id）里查找该对象所在分区的对应的所有设备编号，这些设备会被尽量选择部署在不同区域（Zone）内，区域只是个抽象概念，它可以是某台机器，某个机架，甚至某个建筑内的机群，以提供最高级别的冗余性，建议至少部署5个区域；权重参数是个相对值，可以来根据磁盘的大小来调节，权重越大表示可分配的空间越多，可部署更多的分区。 Swift为账户，容器和对象分别定义了的环，查找账户和容器的是同样的过程。 数据模型 Swift采用层次数据模型，共设三层逻辑结构：Account/Container/Object（即账户/容器/对象)，每层节点数均没有限制，可以任意扩展。这里的账户和个人账户不是一个概念，可理解为租户，用来做顶层的隔离机制，可以被多个个人账户所共同使用；容器代表封装一组对象，类似文件夹或目录；叶子节点代表对象，由元数据和内容两部分组成，如下图所示： 系统架构 Swift采用完全对称、面向资源的分布式系统架构设计，所有组件都可扩展，避免因单点失效而扩散并影响整个系统运转；通信方式采用非阻塞式I/O模式，提高了系统吞吐和响应能力。 Swift 组件包括： 代理服务（Proxy Server）：对外提供对象服务API，会根据环的信息来查找服务地址并转发用户请求至相应的账户、容器或者对象服务；由于采用无状态的REST请求协议，可以进行横向扩展来均衡负载。 认证服务（Authentication Server）：验证访问用户的身份信息，并获得一个对象访问令牌（Token），在一定的时间内会一直有效；验证访问令牌的有效性并缓存下来直至过期时间。 缓存服务（Cache Server）：缓存的内容包括对象服务令牌，账户和容器的存在信息，但不会缓存对象本身的数据；缓存服务可采用Memcached集群，Swift会使用一致性散列算法来分配缓存地址。 账户服务（Account Server）：提供账户元数据和统计信息，并维护所含容器列表的服务，每个账户的信息被存储在一个SQLite数据库中。 容器服务（Container Server）：提供容器元数据和统计信息，并维护所含对象列表的服务，每个容器的信息也存储在一个SQLite数据库中。 对象服务（Object Server）：提供对象元数据和内容服务，每个对象的内容会以文件的形式存储在文件系统中，元数据会作为文件属性来存储，建议采用支持扩展属性的XFS文件系统。 复制服务（Replicator）：会检测本地分区副本和远程副本是否一致，具体是通过对比散列文件和高级水印来完成，发现不一致时会采用推式（Push）更新远程副本，例如对象复制服务会使用远程文件拷贝工具rsync来同步；另外一个任务是确保被标记删除的对象从文件系统中移除。 更新服务（Updater）：当对象由于高负载的原因而无法立即更新时，任务将会被序列化到在本地文件系统中进行排队，以便服务恢复后进行异步更新；例如成功创建对象后容器服务器没有及时更新对象列表，这个时候容器的更新操作就会进入排队中，更新服务会在系统恢复正常后扫描队列并进行相应的更新处理。 审计服务（Auditor）：检查对象，容器和账户的完整性，如果发现比特级的错误，文件将被隔离，并复制其他的副本以覆盖本地损坏的副本；其他类型的错误会被记录到日志中。 账户清理服务（Account Reaper）：移除被标记为删除的账户，删除其所包含的所有容器和对象。 API Swift通过Proxy Server向外提供基于HTTP的REST服务接口，对账户、容器和对象进行CRUD等操作。在访问Swift服务之前，需要先通过认证服务获取访问令牌，然后在发送的请求中加入头部信息X-Auth-Token。下面是请求返回账户中的容器列表的示例： 1234567891011121314GET /v1/&lt;account&gt; HTTP/1.1Host: storage.swift.comX-Auth-Token: easdfd18-0fad-4b3a-81b4-b63c95ec1cba响应头部信息中包含状态码 200，容器列表包含在响应体中：HTTP/1.1 200 OkDate: Thu, 07 Jan 2016 12:58:07 GMTServer: ApacheContent-Type: text/plain; charset=UTF-8Content-Length: 32imagesmoviesdocumentsbackups Swift支持的所有操作可以总结为下表: 资源类型 URL GET PUT POST DELETE HEAD 账户 /account/ 获取容器列表 - - - 获取账户元数据 容器 /account/container 获取对象列表 创建容器 更新容器元数据 删除容器 获取容器元数据 对象 /account/container/object 获取对象内容和元数据 创建、更新或拷贝对象 更新对象元数据 删除对象 获取对象元数据 详细的API规范可以参考开发者指南。应用开发可采用Swift项目本身已经包含的Python的绑定实现；如果使用其它编程语言，可以参考Rackspace兼容Swift的Cloud Files API，支持Java，.Net，Ruby，PHP等语言绑定。 结束语 OpenStack Swift作为稳定和高可用的开源对象存储被很多企业作为商业化部署，如新浪的App Engine已经上线并提供了基于Swift的对象存储服务，韩国电信的Ucloud Storage服务。有理由相信，因为其完全的开放性、广泛的用户群和社区贡献者，Swift可能会成为云存储的开放标准，从而打破Amazon S3在市场上的垄断地位，推动云计算在朝着更加开放和可互操作的方向前进。 EOF 本文作者：Koen 原文链接：https://www.ibm.com/developerworks/cn/cloud/library/1310_zhanghua_openstackswift/]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>Swift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在CentOS7.1上安装分布式存储系统Ceph]]></title>
    <url>%2Fck74yvgov002ddhkctst6ify1.html</url>
    <content type="text"><![CDATA[关于Ceph的介绍本文不再赘述，可以查看官方文档进行了解 Sage Weil读博士的时候开发了这套牛逼的分布式存储系统，最初是奔着高性能分布式文件系统去的，结果云计算风口一来，Ceph重心转向了分布式块存储（Block Storage）和分布式对象存储（Object Storage），现在分布式文件系统CephFS还停在beta阶段。Ceph现在是云计算、虚拟机部署的最火开源存储解决方案，据说有20%的OpenStack部署存储用的都是Ceph的Block Storage。 Ceph 提供3种存储方式：对象存储，块存储和文件系统，下图展示了Ceph存储集群的架构： 硬件环境准备 由于条件限制，本文所有实验机器全是虚拟机，共准备了3台虚拟机，其中1台做监控节点（ceph-mon），2台做存储节点（ceph-osd1，ceph-osd2）。 Ceph要求必须是奇数个监控节点，而且最少3个（自己玩玩的话，1个也是可以的），ceph-adm是可选的，可以把ceph-adm放在monitor上，只不过把ceph-adm单独拿出来架构上看更清晰一些。当然也可以把mon放在 osd上，生产环境下是不推荐这样做的。 ADM 服务器硬件配置比较随意，只是用来操作和管理 Ceph； MON 服务器1块硬盘用来安装操作系统； OSD 服务器上用4块20GB的硬盘做Ceph存储，每个osd对应1块硬盘，每个osd需要1个Journal，所以4块硬盘需要4个Journal，我们用1块20GB硬盘做journal，将硬盘等分成4个区，这样每个区分别对应一个osd硬盘的journal. 软件环境准备 所有Ceph集群节点采用CentOS7.1版本（CentOS-7-x86_64-Minimal-1503-01），所有文件系统采用Ceph官方推荐的xfs。 安装完CentOS后我们需要在每个节点上（包括ceph-adm）做一点基础配置，比如关闭SELINUX、关闭防火墙、同步时间等。 12345678910111213141516171819202122关闭 SELINUXsed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configsetenforce 0reboot关闭iptablessystemctl stop firewalldsystemctl disable firewalld安装 EPEL 软件源：rpm -Uvh https://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm同步时间yum -y ntpntpdate asia.pool.ntp.org修改/etc/hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.128.131 ceph-mon192.168.128.132 ceph-osd1192.168.128.133 ceph-osd2EOF 在每台osd服务器上对4块硬盘进行分区，创建XFS文件系统，对1块用作journal的硬盘分4个区，每个区对应一块硬盘，不需要创建文件系统，留给Ceph自己处理。 123parted -a optimal --script /dev/sdc -- mktable gptparted -a optimal --script /dev/sdc -- mkpart primary xfs 0% 100%mkfs.xfs -f /dev/sdc1 在生产环境中，每台osd服务器上硬盘远不止4台，以上命令需要对多个硬盘进行处理，重复的操作太多，以后还会陆续增加服务器，写成脚本parted.sh方便操作，其中/dev/sdc|d|e|f分别是4块硬盘，/dev/sdb是用做journal的硬盘： 1234567891011121314151617181920212223242526#!/bin/bashset -eif [ ! -x &quot;/sbin/parted&quot; ]; then echo &quot;This script requires /sbin/parted to run!&quot; &gt;&amp;2 exit 1fiDISKS=&quot;c d e f&quot;for i in $&#123;DISKS&#125;; do echo &quot;Creating partitions on /dev/sd$&#123;i&#125; ...&quot; parted -a optimal --script /dev/sd$&#123;i&#125; -- mktable gpt parted -a optimal --script /dev/sd$&#123;i&#125; -- mkpart primary xfs 0% 100% sleep 1 #echo &quot;Formatting /dev/sd$&#123;i&#125;1 ...&quot; mkfs.xfs -f /dev/sd$&#123;i&#125;1 &amp;doneJOURNALDISK=&quot;b&quot;for i in $&#123;JOURNALDISK&#125;; do parted -s /dev/sd$&#123;i&#125; mklabel gpt parted -s /dev/sd$&#123;i&#125; mkpart primary 0% 25% parted -s /dev/sd$&#123;i&#125; mkpart primary 26% 50% parted -s /dev/sd$&#123;i&#125; mkpart primary 51% 75% parted -s /dev/sd$&#123;i&#125; mkpart primary 76% 100%done 在ceph-mon上运行ssh-keygen生成ssh key文件，注意passphrase是空，把ssh key拷贝到每一个Ceph节点上： 12345678910111213141516171819202122232425[root@ceph-mon ~]# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Created directory &apos;/root/.ssh&apos;.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:36:1d:33:20:38:15:4a:8f:50:c4:94:bc:43:ef:a2:a2 root@ceph-monThe key&apos;s randomart image is:+--[ RSA 2048]----+| .*=++.. || oB+ . . || .o+. + || o . . + || o S . || . .. . || . . ||. . ||E. |+-----------------+[root@ceph-mon ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub ceph-mon[root@ceph-mon ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub ceph-osd1[root@ceph-mon ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub ceph-osd2 在ceph-mon上确保登陆到每台节点上都能无密码ssh登陆。 Ceph部署 比起在每个Ceph节点上手动安装Ceph，用ceph-deploy工具统一安装要方便得多： 1yum install ceph-deploy -y 创建一个ceph工作目录，以后的操作都在这个目录下面进行： 12[root@ceph-mon ~]# mkdir ~/ceph-cluster[root@ceph-mon ~]# cd ceph-cluster/ 初始化集群，告诉ceph-deploy哪些节点是监控节点，命令成功执行后会在ceph-cluster目录下生成ceph.conf,ceph.log,ceph.mon.keyring等相关文件： 1[root@ceph-mon ceph-cluster]# ceph-deploy new ceph-mon 在每个Ceph节点上都安装Ceph： 1[root@ceph-mon ceph-cluster]# ceph-deploy install ceph-mon ceph-osd1 ceph-osd2 此处可能出现类似如下错误： 123456[ceph-mon][ERROR ] File &quot;/usr/lib64/python2.7/subprocess.py&quot;, line 1327, in _execute_child[ceph-mon][ERROR ] raise child_exception[ceph-mon][ERROR ] OSError: [Errno 2] No such file or directory[ceph-mon][ERROR ] [ceph-mon][ERROR ] [ceph_deploy][ERROR ] RuntimeError: Failed to execute command: ceph --version 解决方法是在报错的节点上执行下面的命令： 1[root@ceph-mon ceph-cluster]# yum install *argparse* -y 初始化监控节点： 1[root@ceph-mon ceph-cluster]# ceph-deploy mon create-initial 查看一下Ceph存储节点的硬盘情况： 12[root@ceph-mon ceph-cluster]# ceph-deploy disk list ceph-osd1[root@ceph-mon ceph-cluster]# ceph-deploy disk list ceph-osd2 初始化Ceph硬盘，然后创建osd存储节点，存储节点:单个硬盘:对应的journal分区，一一对应： 1234567创建ceph-osd1存储节点[root@ceph-mon ceph-cluster]# ceph-deploy disk zap ceph-osd1:sdc ceph-osd1:sdd ceph-osd1:sde ceph-osd1:sdf[root@ceph-mon ceph-cluster]# ceph-deploy osd create ceph-osd1:sdc:/dev/sdb1 ceph-osd1:sdd:/dev/sdb2 ceph-osd1:sde:/dev/sdb3 ceph-osd1:sdf:/dev/sdb4创建ceph-osd2存储节点[root@ceph-mon ceph-cluster]# ceph-deploy disk zap ceph-osd2:sdc ceph-osd2:sdd ceph-osd2:sde ceph-osd2:sdf[root@ceph-mon ceph-cluster]# ceph-deploy osd create ceph-osd2:sdc:/dev/sdb1 ceph-osd2:sdd:/dev/sdb2 ceph-osd2:sde:/dev/sdb3 ceph-osd2:sdf:/dev/sdb4 最后，我们把生成的配置文件从ceph-adm同步部署到其他几个节点，使得每个节点的ceph配置一致： 1[root@ceph-mon ceph-cluster]# ceph-deploy --overwrite-conf admin ceph-mon ceph-osd1 ceph-osd2 测试 看一下配置成功了没？ 12[root@ceph-mon ceph-cluster]# ceph healthHEALTH_WARN 6 pgs degraded; 6 pgs stuck degraded; 64 pgs stuck unclean; 6 pgs stuck undersized; 6 pgs undersized; too few PGs per OSD (16 &lt; min 30) 增加PG数目，根据Total PGs = (#OSDs * 100) / pool size公式来决定pg_num（pgp_num应该设成和pg_num一样），所以8*100/2=400，Ceph官方推荐取最接近2的指数倍，所以选择512（若日是太大则选择256）。如果顺利的话，就应该可以看到HEALTH_OK了： 12345678910[root@ceph-mon ceph-cluster]# ceph osd pool set rbd size 2set pool 0 size to 2[root@ceph-mon ceph-cluster]# ceph osd pool set rbd min_size 2set pool 0 min_size to 2[root@ceph-mon ceph-cluster]# ceph osd pool set rbd pg_num 256set pool 0 pg_num to 256[root@ceph-mon ceph-cluster]# ceph osd pool set rbd pgp_num 256set pool 0 pgp_num to 256[root@ceph-mon ceph-cluster]# ceph healthHEALTH_OK 更详细一点： 123456789[root@ceph-mon ceph-cluster]# ceph -s cluster 38a7726b-6018-41f4-83c2-911b325116df health HEALTH_OK monmap e1: 1 mons at &#123;ceph-mon=192.168.128.131:6789/0&#125; election epoch 2, quorum 0 ceph-mon osdmap e46: 8 osds: 8 up, 8 in pgmap v72: 256 pgs, 1 pools, 0 bytes data, 0 objects 276 MB used, 159 GB / 159 GB avail 256 active+clean 如果操作没有问题的话记得把上面操作写到ceph.conf文件里，并同步部署的各节点： 12345[root@ceph-mon ceph-cluster]# echo &quot;osd pool default size = 2&quot; &gt;&gt; ~/ceph-cluster/ceph.conf[root@ceph-mon ceph-cluster]# echo &quot;osd pool default min size = 2&quot; &gt;&gt; ~/ceph-cluster/ceph.conf[root@ceph-mon ceph-cluster]# echo &quot;osd pool default pg num = 256&quot; &gt;&gt; ~/ceph-cluster/ceph.conf[root@ceph-mon ceph-cluster]# echo &quot;osd pool default pgp num = 256&quot; &gt;&gt; ~/ceph-cluster/ceph.conf[root@ceph-mon ceph-cluster]# ceph-deploy --overwrite-conf admin ceph-mon ceph-osd1 ceph-osd2 如果一切可以重来 部署过程中如果出现任何奇怪的问题无法解决，可以简单的删除一切从头再来： 123[root@ceph-mon ceph-cluster]# ceph-deploy purge ceph-mon ceph-osd1 ceph-osd2[root@ceph-mon ceph-cluster]# ceph-deploy purgedata ceph-mon ceph-osd1 ceph-osd2[root@ceph-mon ceph-cluster]# ceph-deploy forgetkeys Troubelshooting 如果出现任何网络问题，首先确认节点可以互相无密码ssh，各个节点的防火墙已关闭或加入规则 EOF 本文作者：Koen 参考链接：http://www.vpsee.com/2015/07/install-ceph-on-centos-7/]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB Galera Cluster 部署]]></title>
    <url>%2Fck74yvgog0010dhkc5nw51gi6.html</url>
    <content type="text"><![CDATA[MariaDB作为Mysql的一个分支，在开源项目中已经广泛使用，例如大热的openstack，所以，为了保证服务的高可用性，同时提高系统的负载能力，集群部署是必不可少的。 MariaDB Galera Cluster 介绍 MariaDB集群是MariaDB同步多主机集群。它仅支持XtraDB/ InnoDB存储引擎（虽然有对MyISAM实验支持 - 看wsrep_replicate_myisam系统变量）。 主要功能 同步复制 真正的multi-master，即所有节点可以同时读写数据库 自动的节点成员控制，失效节点自动被清除 新节点加入数据自动复制 真正的并行复制，行级 用户可以直接连接集群，使用感受上与MySQL完全一致 优势 因为是多主，所以不存在Slavelag(延迟) 不存在丢失事务的情况 同时具有读和写的扩展能力 更小的客户端延迟 节点间数据是同步的,而Master/Slave模式是异步的,不同slave上的binlog可能是不同的 技术 Galera集群的复制功能基于Galeralibrary实现,为了让MySQL与Galera library通讯，特别针对MySQL开发了wsrep API。 Galera插件保证集群同步数据，保持数据的一致性，靠的就是可认证的复制，工作原理如下图： 当客户端发出一个commit的指令，在事务被提交之前，所有对数据库的更改都会被write-set收集起来,并且将write-set纪录的内容发送给其他节点。 write-set将在每个节点进行认证测试，测试结果决定着节点是否应用write-set更改数据。 如果认证测试失败，节点将丢弃write-set；如果认证测试成功，则事务提交。 MariaDB Galera Cluster 安装配置 安装环境准备安装MariaDB集群至少需要3台服务器（如果只有两台的话需要特殊配置，请参照官方文档） 操作系统版本：CentOS7.1（CentOS-7-x86_64-Minimal-1503-01） 在三台机器上修改/etc/hosts文件： 12345cat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.128.131 node1192.168.128.132 node2192.168.128.133 node3EOF 为了保证节点间相互通信，需要禁用三台机器的防火墙设置（如果需要防火墙，则参照官方网站增加防火墙信息设置） 12systemctl stop firewalldsystemctl disable firewalld 然后将/etc/sysconfig/selinux的selinux设置成disabled并重启机器,这样初始化环境就完成了。 安装MariaDB Galera Cluster在MariaDB Repository Generator选择对应的系统版本和MariaDB版本，复制相应的yum源配置到/etc/yum.repos.d/MariaDB.repo 123[root@node1 ~]# yum install -y MariaDB-Galera-server galera rsync MariaDB-client[root@node2 ~]# yum install -y MariaDB-Galera-server galera rsync MariaDB-client[root@node3 ~]# yum install -y MariaDB-Galera-server galera rsync MariaDB-client 配置 MariaDB Galera Cluster 初始化数据库服务（只在一个节点进行，然后关闭数据库） 12[root@node1 ~]# service mysql start[root@node1 ~]# service mysql stop 修改/etc/my.cnf.d/galera.cnf 123456[root@node1 ~]# cat /etc/my.cnf.d/galera.cnf[mysqld]wsrep_provider = /usr/lib64/galera/libgalera_smm.sowsrep_cluster_address = &quot;gcomm://node1,node2,node3&quot;wsrep_node_name = node1wsrep_node_address = 192.168.128.131 将此文件复制到node2、node3，注意要把wsrep_node_name和wsrep_node_address改成相应节点的hostname和ip。 启动MariaDB Galera Cluster服务1[root@node1 ~]# mysqld --wsrep-new-cluster --user=root &amp; 此时会出现如下报错： 1160907 17:05:55 [ERROR] WSREP: Only binlog_format = &apos;ROW&apos; is currently supported. Configured value: &apos;STATEMENT&apos;. Please adjust your configuration 解决方法： 在/etc/my.cnf.d/galera.cnf中添加一行binlog_format=ROW 在输出信息中看到类似如下信息证明启动成功，继续启动其他节点： 12345160907 17:09:08 [Note] mysqld: ready for connections.Version: &apos;5.5.51-MariaDB-wsrep&apos; socket: &apos;/var/lib/mysql/mysql.sock&apos; port: 3306 MariaDB Server, wsrep_25.14.r9949137`[root@node2 ~]# service mysql start[root@node3 ~]# service mysql start 注：--wsrep-new-cluster这个参数只能在初始化集群使用，且只能在一个节点使用。 查看集群状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@node1 ~]# mysql -e &apos;show status like &quot;wsrep_%&quot;&apos;+------------------------------+----------------------------------------------------------------+| Variable_name | Value |+------------------------------+----------------------------------------------------------------+| wsrep_local_state_uuid | bb27d68e-74da-11e6-8aa4-469f840e1e54 || wsrep_protocol_version | 7 || wsrep_last_committed | 0 || wsrep_replicated | 0 || wsrep_replicated_bytes | 0 || wsrep_repl_keys | 0 || wsrep_repl_keys_bytes | 0 || wsrep_repl_data_bytes | 0 || wsrep_repl_other_bytes | 0 || wsrep_received | 7 || wsrep_received_bytes | 699 || wsrep_local_commits | 0 || wsrep_local_cert_failures | 0 || wsrep_local_replays | 0 || wsrep_local_send_queue | 0 || wsrep_local_send_queue_max | 1 || wsrep_local_send_queue_min | 0 || wsrep_local_send_queue_avg | 0.000000 || wsrep_local_recv_queue | 0 || wsrep_local_recv_queue_max | 2 || wsrep_local_recv_queue_min | 0 || wsrep_local_recv_queue_avg | 0.142857 || wsrep_local_cached_downto | 18446744073709551615 || wsrep_flow_control_paused_ns | 0 || wsrep_flow_control_paused | 0.000000 || wsrep_flow_control_sent | 0 || wsrep_flow_control_recv | 0 || wsrep_cert_deps_distance | 0.000000 || wsrep_apply_oooe | 0.000000 || wsrep_apply_oool | 0.000000 || wsrep_apply_window | 0.000000 || wsrep_commit_oooe | 0.000000 || wsrep_commit_oool | 0.000000 || wsrep_commit_window | 0.000000 || wsrep_local_state | 4 || wsrep_local_state_comment | Synced || wsrep_cert_index_size | 0 || wsrep_causal_reads | 0 || wsrep_cert_interval | 0.000000 || wsrep_incoming_addresses | 192.168.128.131:3306,192.168.128.132:3306,192.168.128.133:3306 || wsrep_desync_count | 0 || wsrep_evs_delayed | || wsrep_evs_evict_list | || wsrep_evs_repl_latency | 0/0/0/0/0 || wsrep_evs_state | OPERATIONAL || wsrep_gcomm_uuid | bb2686c8-74da-11e6-9cde-5fd4f88f878c || wsrep_cluster_conf_id | 3 || wsrep_cluster_size | 3 || wsrep_cluster_state_uuid | bb27d68e-74da-11e6-8aa4-469f840e1e54 || wsrep_cluster_status | Primary || wsrep_connected | ON || wsrep_local_bf_aborts | 0 || wsrep_local_index | 2 || wsrep_provider_name | Galera || wsrep_provider_vendor | Codership Oy &lt;info@codership.com&gt; || wsrep_provider_version | 25.3.17(r3619) || wsrep_ready | ON || wsrep_thread_count | 2 |+------------------------------+----------------------------------------------------------------+ 几个关键参数 wsrep_connected = on 链接已开启 wsrep_local_index = 2 在集群中的索引值 wsrep_cluster_size =3 集群中节点的数量 wsrep_incoming_addresses = 192.168.128.131:3306,192.168.128.132:3306,192.168.128.133:3306 集群中节点的访问地址 验证数据同步在node1上新建数据库galera_koen,然后在node2和node3上查询，如果可以查询到galera_koen这个库，说明数据同步成功，集群运行正常。 1234567891011121314151617181920212223[root@node1 ~]# mysql -e &quot;create database galera_koen&quot;[root@node2 ~]# mysql -e &quot;show databases;&quot;+--------------------+| Database |+--------------------+| information_schema || galera_koen || mysql || performance_schema || test |+--------------------+[root@node3 ~]# mysql -e &quot;show databases;&quot;+--------------------+| Database |+--------------------+| information_schema || galera_koen || mysql || performance_schema || test |+--------------------+ 至此，MariaDB Galera Cluster已经成功部署。 EOF 本文作者：Koen 参考链接：http://code.oneapm.com/database/2015/07/02/mariadb-galera-cluster/]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python操作MySQL数据库]]></title>
    <url>%2Fck74yvgom001ndhkco67en2qq.html</url>
    <content type="text"><![CDATA[Python DB API https://www.python.org/dev/peps/pep-0249/ Python DB API是Python官方提供的一套访问数据库的统一接口规范 在没有Python DB API之前，Python访问数据库的接口程序混乱，当要对业务使用的数据库进行切换时，需要对Python应用程序进行大量的更改，迁移成本相当的高，因此Python官方提供了一套访问数据库的统一接口规范，实现了Python应用程序对多种数据库访问方式的统一。 Python DB API包含的内容 使用Python DB API访问数据库的流程 Python开发MySQL环境的配置 Python2 下载MySQL-Python并安装，安装程序会自动检测Python客户端的位置： https://sourceforge.net/projects/mysql-python/# Python3 12pip install PyMySQLpip isntall PyMySQL3 数据库连接对象Connection 连接对象：建立Python客户端与数据库的网络连接 创建方法：MySQLdb.Connect(参数)/pymysql.connect(参数) 参数名 类型 说明 host 字符串 MySQL服务器地址 port 数字 MySQL服务器端口号 user 字符串 用户名 passwd 字符串 密码 db 字符串 数据库名称 charset 字符串 连接编码 connection对象支持的方法 方法名 说明 cursor() 使用该连接创建并返回游标 commit() 提交当前事务 rollback() 回滚当前事务 close() 关闭连接 示例代码 1create database test 123456789101112import pymysqlconn = pymysql.connect( host=&apos;127.0.0.1&apos;, port = 3306, user=&apos;root&apos;, passwd=&apos;westos&apos;, charset=&apos;utf8&apos;, db=&apos;test&apos;)print(conn) 游标对象Cursor 游标对象：用于执行查询和获取结果 Cursor对象支持的方法： 参数名 说明 execute(op[,args]) 执行一个数据库查询或命令 fetchone() 取的结果集的下一行 fetchmany(size) 获取结果集的下几行 fetchall() 获取结果集中剩下的所有行 rowcount 最近一次execute返回数据的行数或影响行数 close() 关闭游标对象 演示select数据 流程 示例代码 123456789101112131415use testcreate table user ( userid int not null auto_increment, username varchar(100), primary key(userid))engine=innodb auto_increment=1 default charset=&apos;utf8&apos;;insert into user(userid,username) values(1,&apos;NAME1&apos;);insert into user(userid,username) values(2,&apos;NAME2&apos;);insert into user(userid,username) values(3,&apos;NAME3&apos;);insert into user(userid,username) values(4,&apos;NAME4&apos;);insert into user(userid,username) values(5,&apos;NAME5&apos;);insert into user(userid,username) values(6,&apos;NAME6&apos;);insert into user(userid,username) values(7,&apos;NAME7&apos;);insert into user(userid,username) values(8,&apos;NAME8&apos;);insert into user(userid,username) values(9,&apos;NAME9&apos;); 12345678910111213141516171819202122import pymysqlconn = pymysql.connect( host=&apos;127.0.0.1&apos;, port = 3306, user=&apos;root&apos;, passwd=&apos;westos&apos;, charset=&apos;utf8&apos;, db=&apos;test&apos;)cur = conn.cursor()sql = &quot;select * from user&quot;cur.execute(sql)rs = cur.fetchall()for row in rs: print(&quot;userid=%s,username=%s&quot; %row)cur.close()conn.close() 事务 事务:访问和更新数据库的一个程序执行单元 原子性：事务中包括的诸操作要么都做，要么都不做 一致性：事务必须使数据库从一致性状态变到另一个一致性状态 隔离性：一个事务的执行不能被其他事务干扰 持久性：事务一旦提交，它对数据库的改变就是永久的 注意：开发过程中一般关闭自动提交事务功能，设置conn.autocommit(False) 演示insert/update/delete数据 流程 示例代码 123456789101112131415use testcreate table user ( userid int not null auto_increment, username varchar(100), primary key(userid))engine=innodb auto_increment=1 default charset=&apos;utf8&apos;;insert into user(userid,username) values(1,&apos;NAME1&apos;);insert into user(userid,username) values(2,&apos;NAME2&apos;);insert into user(userid,username) values(3,&apos;NAME3&apos;);insert into user(userid,username) values(4,&apos;NAME4&apos;);insert into user(userid,username) values(5,&apos;NAME5&apos;);insert into user(userid,username) values(6,&apos;NAME6&apos;);insert into user(userid,username) values(7,&apos;NAME7&apos;);insert into user(userid,username) values(8,&apos;NAME8&apos;);insert into user(userid,username) values(9,&apos;NAME9&apos;); 12345678910111213141516171819202122232425262728293031import pymysqlconn = pymysql.connect( host=&apos;127.0.0.1&apos;, port = 3306, user=&apos;root&apos;, passwd=&apos;westos&apos;, charset=&apos;utf8&apos;, db=&apos;test&apos;)cur = conn.cursor()sql_insert = &quot;insert into user(userid,username) values(10,&apos;name10&apos;)&quot;sql_update = &quot;update user set username=&apos;name91&apos; where userid=9&quot;sql_delete = &quot;delete from user where userid&lt;3&quot;try: cur.execute(sql_insert) print(cur.rowcount) cur.execute(sql_update) print(cur.rowcount) cur.execute(sql_delete) print(cur.rowcount) conn.commit()except Exception as e: print(e) conn.rollback()cur.close()conn.close() 银行转账实例——账户A给账户B转账100元 流程 示例代码 1234567create table account ( accountid int, money int, primary key(accountid))engine=innodb default charset=&apos;utf8&apos;;insert into account(accountid,money) values(11,110);insert into account(accountid,money) values(12,10); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# -*- coding:UTF8 -*-import pymysqlimport sysclass TransferMoney(object): def __init__(self,conn): self.conn = conn def check_acct_available(self,accountid): cur = self.conn.cursor() try: sql = &quot;select * from account where accountid=%s&quot; %accountid cur.execute(sql) print(&quot;check_acct_available:&quot;+sql) rs = cur.fetchall() if len(rs) != 1: raise Exception(&quot;账号%s不存在&quot; %accountid) finally: cur.close() def has_enough_money(self,source_accountid,money): cur = self.conn.cursor() try: sql = &quot;select * from account where accountid=%s and money&gt;=%s&quot; % (source_accountid,money) cur.execute(sql) print(&quot;have_enought_money:&quot;+sql) rs = cur.fetchall() if len(rs) != 1: raise Exception(&quot;账号%s没有足够的钱&quot; % source_accountid) finally: cur.close() def reduce_money(self,source_accountid,money): cur = self.conn.cursor() try: sql = &quot;update account set money=money-%s where accountid=%s&quot; % (money,source_accountid) cur.execute(sql) print(&quot;reduce_money:&quot;+sql) if cur.rowcount != 1: raise Exception(&quot;账号%s减款失败&quot; % source_accountid) finally: cur.close() def add_money(self,target_account,money): cur = self.conn.cursor() try: sql = &quot;update account set money=money+%s where accountid=%s&quot; % (money, target_account) cur.execute(sql) print(&quot;add_money:&quot; + sql) if cur.rowcount != 1: raise Exception(&quot;账号%s加法失败&quot; % target_account) finally: cur.close() def transfer(self,source_accountid,target_account,money): try: self.check_acct_available(source_accountid) #self.check_acct_available(target_account) self.has_enough_money(source_accountid,money) self.reduce_money(source_accountid,money) self.add_money(target_account,money) self.conn.commit() except Exception as e: self.conn.rollback() raise eif __name__ == &quot;__main__&quot;: source_accountid = sys.argv[1] target_accountid = sys.argv[2] money = sys.argv[3] conn = pymysql.connect( host=&apos;127.0.0.1&apos;, port = 3306, user=&apos;root&apos;, passwd=&apos;westos&apos;, charset=&apos;utf8&apos;, database=&apos;test&apos; ) tr_money = TransferMoney(conn) try: tr_money.transfer(source_accountid,target_accountid,money) except Exception as e: print(&quot;出现问题：&quot;+str(e)) finally: conn.close() 执行结果： G:\PythonProject\python-mysql&gt;python connmysql.py 11 12 100 check_acct_available:select * from account where accountid=11 have_enought_money:select * from account where accountid=11 and money&gt;=100 reduce_money:update account set money=money-100 where accountid=11 add_money:update account set money=money+100 where accountid=12 EOF 本文作者：Koen 参考链接：http://www.imooc.com/learn/475]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask——电子邮件]]></title>
    <url>%2Fck74yvgo9000hdhkcb532frw8.html</url>
    <content type="text"><![CDATA[很多类型的应用程序需要在特定事件发生时提醒用户，而常用的通信方法是电子邮件。虽然Python标准库中的smtplib包可用在Flask程序中发送电子邮件，但包装了smtplib的Flask-Mail扩展能更好地和Flask集成。 使用Flask-Mail提供电子邮件支持 使用pip安装Flask-Mail： 1(env) [root@server1 myproject]# pip install flask-mail Flask-Mail的初始化方法如下： 12from flask.ext.mail import Mailmail = Mail(app) Flask-Mail连接到简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）服务器，并把邮件交给这个服务器发送。如果不进行配置，Flask-Mail会连接localhost上的端口25，无需验证即可发送电子邮件。下表列出了可用来设置SMTP服务器的配置。 Flask-Mail SMTP服务器的配置 配置 默认值 说明 MAIL_SERVER localhost 电子邮件服务器的主机名或IP地址 MAIL_PORT 25 电子邮件服务器的端口 MAIL_USE_TLS False 启用传输层安全（Transport Layer Security，TLS）协议 MAIL_USE_SSL False 启用安全套接层（Secure Sockets Layer，SSL）协议 MAIL_USERNAME None 邮件账户的用户名 MAIL_PASSWORD None 邮件账户的密码 在开发过程中，如果连接到外部SMTP服务器，则可能更方便。下面这个例子展示了如何配置程序，以便使用QQ邮箱账户发送电子邮件。 run.py：配置Flask-Mail使用QQ邮箱 1234567891011121314151617from flask import Flaskfrom flask.ext.mail import Mailfrom flask.ext.script import Managerimport osapp = Flask(__name__)app.config[&apos;MAIL_SERVER&apos;] = &apos;smtp.qq.com&apos;app.config[&apos;MAIL_PORT&apos;] = 465 app.config[&apos;MAIL_USE_SSL&apos;] = Trueapp.config[&apos;MAIL_USERNAME&apos;] = os.environ.get(&apos;MAIL_USERNAME&apos;)app.config[&apos;MAIL_PASSWORD&apos;] = os.environ.get(&apos;MAIL_PASSWORD&apos;)mail = Mail(app)manager = Manager(app)if __name__ == &quot;__main__&quot;: manager.run() 注意：千万不要把账户密令直接写入脚本，特别是当你计划开源自己的作品时。为了保护账户信息，你需要让脚本从环境中导入敏感信息。 保护电子邮件服务器用户名和密码的两个环境变量要在环境中定义。如果你在Linux或Mac OS X中使用bash，那么可以按照下面的方式设定这两个变量： 12(env) [root@server1 myproject]# export MAIL_USERNAME=&lt;qq-mail username&gt;(env) [root@server1 myproject]# export MAIL_PASSWORD=&lt;qq-mail password&gt; 微软Windows用户可按照下面的方式设定环境变量： 12(env) $ set MAIL_USERNAME=&lt;qq-mail username&gt;(env) $ set MAIL_PASSWORD=&lt;qq-mail password&gt; 在Python shell中发送电子邮件 你可以打开一个shell会话，发送一封测试邮件，以检查配置是否正确： 注意：发送测试邮件前，请先在你的邮箱设置中打开POP3/SMTP服务，获取授权码，具体步骤请参考http://service.mail.qq.com/cgi-bin/help?subtype=1&amp;&amp;no=1001256&amp;&amp;id=28 12345678(env) [root@server1 myproject]# python run.py shell&gt;&gt;&gt; from flask.ext.mail import Message&gt;&gt;&gt; from run import mail&gt;&gt;&gt; msg = Message(&apos;Hello Koen&apos;,sender=&apos;you@example.com&apos;,recipients=[&apos;you@example.com&apos;])&gt;&gt;&gt; msg.body = &apos;Hello Koen&apos;&gt;&gt;&gt; msg.html = &apos;&lt;h1&gt;Hello Koen!&lt;/h1&gt;&apos;&gt;&gt;&gt; with app.app_context():... mail.send(msg) 注意：Flask-Mail中的send()函数使用current_app,因此要在激活的程序上下文中执行。 在程序中集成发送电子邮件功能 为了避免每次都手动编写电子邮件消息，我们最好把程序发送电子邮件的通用部分抽象出来，定义成一个函数。这么做还有个好处，即该函数可以使用Jinja2模板渲染邮件正文，灵活性极高。 1234567891011from flask.ext.mail import Messageapp.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] = &apos;[Flasky]&apos;app.config[&apos;FLASKY_MAIL_SENDER&apos;] = &apos;Flasky Admin &lt;flasky@example.com&gt;&apos;def send_email(to, subject, template, **kwargs): msg = Message(app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] + &apos; &apos; + subject, sender=app.config[&apos;FLASKY_MAIL_SENDER&apos;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) msg.html = render_template(template + &apos;.html&apos;, **kwargs) mail.send(msg) 这个函数用到了两个程序特定配置项，分别定义邮件主题的前缀和发件人的地址。send_email()函数的参数分别为收件人地址、主题、渲染邮件正文的模板和关键字参数列表。指定模板时不要包含扩展名，这样才能使用两个模板分别渲染纯文本正文和富文本正文。调用者将关键字参数传给render_template()函数，以便在模板中使用，进而生成电子邮件正文。 index()视图函数很容易被扩展，这样每当表单接收新名字时，程序都会给管理员发送一封电子邮件。 run.py：电子邮件示例 1234567891011121314151617181920app.config[&apos;FLASKY_ADMIN&apos;] = os.environ.get(&apos;FLASKY_ADMIN&apos;)@app.route(&apos;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() if user is None: user = User(username=form.name.data) db.session.add(user) session[&apos;known&apos;] = False if app.config[&apos;FLASKY_ADMIN&apos;]: send_email(app.config[&apos;FLASKY_ADMIN&apos;], &apos;New User&apos;, &apos;mail/new_user&apos;, user=user) else: session[&apos;known&apos;] = True session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;, form=form, name=session.get(&apos;name&apos;), known=session.get(&apos;known&apos;, False)) 电子邮件的收件人保存在环境变量FLASKY_ADMIN中，在程序启动过程中，它会加载到一个同名配置变量中。我们要创建两个模板文件，分别用于渲染纯文本和HTML版本的邮件正文。这两个模板文件都保存在templates文件夹下的mail子文件夹中，以便和普通模板区分开来。电子邮件的模板中要有一个模板参数是用户，因此调用send_email()函数时要以关键字参数的形式传入用户。 完整的run.py如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import osfrom flask import Flask, render_template, session, redirect, url_forfrom flask.ext.script import Manager, Shellfrom flask.ext.bootstrap import Bootstrapfrom flask.ext.moment import Momentfrom flask.ext.wtf import Formfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import Requiredfrom flask.ext.sqlalchemy import SQLAlchemyfrom flask.ext.migrate import Migrate, MigrateCommandfrom flask.ext.mail import Mail, Messagebasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] =\ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;)app.config[&apos;SQLALCHEMY_COMMIT_ON_TEARDOWN&apos;] = Trueapp.config[&apos;MAIL_SERVER&apos;] = &apos;smtp.qq.com&apos;app.config[&apos;MAIL_PORT&apos;] = 465app.config[&apos;MAIL_USE_SSL&apos;] = Trueapp.config[&apos;MAIL_USERNAME&apos;] = os.environ.get(&apos;MAIL_USERNAME&apos;)app.config[&apos;MAIL_PASSWORD&apos;] = os.environ.get(&apos;MAIL_PASSWORD&apos;)app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] = &apos;[Flasky]&apos;app.config[&apos;FLASKY_MAIL_SENDER&apos;] = &apos;Flasky Admin &lt;flasky@example.com&gt;&apos;app.config[&apos;FLASKY_ADMIN&apos;] = os.environ.get(&apos;FLASKY_ADMIN&apos;)manager = Manager(app)bootstrap = Bootstrap(app)moment = Moment(app)db = SQLAlchemy(app)migrate = Migrate(app, db)mail = Mail(app)class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;, lazy=&apos;dynamic&apos;) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.usernamedef send_email(to, subject, template, **kwargs): msg = Message(app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] + &apos; &apos; + subject, sender=app.config[&apos;FLASKY_MAIL_SENDER&apos;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) msg.html = render_template(template + &apos;.html&apos;, **kwargs) mail.send(msg)class NameForm(Form): name = StringField(&apos;What is your name?&apos;, validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)def make_shell_context(): return dict(app=app, db=db, User=User, Role=Role)manager.add_command(&quot;shell&quot;, Shell(make_context=make_shell_context))manager.add_command(&apos;db&apos;, MigrateCommand)@app.route(&apos;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() if user is None: user = User(username=form.name.data) db.session.add(user) session[&apos;known&apos;] = False if app.config[&apos;FLASKY_ADMIN&apos;]: send_email(app.config[&apos;FLASKY_ADMIN&apos;], &apos;New User&apos;, &apos;mail/new_user&apos;, user=user) else: session[&apos;known&apos;] = True session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;, form=form, name=session.get(&apos;name&apos;), known=session.get(&apos;known&apos;, False))if __name__ == &apos;__main__&apos;: manager.run() templates/base.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#123;% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block head %&#125;&#123;&#123; super() &#125;&#125;&lt;link rel=&quot;shortcut icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;, filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&lt;link rel=&quot;icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;, filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-target=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &#123;% for message in get_flashed_messages() %&#125; &lt;div class=&quot;alert alert-warning&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt; &#123;&#123; message &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% block page_content %&#125;&#123;% endblock %&#125;&lt;/div&gt;&#123;% endblock %&#125;&#123;% block scripts %&#125;&#123;&#123; super() &#125;&#125;&#123;&#123; moment.include_moment() &#125;&#125;&#123;% endblock %&#125; templates/index.html 12345678910111213141516&#123;% extends &quot;base.html&quot; %&#125;&#123;% import &quot;bootstrap/wtf.html&quot; as wtf %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello, &#123;% if name %&#125;&#123;&#123; name &#125;&#125;&#123;% else %&#125;Stranger&#123;% endif %&#125;!&lt;/h1&gt; &#123;% if not known %&#125; &lt;p&gt;Pleased to meet you!&lt;/p&gt; &#123;% else %&#125; &lt;p&gt;Happy to see you again!&lt;/p&gt; &#123;% endif %&#125;&lt;/div&gt;&#123;&#123; wtf.quick_form(form) &#125;&#125;&#123;% endblock %&#125; templates/mail/new_user.txt 1User &#123;&#123; user.username &#125;&#125; has joined. templates/mail/new_user.html 1User &lt;b&gt;&#123;&#123; user.username &#125;&#125;&lt;/b&gt; has joined. 除了前面提到的环境变量MAIL_USERNAME和MAIL_PASSWORD之外，这个版本的程序还需要使用环境变量FLASKY_ADMIN。Linux和Mac OS X用户可使用下面的命令添加： 1(env) [root@server1 myproject]# export FLASKY_ADMIN=&lt;your-email-address&gt; 对微软Windows用户来说，等价的命令是： 1(env) $ set FLASKY_ADMIN=&lt;your-email-address&gt; 设置好这些环境变量后，我们就可以测试程序了。每次你在表单中填写新名字时，管理员都会收到一封电子邮件。 异步发送电子邮件如果你发送了几封测试邮件，可能会注意到mail.send()函数在发送电子邮件时停滞了几秒钟，在这个过程中浏览器就像无响应一样。为了避免处理请求过程中不必要的延迟，我们可以把发送电子邮件的函数移到后台线程中。 run.py：异步发送电子邮件 123456789101112131415from threading import Threaddef send_async_email(app, msg): with app.app_context(): mail.send(msg)def send_email(to, subject, template, **kwargs): msg = Message(app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] + &apos; &apos; + subject, sender=app.config[&apos;FLASKY_MAIL_SENDER&apos;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) msg.html = render_template(template + &apos;.html&apos;, **kwargs) thr = Thread(target=send_async_email, args=[app, msg]) thr.start() return thr 上述实现涉及一个有趣的问题。很多Flask扩展都假设已经存在激活的程序上下文和请求上下文。Flask-Mail中的send()函数使用current_app，因此必须激活程序上下文。不过，在不同线程中执行mail.send()函数时，程序上下文要使用app.app_context()人工创建。 现在再运行程序，你会发现程序流畅多了。不过要记住，程序要发送大量电子邮件时，使用专门发送电子邮件的作业要比给每封邮件都新建一个线程要合适。例如，我们可以把执行send_async_email()函数的操作发给Celery（http://www.celeryproject.org/）任务队列。 完整的run.py如下，其他模板文件不变： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import osfrom threading import Threadfrom flask import Flask, render_template, session, redirect, url_forfrom flask.ext.script import Manager, Shellfrom flask.ext.bootstrap import Bootstrapfrom flask.ext.moment import Momentfrom flask.ext.wtf import Formfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import Requiredfrom flask.ext.sqlalchemy import SQLAlchemyfrom flask.ext.migrate import Migrate, MigrateCommandfrom flask.ext.mail import Mail, Messagebasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] =\ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;)app.config[&apos;SQLALCHEMY_COMMIT_ON_TEARDOWN&apos;] = Trueapp.config[&apos;MAIL_SERVER&apos;] = &apos;smtp.qq.com&apos;app.config[&apos;MAIL_PORT&apos;] = 465 app.config[&apos;MAIL_USE_SSL&apos;] = Trueapp.config[&apos;MAIL_USERNAME&apos;] = os.environ.get(&apos;MAIL_USERNAME&apos;)app.config[&apos;MAIL_PASSWORD&apos;] = os.environ.get(&apos;MAIL_PASSWORD&apos;)app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] = &apos;[Flasky]&apos;app.config[&apos;FLASKY_MAIL_SENDER&apos;] = &apos;379148058@qq.com&apos;app.config[&apos;FLASKY_ADMIN&apos;] = os.environ.get(&apos;FLASKY_ADMIN&apos;)manager = Manager(app)bootstrap = Bootstrap(app)moment = Moment(app)db = SQLAlchemy(app)migrate = Migrate(app, db)mail = Mail(app)class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;, lazy=&apos;dynamic&apos;) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.usernamedef send_async_email(app, msg): with app.app_context(): mail.send(msg)def send_email(to, subject, template, **kwargs): msg = Message(app.config[&apos;FLASKY_MAIL_SUBJECT_PREFIX&apos;] + &apos; &apos; + subject, sender=app.config[&apos;FLASKY_MAIL_SENDER&apos;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) msg.html = render_template(template + &apos;.html&apos;, **kwargs) thr = Thread(target=send_async_email, args=[app, msg]) thr.start() return thrclass NameForm(Form): name = StringField(&apos;What is your name?&apos;, validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)def make_shell_context(): return dict(app=app, db=db, User=User, Role=Role)manager.add_command(&quot;shell&quot;, Shell(make_context=make_shell_context))manager.add_command(&apos;db&apos;, MigrateCommand)@app.route(&apos;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() if user is None: user = User(username=form.name.data) db.session.add(user) session[&apos;known&apos;] = False if app.config[&apos;FLASKY_ADMIN&apos;]: send_email(app.config[&apos;FLASKY_ADMIN&apos;], &apos;New User&apos;, &apos;mail/new_user&apos;, user=user) else: session[&apos;known&apos;] = True session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;, form=form, name=session.get(&apos;name&apos;), known=session.get(&apos;known&apos;, False))if __name__ == &apos;__main__&apos;: manager.run() 至此，我们已经完成了对大多数Web程序所需功能的概述。 EOF 本文作者：Koen 参考书籍：《Flask Web开发——基于Python的Web应用开发实战》]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask——数据库]]></title>
    <url>%2Fck74yvgo6000cdhkcayyl4exc.html</url>
    <content type="text"><![CDATA[数据库按照一定规则保存程序数据，程序再发起查询取回所需的数据。Web程序最常用基于关系模型的数据库，这种数据库也称为SQL数据库，因为它们使用结构化查询语句。不过最近几年文档数据库和键值对数据库成了流行的替代选择，这两种数据库合称NoSQL数据库。 SQL数据库 关系型数据库把数据存储在表中，表模拟程序中不同的实体。例如，订单管理程序的数据库中可能有表customers、products和orders。 表的列数是固定的，行数是可变的。列定义表所表示的实体的数据属性。例如，customers表中可能有name、address、phone表列。表中的行定义各列对应的真实数据。 表中有个特殊的列，称为主键，其值为表中各行的唯一标识符。表中还可以有称为外键的列，引用同一个表或不同表中某行的主键。行之间的这种联系称为关系，这是关系型数据库模型的基础。图1展示了一个简单数据库的关系图。这个数据库中有两个表，分别存储用户和用户角色。连接两个表的线代表两个表之间的关系。 图1 关系型数据库示例 在这个数据库关系图中，roles表存储所有可用的用户角色，每个角色都使用一个唯一的id值（即表的主键）进行标识。users表包含用户列表，每个用户也有唯一的id值。除了id主键之外，roles表中还有name列，users表中还有username列和password列。users表中的role_id列是外键，引用角色的id，通过这种方式为每个指定角色。 从这个例子可以看出，关系型数据库存储数据很高效，而且避免了重复。将这个数据库中的用户角色重命名也很简单，因为角色名只出现在一个地方。一旦在roles表中修改完角色名，所有通过role_id引用这个角色的用户都能立即看到更新。 但从另一方面来看，把数据分别存放在多个表中还是很复杂的。生成一个包含角色的用户列表会遇到一个小问题，因为在此之前要分别从两个表中读取用户和用户角色，再将其联结起来。关系型数据库引擎为联结操作提供了必要的支持。 NoSQL数据库 所有不遵循上节所述的关系模型的数据库统称为NoSQL数据库。NoSQL数据库一般使用集合代替表，使用文档代替记录。NoSQL数据库采用的设计方式使联结变得困难，所以大多数数据库根本不支持这种操作。对于结构如图1所示的关系型数据库，若要列出各用户及其角色，就需要在程序中执行联结操作，即先读取每个用户的role_id，再在roles表中搜索对应的记录。 NoSQL数据库更适合设计成如图2所示的结构。这是执行反规范化操作得到的结果，它减少了表的数量，却增加了数据重复量。 图2 NoSQL数据库示例 这种结构的数据库要把角色名存储在每个用户中。如此一来，将角色重命名的操作就变得很耗时，可能需要更新大量文档。 使用NoSQL数据库当然也有好处。数据重复可以提升查询速度。列出用户及其角色的操作很简答，因为无需联结。 使用SQL还是NoSQL SQL数据库擅长于用高效且紧凑的形式存储结构化数据。这种数据库需要花费大量精力保证数据的一致性。NoSQL数据库放宽了对这种一致性的要求，从而获得性能上的优势。 对中小型程序来说，SQL和NoSQL数据库都是很好的选择，而且性能相当。 Python数据库框架 大多数的数据库引擎都有对应的Python包，包含开源包和商业包。Flask并不限制你使用何种类型的数据库包，因为可以根据自己的喜好选择使用MySQL、Postgres、SQLite、Redis、MongoDB或者CouchDB。 如果这些都无法满足需求，还有一些数据库抽象层代码包供选择，例如SQLAlchemy和MongoEngine。你可以使用这些抽象包直接处理高等级的Python对象，而不用处理如表、文档或查询语言此类的数据库实例。 选择数据库框架时，你要考虑很多因素。 易用性 如果直接比较数据库引擎和数据库抽象层，显然后者取胜。抽象层，也称为对象关系映射（Object-Relational Mapper，ORM）或对象文档映射（Object-Document Mapper，ODM），在用户不知觉的情况下把高层的面向对象操作转换成低层的数据库指令。 性能 ORM和ODM把对象业务转换成数据库业务会有一定的损耗。大多数情况下，这种性能的降低微不足道，但也不一定都是如此。一般情况下，ORM和ODM对生产率的提升远远超过了这一丁点儿的性能降低，所以性能降低这个理由不足以说服用户完全放弃ORM和ODM。真正的关键点在于如何选择一个能直接操作低层数据库的抽象层，以防特定的操作需要直接使用数据库原生指令优化。 可移植性 选择数据库时，必须考虑其是否能在你的开发平台和生产平台中使用。例如，如果你打算利用云平台托管程序，就要知道这个云服务提供了哪些数据库可供选择。 可移植性还针对ORM和ODM。尽管有些框架只为一种数据库引擎提供抽象层，但其他框架可能做了更高层的抽象，它们支持不同的数据库引擎，而且都使用相同的面向对象接口。SQLAlchemy ORM就是一个很好的例子，它支持很多关系型数据库引擎，包括流行的MySQL，Postgres和SQLite。 Flask集成度 选择框架时，你不一定非得选择已经集成了Flask的框架，但选择这些框架可以节省你编写集成代码的时间。使用集成了Flask的框架可以简化配置和操作，所以专门为Flask开发的扩展是你的首选。 基于以上因素，这里选择使用的数据库框架是Flask-SQLAlchemy（http://flask-sqlalchemy.pocoo.org/2.1/），这个Flask扩展包装了SQLAlchemy（(http://www.sqlalchemy.org/)[http://www.sqlalchemy.org/]）框架。 使用Flask-SQLAlchemy管理数据库 Flask-SQLAlchemy是一个扩展，简化了在Flask程序中使用SQLAlchemy的操作。SQLAlchemy是一个很强大的关系型数据库框架，支持多种数据库后台。SQLAlchemy提供了高层ORM，也提供了使用数据库原生SQL的低层功能。 和其他大多数扩展一样，Flask-SQLAlchemy也使用pip安装： (env) [root@server1 myproject]# pip install flask-sqlalchemy 在Flask-SQLAlchemy中，数据库使用URL指定。最流行的数据库引擎的数据库URL格式如下表所示： Flask-SQLAlchemy数据库URL 数据库引擎 URL MySQL mysql://username:password@hostname/database Postgres postgresql://username:password@hostname/database SQLite（Unix） sqlite:////absolute/path/to/database SQLite（Windows） sqlite:///c:/absolute/path/to/database 在这些URL中，hostname表示MySQL服务所在的主机，可以是本地主机（localhost），也可以是远程服务器。数据库服务器上可以托管多个数据库，因此database表示要使用的数据库名。如果数据库需要进行认证，username和password表示数据库用户密令。 注意：SQLite数据库不需要使用服务器，因此不用指定hostname、username和password。URL中的database是硬盘上文件的文件名。 程序使用的数据库URL必须保存到Flask配置对象的SQLALCHEMY_DATABASE_URI键中。配置对象中还有一个很有用的选项，即SQLALCHEMY_COMMIT_ON_TEARDOWN键，将其设为True时，每次请求结束后都会自动提交数据库中的变动。其他配置选项的作用请参阅Flask-SQLAlchemy的文档。下面的run.py展示了如何初始化及配置一个简单的SQLite数据库。 run.py：配置数据库 123456789from flask.ext.sqlalchemy import SQLAlchemybasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] = &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;)app.config[&apos;SQLALCHEMY_COMMIT_ON_TEARDOWN&apos;] = Truedb = SQLAlchemy(app) db对象是SQLAlchemy类的实例，表示程序使用的数据库，同时还获得了Flask-SQLAlchemy提供的所有功能。 定义模型 模型这个术语表示程序使用的持久化实体。在ORM中，模型一般是一个Python类，类中的属性对应数据库表中的列。 Flask-SQLAlchemy创建的数据库实例为模型提供了一个基类以及一系列辅助类和辅助函数，可用于定义模型的结构。图1中的roles表和users表可定义为模型Role和User。 run.py：定义Role和User模型 12345678910111213141516class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.username 类变量__tablename__定义在数据库中使用的表明。如果没有定义__tablename__，Flask-SQLAlchemy会使用一个默认名字，但默认的表名没有遵守使用复数形式进行命名的约定，所以最好由我们自己来指定表名。其余的类变量都是该模型的属性，被定义为db.Column类的实例。 db.Column类构造函数的第一个参数是数据库列和模型属性的类型。下面列出了一些可用的列类型以及在模型中使用的Python类型。 最常用的SQLAlchemy列类型 类型名 Python类型 说明 Integer int 普通整数，一般是32位 SmallInteger int 取值范围小的整数，一般是16位 BigInteger int或long 不限制精度的整数 Float float 浮点数 Numeric decimal.Decimal 定点数 String str 变长字符串 Text str 变长字符串，对较长或不限长度的字符串做了优化 Unicode unicode 变长Unicode字符串 UnicodeText unicode 变长Unicode字符串，对较长或不限长度的字符串做了优化 Boolean bool 布尔值 Date datetime.date 日期 Time datetime.time 时间 DateTime datetime.datetime 日期和时间 Interval datetime.timedelta 时间间隔 Enum str 一组字符串 PickleType 任何Python对象 自动使用Pickle序列化 LargeBinary str 二进制文件 db.Column中其余的参数指定属性的配置选项。 最常使用的SQLAlchemy列选项 选项名 说明 primary_key 如果设为True，这列就是表的主键 unique 如果设为True，这列不允许出现重复的值 index 如果设为True，为这列创建索引，提升查询效率 nullable 如果设为True，这列允许使用空值；如果设为False，这列不允许使用空值 default 为这列定义默认值 *注意：Flask-SQLAlchemy要求每个模型都要定义主键，这一列经常命名为id。 虽然没有强制要求，但这两个模型都定义了__repr()__方法，返回一个具有可读性的字符串表示模型，可在调试和测试时使用。 关系 关系型数据库使用关系把不同表中的行联结起来。图1所示的关系图表示用户和角色之间的一种简单关系。这是角色到用户的一对多关系，因为一个角色可属于多个用户，而每个用户都只能有一个角色。 图1中的一对多关系在模型类中的表示方法如下： 1234567891011121314151617class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.username 如图1所示，关系使用users表中的外键连接了两行。添加到User模型中role_id列被定义为外键，就是这个外键建立起了关系。传给db.ForeignKey()的参数’roles.id’表明，这列的值是roles表中行的id值。 添加到Role模型中的users属性代表这个关系的面向对象视角。对于一个Role类的实例，其users属性将返回与角色相关联的用户组成的列表。db.relationship()的第一个参数表明这个关系的另一端是哪个模型。如果模型类尚未定义，可使用字符串形式指定。 db.relationship()中的backref菜蔬向User模型中添加一个role属性，从而定义反向关系。这一属性可替代role_id访问Role模型，此时获取的是模型对象，而不是外键的值。 大多数情况下，db.relationship()都能自行找到关系中的外键，但有时却无法决定把哪一列作为外键。例如，如果User模型中有两个或以上的列定义为Role模型的外键，SQLAlchemy就不知道该使用哪列。如果无法决定外键，你就要为db.relationship()提供额外参数，从而确定所用外键。 常用的SQLAlchemy关系选项 选项名 说明 backref 在关系的另一个模型中添加反向引用 primaryjoin 明确指定两个模型之间使用的联结条件。只在模棱两可的关系中需要指定 lazy 指定如何加载相关记录。可选值有select（首次访问时按需加载）、immediate（源对象加载后就加载）、joined（加载记录，但使用联结）、subquery（立即加载，但使用子查询）、noload（永不加载）和dynamic（不加载记录，但提供加载记录的查询） uselist 如果设为False，不使用列表，而使用标量值 order_by 指定关系中记录的排序方式 secondary 指定多对多关系中关系表的名字 secondaryjoin SQLAlchemy无法自行决定时，指定多对多关系中的二级联结条件 除了一对多之外，还有几种其他的关系类型。一对一关系可以用前面介绍的一对多关系表示，但调用db.relationship()时要把uselist设为False，把”多”变成”一”。多对一关系也可使用一对多表示，对调两个表即可，或者把外键和db.relationship()都放在”多”这一侧。最复杂的关系类型是多对多，需要用到第三张表，这个表称为关系表。 数据库操作 现在模型已经按照图1所示的数据库关系图完整配置，可以随时使用了。学习如何使用模型的最好方法是在Python shell中实际操作。接下来将介绍最常用的数据库操作 run.py 123456789101112131415161718192021222324252627282930313233343536import osfrom flask import Flaskfrom flask.ext.script import Managerfrom flask.ext.sqlalchemy import SQLAlchemybasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] =\ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;)app.config[&apos;SQLALCHEMY_COMMIT_ON_TEARDOWN&apos;] = Truemanager = Manager(app)db = SQLAlchemy(app)class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;, lazy=&apos;dynamic&apos;) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.usernameif __name__ == &apos;__main__&apos;: db.create_all() manager.run() 创建表首先，我们要让Flask-SQLAlchemy根据模型类创建数据库。方法是使用db.create_all()函数： (env) [root@server1 myproject]# python run.py shell &gt;&gt;&gt; from run import db &gt;&gt;&gt; db.create_all() 如果你查看程序目录，会发现新建了一个名为data.sqlite的文件。这个SQLite数据库文件的名字就是在配置中指定的。如果数据库表已经存在于数据库中，那么db.create_all()不会重新创建或者更新这个文件。如果修改模型后要把改动应用到现有的数据库中，这一特性会带来不便。更新现有数据库表的粗暴方式是先删除旧表再重新创建： &gt;&gt;&gt; db.drop_all() &gt;&gt;&gt; db.create_all() 遗憾的是，这个方法有个我们不想看到的副作用，它把数据库中原有的数据都销毁了。 插入行下面这段代码创建了一些角色和用户： &gt;&gt;&gt; from run import Role,User &gt;&gt;&gt; admin_role = Role(name=&apos;Admin&apos;) &gt;&gt;&gt; mod_role = Role(name=&apos;Moderator&apos;) &gt;&gt;&gt; user_role = Role(name=&apos;User&apos;) &gt;&gt;&gt; user_john = User(username=&apos;john&apos;,role=admin_role) &gt;&gt;&gt; user_susan = User(username=&apos;susan&apos;,role=user_role) &gt;&gt;&gt; user_david = User(username=&apos;david&apos;,role=user_role) 模型的构造函数接受的参数是使用关键字参数指定的模型属性初始值。注意，role属性也可使用，虽然它不是真正的数据库列，但却是一对多关系的高级表示。这些新建对象的id属性并没有明确设定，因为主键是由Flask-SQLAlchemy管理的。现在这些对象只存在于Python中，还未写入数据库。因此id尚未赋值： &gt;&gt;&gt; print(admin_role.id) None &gt;&gt;&gt; print(mod_role.id) None &gt;&gt;&gt; print(user_role.id) None 通过数据库会话管理对数据库所做的改动，在Flask-SQLAlchemy中，会话由db.session表示。准备把对象写入数据库之前，先要将其添加到会话中： &gt;&gt;&gt; db.session.add(admin_role) &gt;&gt;&gt; db.session.add(mod_role) &gt;&gt;&gt; db.session.add(user_role) &gt;&gt;&gt; db.session.add(user_john) &gt;&gt;&gt; db.session.add(user_susan) &gt;&gt;&gt; db.session.add(user_david) 或者简写成： &gt;&gt;&gt; db.session.add_all([admin_role,mod_role,user_role,user_john,user_susan,user_david]) 为了把对象写入数据库，我们要调用commit()方法提交会话： &gt;&gt;&gt; db.session.commit() 再次查看id属性，现在它们已经赋值了： &gt;&gt;&gt; print(admin_role.id) 1 &gt;&gt;&gt; print(mod_role.id) 2 &gt;&gt;&gt; print(user_role.id) 3 注意：数据库会话db.session和Flask——Web表单中介绍的Flask session对象没有关系。数据库会话也称为事务 数据库会话能保证数据库的一致性。提交操作使用原子方式把会话中的对象全部写入数据库。如果在写入会话的过程中发生了错误，整个会话都会失效。如果你始终把相关改动放在会话中提交，就能避免因部分更新导致的数据库不一致性。 注意：数据库会话也可回滚。调用db.session.rollback()后，添加到数据库会话中的所有对象都会还原到它们在数据库时的状态。 修改行在数据库会话上调用add()方法也能更新模型。我们继续在之前的shell会话中进行操作，下面这个例如把”Admin”角色重命名为”Administrator”： &gt;&gt;&gt; admin_role.name = &apos;Administrator&apos; &gt;&gt;&gt; db.session.add(admin_role) &gt;&gt;&gt; db.session.commit() &gt;&gt;&gt; print(admin_role.name) Administrator 删除行数据库会话还有个delete()方法。下面这个例子把”Moderator”角色从数据库中删除： &gt;&gt;&gt; db.session.delete(mod_role) &gt;&gt;&gt; db.session.commit() 注意：删除与插入和更新一样，提交数据库会话后才会执行。 查询行Flask-SQLAlchemy为每个模型类都提供了query对象。最基本的模型查询是取回对应表中的所有记录： &gt;&gt;&gt; Role.query.all() [&lt;Role u&apos;Administrator&apos;&gt;, &lt;Role u&apos;User&apos;&gt;] &gt;&gt;&gt; User.query.all() [&lt;User u&apos;john&apos;&gt;, &lt;User u&apos;susan&apos;&gt;, &lt;User u&apos;david&apos;&gt;] 使用过滤器可以配置query对象进行更精确的数据查询。下面这个例子查找角色为”User”的所有用户： &gt;&gt;&gt; User.query.filter_by(role=user_role).all() [&lt;User u&apos;susan&apos;&gt;, &lt;User u&apos;david&apos;&gt;] 或者： &gt;&gt;&gt; User.query.filter_by(role_id=user_role.id).all() [&lt;User u&apos;susan&apos;&gt;, &lt;User u&apos;david&apos;&gt;] 若要查看SQLAlchemy为查询生成的原生SQL查询语句，只需把query对象转换成字符串： &gt;&gt;&gt; str(User.query.filter_by(role=user_role)) &apos;SELECT users.id AS users_id, users.username AS users_username, users.role_id AS users_role_id \nFROM users \nWHERE :param_1 = users.role_id&apos; 如果你退出了shell会话，前面这些例子中创建的对象就不会以Python对象的形式存在，而是作为各自数据库表中的行。如果你打开了一个新的shell会话，就要从数据库中读取行，再重新创建Python对象。下面这个例子发起了一个查询，加载名为”User”的用户角色： &gt;&gt;&gt; from run import Role,User &gt;&gt;&gt; user_role = Role.query.filter_by(name=&apos;User&apos;).first() filter_by()等过滤器在query对象上调用，返回一个更精确的query对象。多个过滤器可以一起调用，直到获得所需结果。 常用的SQLAlchemy查询过滤器 过滤器 说明 filter() 把过滤器添加到原查询上，返回一个新查询 filter_by() 把等值过滤器添加到原查询上，返回一个新查询 limit() 使用指定的值限制原查询返回的结果数量，返回一个新查询 offset() 偏移原查询返回的结果，返回一个新查询 order_by() 根据指定条件对原查询结果进行排序，返回一个新查询 group_by() 根据指定条件对原查询结果进行分组，返回一个新查询 在查询上应用指定的过滤器后，通过调用all()执行查询，以列表的形式返回结果。除了all()之外，还有其他方法能触发查询执行。 最常用的SQLAlchemy查询执行函数 方法 说明 all() 以列表形式返回查询的所有结果 first() 返回查询的第一个结果，如果没有结果，则返回None first_or_404() 返回查询的第一个结果，如果没有结果，则终止请求，返回404错误响应 get() 返回指定主键对应的行，如果没有对应的行，则返回None get_or_404() 返回指定主键对应的行，如果没找到指定的主键，则终止请求，返回404错误响应 count() 返回查询结果的数量 paginate() 返回一个Paginate对象，它包含指定范围内的结果 关系和查询的处理方式类似。下面这个例子分别从关系的两端查询角色和用户之间的一对多关系： &gt;&gt;&gt; users = user_role.users &gt;&gt;&gt; users [&lt;User u&apos;suan&apos;&gt;,&lt;User u&apos;david&apos;&gt;] &gt;&gt;&gt; users[0].role &lt;Role u&apos;User&apos;&gt; 这个例子中的user_role.users查询有个小问题。执行user_role.users表达式时，隐含的查询会调用all()返回一个用户列表。query对象是隐藏的，因此无法指定更精确的查询过滤器。就这个特定示例而言，返回一个按照字母顺序排序的用户列表可能更好。在之前的示例我们修改了关系的设置，加入了lazy = &#39;dynamic&#39;参数，从而禁止自动执行查询。 run.py：动态关系 123class Role(db.Model): #... users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;, lazy=&apos;dynamic&apos;) 这样配置关系之后，user_role.users会返回一个尚未执行的查询，因此可以在其上添加过滤器： &gt;&gt;&gt; user_role.users.order_by(User.username).all() [&lt;User u&apos;david&apos;&gt;, &lt;User u&apos;susan&apos;&gt;] &gt;&gt;&gt; user_role.users.count() 2 在视图函数中操作数据库 上面介绍的数据库操作可以直接在视图函数中进行，下面展示了首页路由的新版本，已经把用户输入的名字写入了数据库。 run.py：在视图函数中操作数据库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import osfrom flask import Flask, render_template, session, redirect, url_forfrom flask.ext.script import Managerfrom flask.ext.bootstrap import Bootstrapfrom flask.ext.moment import Momentfrom flask.ext.wtf import Formfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import Requiredfrom flask.ext.sqlalchemy import SQLAlchemybasedir = os.path.abspath(os.path.dirname(__file__))app = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] =\ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;)app.config[&apos;SQLALCHEMY_COMMIT_ON_TEARDOWN&apos;] = Truemanager = Manager(app)bootstrap = Bootstrap(app)moment = Moment(app)db = SQLAlchemy(app)class Role(db.Model): __tablename__ = &apos;roles&apos; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;, lazy=&apos;dynamic&apos;) def __repr__(self): return &apos;&lt;Role %r&gt;&apos; % self.nameclass User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.usernameclass NameForm(Form): name = StringField(&apos;What is your name?&apos;, validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)@app.route(&apos;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() if user is None: user = User(username=form.name.data) db.session.add(user) session[&apos;known&apos;] = False else: session[&apos;known&apos;] = True session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;, form=form, name=session.get(&apos;name&apos;), known=session.get(&apos;known&apos;, False))if __name__ == &apos;__main__&apos;: manager.run() 在这个修改后的版本中，提交表单后，程序会使用filter_by()查询过滤器在数据库中查找提交的名字。变量known被写入用户会话中，因此重定向之后，可以把数据传给模板，用来显示自定义的欢迎信息。**注意：要想让程序正常运行，必须按照前面介绍的方法，在Python shell中创建数据库表。 (env) [root@server1 myproject]# python run.py shell &gt;&gt;&gt; from run import db &gt;&gt;&gt; db.create_all() &gt;&gt;&gt; exit() 对应的模板新版本如下，这个模板使用known参数在欢迎消息中加入了第二行，从而对已知用户和新用户显示不同的内容。 templates/base.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block head %&#125;&#123;&#123; super() &#125;&#125;&lt;link rel=&quot;shortcut icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;, filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&lt;link rel=&quot;icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;, filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-target=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &#123;% for message in get_flashed_messages() %&#125; &lt;div class=&quot;alert alert-warning&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt; &#123;&#123; message &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% block page_content %&#125;&#123;% endblock %&#125;&lt;/div&gt;&#123;% endblock %&#125;&#123;% block scripts %&#125;&#123;&#123; super() &#125;&#125;&#123;&#123; moment.include_moment() &#125;&#125;&#123;% endblock %&#125; templates/index.html 12345678910111213141516&#123;% extends &quot;base.html&quot; %&#125;&#123;% import &quot;bootstrap/wtf.html&quot; as wtf %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello, &#123;% if name %&#125;&#123;&#123; name &#125;&#125;&#123;% else %&#125;Stranger&#123;% endif %&#125;!&lt;/h1&gt; &#123;% if not known %&#125; &lt;p&gt;Pleased to meet you!&lt;/p&gt; &#123;% else %&#125; &lt;p&gt;Happy to see you again!&lt;/p&gt; &#123;% endif %&#125;&lt;/div&gt;&#123;&#123; wtf.quick_form(form) &#125;&#125;&#123;% endblock %&#125; 集成Python shell 每次启动shell会话都要导入数据库实例和模型，这真是份枯燥的工作。为了避免一直重复导入，我们可以做些配置，让Flask-Script的shell命令自动导入特定的对象。 若想把对象添加导入列表中，我们要为shell命令注册一个make_context()回调函数 12345from flask.ext.script import Shelldef make_shell_context(): return dict(app=app, db=db, User=User, Role=Role)manager.add_command(&quot;shell&quot;, Shell(make_context=make_shell_context)) make_shell_context()函数注册了程序、数据库实例以及模型，因此这些对象能直接导入shell： (env) [root@server1 myproject]# python run.py shell &gt;&gt;&gt; app &lt;Flask &apos;run&apos;&gt; &gt;&gt;&gt; db &lt;SQLAlchemy engine=&apos;sqlite:////root/myproject/data.sqlite&apos;&gt; &gt;&gt;&gt; User &lt;class &apos;__main__.User&apos;&gt; &gt;&gt;&gt; Role &lt;class &apos;__main__.Role&apos;&gt; &gt;&gt;&gt; exit() 使用Flask-Migrate实现数据库迁移 在开发程序的过程中，你会发现有时需要修改数据库模型，而且修改之后还需要更新数据库。 仅当数据库表不存在时，Flask-SQLAlchemy才会根据模型进行创建。因此，更新表的唯一方式就是先删除旧表，不过这样做会丢失数据库中的所有数据。 更新表的最好方法是使用数据库迁移框架。源码版本控制工具可以跟踪源码文件的变化，类似地，数据库迁移框架能跟踪数据库模式的变化，然后增量式的把变化应用到数据库中。 SQLAlchemy的主力开发人员编写了一个迁移框架，称为Alembic(http://alembic.readthedocs.io/en/latest/index.html)。除了直接使用Alembic之外，Flask程序还可以使用Flask-Migrate（http://flask-migrate.readthedocs.io/en/latest/）扩展。这个扩展对Alembic做了轻量级包装，并集成到Flask-Script中，所有操作都通过Flask-Script命令完成。 创建迁移仓库首先，我们要在虚拟环境中安装Flask-Migrate： (env) [root@server1 myproject]# pip install flask-migrate 这个扩展的初始化方法如下： 1234from flask.ext.migrate import Migrate, MigrateCommand#...migrate = Migrate(app, db)manager.add_command(&apos;db&apos;, MigrateCommand) 为了导出数据库迁移命令，Flask-Migrate提供了一个MigrateCommand类，可附加到Flask-Script的manager对象上。在这个例子中，MigrateCommand类使用db命令附加。 在维护数据库迁移之前，要使用init子命令创建迁移仓库： (env) [root@server1 myproject]# python run.py db init Creating directory /root/myproject/migrations ... done Creating directory /root/myproject/migrations/versions ... done Generating /root/myproject/migrations/README ... done Generating /root/myproject/migrations/script.py.mako ... done Generating /root/myproject/migrations/alembic.ini ... done Generating /root/myproject/migrations/env.pyc ... done Generating /root/myproject/migrations/env.py ... done Please edit configuration/connection/logging settings in &apos;/root/myproject/migrations/alembic.ini&apos; before proceeding. 这个命令会创建migrations文件夹，所有迁移脚本都存放其中。 注意：数据库迁移仓库中的文件要和程序的其他文件一起纳入版本控制。 创建迁移脚本在Alembic中，数据库迁移用迁移脚本表示。脚本中有两个函数，分别是upgrade()和downgrade()。upgrade()函数把迁移中的改动应用到数据库中，downgrade()函数则将改动删除。Alembic具有添加和删除改动的能力，因此数据库可重设到修改历史的任意一点。 我们可以使用revision命令手动创建Alembic迁移，也可使用migrate命令自动创建。手动创建的迁移只是一个骨架，upgrade()和downgrade()函数都是空的，开发者要使用Alembic提供的Operations对象指令实现具体操作。自动创建的迁移会根据模型定义和数据库当前状态之间的差异生成upgrade()和downgrade()函数的内容。 注意：自动创建的迁移不一定总是正确的，有可能会漏掉一些细节。自动生成迁移脚本后一定要进行检查。 migrate子命令用来自动创建迁移脚本： (env) [root@server1 myproject]# python run.py db migrate -m &quot;initial migration&quot; INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.autogenerate.compare] Detected added table &apos;roles&apos; INFO [alembic.autogenerate.compare] Detected added table &apos;users&apos; INFO [alembic.autogenerate.compare] Detected added index &apos;ix_users_username&apos; on &apos;[&apos;username&apos;]&apos; Generating /root/myproject/migrations/versions/a2489d001cec_initial_migration.py ... done 更新数据库检查并修正好迁移脚本之后，我们可以使用db upgrade命令把迁移应用到数据库中： 注意：迁移时先删除数据库文件data.splite，然后执行Flask-Migrate提供的upgrade命令，使用这个迁移框架重新生成数据库。 (env) [root@server1 myproject]# python run.py db upgrade INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade -&gt; a2489d001cec, initial migration 对第一个迁移来说，其作用和调用db.create_all()方法一样。但在后续的迁移中，upgrade命令能把改动应用到数据库中，且不影响其中保存的数据。 EOF 本文作者：Koen 参考书籍：《Flask Web开发——基于Python的Web应用开发实战》]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Python生成一个日期列表]]></title>
    <url>%2Fck74yvgox002ldhkczp3q7xw5.html</url>
    <content type="text"><![CDATA[功能描述：只要输入起始日期和终止日期就能生成在这段时间内的一个日期列表，日期格式为：19940214 代码实现： 123456789101112131415161718192021import datetimedef datelist(start, end): start_date = datetime.date(*start) end_date = datetime.date(*end) result = [] curr_date = start_date while curr_date != end_date: result.append(&quot;%04d%02d%02d&quot; % (curr_date.year, curr_date.month, curr_date.day)) #datetime.timedelta返回两个时间的差值 curr_date += datetime.timedelta(days=1) result.append(&quot;%04d%02d%02d&quot; % (curr_date.year, curr_date.month, curr_date.day)) return resultif __name__ == &quot;__main__&quot;: start_date = input(&quot;The start_date(year-month-day):&quot;) end_date = input(&quot;The end_date(year-month-day):&quot;) (start_date_year,start_date_month,start_date_day) = start_date.split(&apos;-&apos;) (end_date_year,end_date_month,end_date_day) = end_date.split(&apos;-&apos;) print(datelist((int(start_date_year),int(start_date_month),int(start_date_day)),(int(end_date_year),int(end_date_month),int(end_date_day)))) EOF 本文作者：Koen 参考链接：https://www.zhihu.com/question/35455996]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask——Web表单]]></title>
    <url>%2Fck74yvgo30009dhkcyzbits6v.html</url>
    <content type="text"><![CDATA[Flask——程序的基本结构中介绍的请求对象包含客户端发出的所有请求信息。其中，request.form能获取POST请求中提交的表单数据。 尽管Flask的请求对象提供的信息足够用于处理Web表单，但有些任务很单调，而且要重复操作。比如：生成表单的HTML代码和验证提交的表单数据。 Flask-WTF（https://flask-wtf.readthedocs.io/en/latest/）扩展可以把处理Web表单的过程变成一个愉悦的体验。这个扩展对独立的WTForms（http://wtforms.readthedocs.io/en/latest/）包进行了包装，方便集成到Flask程序中。 Flask-WTF及其依赖可使用pip安装： (env) [root@server1 myporject]# pip install flask-wtf 跨站请求伪造保护 默认情况下，Flask-WTF能保护所有表单免受跨站请求伪造（Cross-Site Request Forgery,CSRF）的攻击。恶意网站把请求发送到攻击者已登录的其他网站时就会引发CSRF攻击。 为了实现CSRF保护，Flask-WTF需要程序设置一个密钥。Flask-WTF使用这个密钥生成加密令牌，再用令牌验证请求中表单数据的真伪。设置密钥的方法如下： run.py：设置Flask-WTF 12app = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos; app.config字典可用来存储框架、扩展和程序本身的配置变量。使用标准的字典句法就能把配置值添加到app.config对象中。这个对象还提供了一些方法，可以从文本或环境中导入配置值。 SECRET_KEY配置变量时通用密钥，可在Flask和多个第三方扩展中使用。如其名所示，加密的强度取决于变量值的机密程度。不同的程序要使用不同的密钥，而且要保证其他人不知道你所用的字符串。 注意：为了增强安全性，密钥不应该直接写入代码，而要保存在环境变量中。 表单类 使用Flask-WTF时，每个Web表单都由一个继承自Form的类表示。这个类定义表单中一组字段，每个字段都用对象表示。字段对象可附属一个或多个验证函数。验证函数用来验证用户提交的输入值是否符合要求。 下面设计一个简单的Web表单，包含一个文本字段和一个提交按钮。 run.py：定义表单类 123456from flask.ext.wtf import Formfrom wtforms import StringField,SubmitFieldfrom wtforms.validators import Requiredclass NameForm(Form): name = StringField(&apos;What is your name?&apos;,validators=[Required()]) submit = SubmitField(&apos;Submit&apos;) 这个表单中的字段都定义为类变量，类变量的值是相应字段类型的对象。在这个示例中，NameForm表单中有一个名为name的文本字段和一个名为submit的提交按钮。StringField类表示属性为type=”text”的&lt;input&gt;元素。SubmitField类表示属性为type=”submit”的&lt;input&gt;元素。字段构造函数的第一个参数是把表单渲染成HTML时使用的标号。 StringField构造函数中的可选参数validators指定一个由验证函数组成的列表，在接受用户提交的数据之前验证数据。验证函数Required()确保提交的字段不为空。 注意：Form基类由Flask-WTF扩展定义，所以从flask.ext.wtf中导入。字段和验证函数却可以直接从WTForms包中导入。 WTForms支持的HTML标准字段： 字段类型 说明 StringField 文本字段 TextAreaField 多行文本字段 PasswordField 密码文本字段 HiddenField 隐藏文本字段 DateField 文本字段，值为datetime.date格式 DateTimeField 文本字段，值为datetime.datetime格式 IntegerField 文本字段，值为整数 DecimalField 文本字段，值为decimal.Decimal FloatField 文本字段，值为浮点数 BooleanField 复选框，值为True和False RadioField 一组单选框 SelectField 下拉列表 SelectMultipleField 下拉列表，可选择多个值 FileField 文件上传字段 SubmitField 表单提交按钮 FormField 把表单作为字段嵌入另一个表单 FieldList 一组指定类型的字段 WTForms验证函数： 验证函数 说明 Email 验证电子邮件地址 EqualTo 比较两个字段的值；常用于要求输入两次密码进行确认的情况 IPAddress 验证IPv4网络地址 Length 验证输入字符串的长度 NumberRange 验证输入的值在数字范围内 Optional 无输入值时跳过其他验证函数 Required 确保字段中有数据 Regexp 使用正则表达式验证输入值 URL 验证URL AnyOf 确保输入值在可选值列表中 NoneOf 确保输入值不在可选值列表中 把表单渲染成HTML 表单字段是可调用的，在模板中调用会渲染成HTML。假设视图函数把一个NameForm实例通过参数form传入模板，在模板中可以生成一个简单的表单，如下所示： 12345&lt;form method=&quot;POST&quot;&gt; &#123;&#123; form.hidden_tag() &#125;&#125; &#123;&#123; form.name.label &#125;&#125;&#123;&#123; form.name() &#125;&#125; &#123;&#123; form.submit() &#125;&#125;&lt;/form&gt; 当然，这个表单还很简陋。要想改进表单的外观，可以把参数传入渲染字段的函数，传入的参数会被转换成字段的HTML属性。例如：可以为字段指定id或class属性，然后定义CSS样式： 12345&lt;form method=&quot;POST&quot;&gt; &#123;&#123; form.hidden_tag() &#125;&#125; &#123;&#123; form.name.label &#125;&#125;&#123;&#123; form.name(id=&apos;my-text-field&apos;) &#125;&#125; &#123;&#123; form.submit() &#125;&#125;&lt;/form&gt; 即便能指定HTML属性，但按照这种方法渲染表单的工作量还是很大，所以在条件允许的情况下最好能使用Bootstrap中的表单样式。Flask-Bootstrap提供了一个非常高端的辅助函数，可以使用Bootstrap中预先定义好的表单样式渲染整个Flask-WTF表单，而这些操作只需一次调用即可完成。使用Flask-Bootstrap，上述表单可使用下面的方式渲染： 12&#123;% import &quot;bootstrap/wtf.html&quot; as wtf %&#125;&#123;&#123; wtf.quick_form(form) &#125;&#125; import指令的使用方法和普通Python代码一样，允许导入模块中的元素并用在多个模板中。导入的bootstrap/wtf.html文件中定义了一个使用Bootstrap渲染Flask-WTF表单对象的辅助函数。wtf.quick_form()函数的参数为Flask-WTF表单对象，使用Bootstrap的默认样式渲染传入的表单。run.py的完整模板如下： templates/index.html：使用Flask-WTF和Flask-Bootstrap渲染表单 1234567891011&#123;% extends &quot;base.html&quot; %&#125;&#123;% import &quot;bootstrap/wtf.html&quot; as wtf %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello,&#123;% if name %&#125;&#123;&#123; name &#125;&#125;&#123;% else %&#125;Stranger&#123;% endif %&#125;!&lt;/h1&gt;&lt;/div&gt;&#123;&#123; wtf.quick_form(form) &#125;&#125;&#123;% endblock %&#125; 模板的内容区现在有两部分。第一部分是页面头部，显示欢迎消息。这里用到了一个模板条件语句。Jinja2中的条件语句格式为...。如果条件的计算结果为True，那么渲染if和else指令之间的值。如果条件的计算结果为False，则渲染else和endif指令之间的值。在这个示例中，如果没有定义模板变量name，则会渲染字符串”Hello,Stranger!”。内容区的第二部分使用wtf.quick_form()函数渲染NameForm对象。 在视图函数中处理表单 在run.py中，视图函数index()不仅要渲染表单，还要接收表单中的数据。 run.py：路由方法 12345678@app.route(&apos;/&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def index(): name = None form = NameForm() if form.validate_on_submit(): name = form.name.data form.name.data = &apos;&apos; return render_template(&apos;index.html&apos;,form=form,name=name) app.route修饰器中添加的methods参数告诉Flask在URL映射中把这个视图函数注册为GET和POST请求的处理程序。如果没指定methods参数，就只把视图函数注册为GET请求的处理程序。 把POST加入方法列表很有必要，因为将提交表单作为POST请求进行处理更加便利。表单也可作为GET请求提交，不过GET请求没有主体，提交的数据以查询字符串的形式附加到URL中，可在浏览器的地址栏中看到。基于这个以及其他多个原因，提交表单大都作为POST请求进行处理。 局部变量name用来存放表单中输入的有效名字，如果没有输入，其值为None。如上述代码所示，在视图函数中创建一个NameForm类实例用于表示表单。提交表单后，如果数据能被所有验证函数接受，那么validate_on_submit()方法的返回值为True，否则返回False。这个函数的返回值决定是重新渲染表单还是处理表单提交的数据。 用户第一次访问程序时，服务器会收到一个没有表单数据的GET请求，所以validate_on_submit()将返回False。if语句的内容被跳过，通过渲染模板处理请求，并传入表单对象和值为None的name变量作为参数。用户会看到浏览器中显示了一个表单。 用户提交表单后，服务器收到一个包含数据的POST请求。validate_on_submit()会调用name字段上附属的Required()验证函数。如果名字不为空，就能通过验证，validate_on_submit()返回True。现在，用户输入的名字可通过字段的data属性获取。在if语句中，把名字赋值给局部变量name，然后再把data属性设为空字符串，从而清空表单字段。最后一行调用render_template()函数渲染模板，但这一次参数name的值为表单中输入的名字，因此会显示一个针对该用户的欢迎消息。 完整代码示例如下： templates/base.html 123456789101112131415161718192021222324252627282930&#123;% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-target=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &#123;% block page_content %&#125;&#123;% endblock %&#125;&lt;/div&gt; &#123;% endblock %&#125; templates/index.html 1234567891011&#123;% extends &quot;base.html&quot; %&#125;&#123;% import &quot;bootstrap/wtf.html&quot; as wtf %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello,&#123;% if name %&#125;&#123;&#123; name &#125;&#125;&#123;% else %&#125;Stranger&#123;% endif %&#125;!&lt;/h1&gt;&lt;/div&gt;&#123;&#123; wtf.quick_form(form) &#125;&#125;&#123;% endblock %&#125; run.py 12345678910111213141516171819202122232425from flask import Flask,render_templatefrom flask.ext.bootstrap import Bootstrapfrom flask.ext.wtf import Formfrom wtforms import StringField,SubmitFieldfrom wtforms.validators import Requiredapp = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;bootstrap = Bootstrap(app)class NameForm(Form): name = StringField(&apos;What is your name?&apos;,validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)@app.route(&apos;/&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def index(): name = None form = NameForm() if form.validate_on_submit(): name = form.name.data form.name.data = &apos;&apos; return render_template(&apos;index.html&apos;,form=form,name=name)if __name__ == &apos;__main__&apos;: app.run(&apos;0.0.0.0&apos;) Flask-WTF Web表单 上图是用户首次访问网站时浏览器显示的表单。用户提交名字后，程序会生成一个针对该用户的欢迎消息（如下图）。欢迎消息下方还是会显示这个表单，以便用户输入新名字。 提交后显示的Web表单 如果用户提交表单之前没有输入名字，Required()验证函数会捕获这个错误(如下图)。注意一下扩展自动提供了多少功能。这说明像Flask-WTF和Flask-Bootstrap这样设计良好的扩展能让程序具有强大的功能。 验证失败后显示的Web表单 重定向和用户会话 上述的run.py存在一个可用性问题。用户输入名字后提交表单，然后点击浏览器的刷新按钮，会看到一个莫名其妙的警告，要求在再次提交表单之前进行确认。之所以出现这种情况，是因为刷新页面时浏览器会重新发送之前已经发送过的最后一个请求。如果这个请求是一个包含表单数据的POST请求，刷新页面后会再次提交表单。大多数情况下，这并不是理想的处理方式。 很多用户都不理解浏览器发出的这个警告。基于这个原因，最好别让Web程序把POST请求作为浏览器发送的最后一个请求。 这种需求的实现方式是，使用重定向作为POST请求的响应，而不是使用常规响应。重定向是一种特殊的响应，响应内容是URL，而不是包含HTML代码的字符串。浏览器收到这种响应时，会向重定向的URL发起GET请求，显示页面的内容。这个页面的加载可能要多花几微秒，因为要先把第二个请求发给服务器。除此之外，用户不会察觉到有什么不同。现在，最后一个请求是GET请求，所以刷新命令能像预期的那样正常使用了。这个技巧称为Post/重定向/Get模式。 但这种方式会带来另一个问题。程序处理POST请求时，使用form.name.data获取用户输入的名字，可是一旦这个请求结束，数据也就丢失了。因为这个POST请求使用重定向处理，所以程序需要保存输入的名字，这样重定向后的请求才能获得并使用这个名字，从而构建真正的响应。 程序可以把数据存储在用户会话中，在请求之间”记住”数据。用户会话是一种私有存储，存在于每个连接到服务器的客户端中。它是请求上下文中的变量，名为session，像标准的Python字典一样操作。 注意：默认情况下，用户会话保存在客户端cookie中，使用设置的SECRET_KEY进行加密签名。如果篡改了cookie中的内容，签名就会失效，会话也会随之失效。 更新之后的run.py如下，实现了重定向和用户会话，模板文件没有变动： run.py：重定向和用户会话 123456789101112131415161718192021222324from flask import Flask,render_template,session,redirect,url_forfrom flask.ext.bootstrap import Bootstrapfrom flask.ext.wtf import Formfrom wtforms import StringField,SubmitFieldfrom wtforms.validators import Requiredapp = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;bootstrap = Bootstrap(app)class NameForm(Form): name = StringField(&apos;What is your name?&apos;,validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)@app.route(&apos;/&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;,form=form,name=session.get(&apos;name&apos;))if __name__ == &apos;__main__&apos;: app.run(&apos;0.0.0.0&apos;) 在程序的前一个版本中，局部变量name被用于存储用户在表单中输入的名字。这个变量现在保存在用户会话中，即session[‘name’]，所以在两次请求之间也能记住输入的值。 现在，包含合法表单数据的请求最后会调用redirect()函数。redirect()是个辅助函数，用来生成HTTP重定向响应。redirect()函数的参数是重定向的URL，这里使用的重定向URL是程序的根地址，因为重定向响应本可以写得简单一些，写成redirect(‘/‘)，但却会使用Flask提供的URL生成函数url_for()。推荐使用url_for()生成URL，因为这个函数使用URL映射生成URL，从而保证URL和定义的路由兼容，而且修改路由名字后依然可用。 url_for()函数的第一个且唯一必须指定的参数是端点名，即路由的内部名字。默认情况下，路由的端点是相应视图函数的名字。在这个示例中，处理根地址的视图函数是index()，因此传给url_for()函数的名字是index。 最后一处改动位于render_template()函数中，使用session.get(‘name’)直接从会话中读取name参数的值。和普通的字典一样，这里使用get()获取字典中键对应的值以避免未找到键的异常情况，因为对于不存在的值，get()会返回默认值None。 使用这个版本的程序时，刷新浏览器页面，看到的新页面就和预期一样了。 Flash消息请求完成后，有时需要让用户知道状态发生了变化。这里可以使用确认消息、警告或者错误提醒。一个典型例子是，用户提交了有一项错误的登录表单后，服务器发回的响应重新渲染了登录表单，并在表单上面显示一个消息，提示用户用户名或者密码错误。 这种功能是Flask的核心特性。flash()函数可实现这种效果。 run.py：Flash消息 123456789101112131415161718192021222324252627from flask import Flask,render_template,session,redirect,url_for,flashfrom flask.ext.bootstrap import Bootstrapfrom flask.ext.wtf import Formfrom wtforms import StringField,SubmitFieldfrom wtforms.validators import Requiredapp = Flask(__name__)app.config[&apos;SECRET_KEY&apos;] = &apos;hard to guess string&apos;bootstrap = Bootstrap(app)class NameForm(Form): name = StringField(&apos;What is your name?&apos;,validators=[Required()]) submit = SubmitField(&apos;Submit&apos;)@app.route(&apos;/&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): old_name = session.get(&apos;name&apos;) if old_name is not None and old_name != form.name.data: flash(&apos;Looks like you have changed your name!&apos;) session[&apos;name&apos;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;,form=form,name=session.get(&apos;name&apos;))if __name__ == &apos;__main__&apos;: app.run(&apos;0.0.0.0&apos;) 在这个示例中，每次提交的名字都会和存储在用户会话中的名字进行比较，而会话中存储的名字是前一次在这个表单中提交的数据。如果两个名字不一样，就会调用flash()函数，在发给客户端的下一个响应中显示一个消息。 仅调用flash()函数并不能把消息显示出来，程序使用的模板要渲染这些消息。最好在基模板中渲染Flash消息，因为这样所有页面都能使用这些消息。Flask把get_flashed_messages()函数开放到模板，用来获取并渲染消息。 templates/base.html：渲染Flash消息 12345678910111213141516171819202122232425262728293031323334353637&#123;% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-target=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &#123;% for message in get_flashed_messages() %&#125; &lt;div class=&quot;alert alert-warning&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt; &#123;&#123; message &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% block page_content %&#125;&#123;% endblock %&#125;&lt;/div&gt;&#123;% endblock %&#125; 在这个示例中，使用Bootstrap提供的警报CSS样式渲染警告消息。 在模板中使用循环是因为在之前的请求循环中每次调用flash()函数时都会生成一个消息，所以可能有多个消息在排队等待显示。get_flashed_messages()函数获取的消息在下次调用时不会再次返回，因此Flash消息只显示一次，然后就消失了。 EOF 本文作者：Koen 参考书籍：《Flask Web开发——基于Python的Web应用开发实战》]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器的工作原理]]></title>
    <url>%2Fck74yvgp5003ddhkcf891d620.html</url>
    <content type="text"><![CDATA[浏览器的主要功能 浏览器的主要功能是将用户选择的WEB资源呈现出来，它需要从服务器请求资源，并将其显示在浏览器窗口中，资源的格式通常是HTML，也包括PDF、image及其他格式。用户用URL来指定所请求资源的位置。HTML和CSS规范中规定了浏览器解释HTML文档的方式，由W3C组织对这些规范进行维护，W3C是负责制定WEB标准的组织。 浏览器的主要构成 用户界面 包括地址栏、后退/前进按钮、书签目录等，也就是你所看到的除了用来显示你所请求页面的主窗口之外的其他部分 浏览器引擎 用来查询及操作渲染引擎的接口 渲染引擎 用来显示请求的内容。例如：如果请求内容为HTML，它负责解析HTML及CSS，并将解析后的结果显示出来 网络 用来完成网络调用。例如：HTTP请求，它具有平台无关的接口，可以在不同平台上工作 UI后端 用来绘制类似组合选择框及对话框等基本组件，具有不特定于某个平台的通用接口，底层使用操作系统的用户接口 JS解释器 用来解释执行JS代码 数据存储 属于持久层，浏览器需要在硬盘中保存类似cookie的各种数据，HTML5定义了Web Database技术，这是一种轻量级完整的客户端存储技术。需要注意的是，不同于大部分浏览器，Chrome为每个Tab分配了各自的渲染引擎实例，每个Tab就是一个独立的进程。 渲染引擎 渲染引擎的职责就是渲染，即在浏览器窗口中显示所请求的内容。 默认情况下，渲染引擎可以显示HTML、XML文档及图片，它也可以借助插件（一种浏览器扩展）显示其他类型的数据，例如使用PDF阅读器插件，可以显示PDF格式的文件。当然，渲染引擎最主要的用途是——显示应用了CSS之后的HTML及图片。 本文所讨论的浏览器：Firefox、Chrome和Safari是基于两种渲染引擎构建的，Firefox使用Geoko——Mozilla自主研发的渲染引擎，Safari和Chrome都使用Webkit——是一款开源渲染引擎，它本来是为Linux平台研发的，后来由Apple移植到Mac及Windows上。 网页的生成过程，大致可以分成五步： HTML代码转化成DOM CSS代码转化成CSSOM（CSS Object Model） 结合DOM和CSSOM，生成一棵渲染树（包含每个节点的视觉信息） 生成布局（layout），即将渲染树的所有节点进行平面合成 将布局绘制（paint）在屏幕上 这五步里面，第一步到第三步都非常快，耗时的是第四步和第五步。”生成布局（flow）”和”绘制（paint）”这两步，合称为”渲染（render）”。 解析HTML以构建DOM树–&gt;构建redner树–&gt;布局render树–&gt;绘制render树 渲染引擎开始解析HTML，并将标签转化为内容树中的DOM节点。接着，它解析外部CSS文件及style标签中的样式信息。这些样式信息以及HTML中的可见性指令将被用来构建另一棵树————render树。Render树由一些包含有颜色和大小等属性的矩形组成，它们将被按照正确的顺序显示到屏幕上。Render树构建好了之后，将会执行布局过程，它将确定每个节点在屏幕上的确切坐标。再下一步就是绘制，即遍历render树，并使用UI后端层绘制每个节点。值得注意的是，这个过程是逐步完成的，为了更好的用户体验，渲染引擎将会尽可能早的将内容呈现到屏幕上，并不会等到所有的HTML都解析完成之后再去构建和布局render树。它是解析完一部分内容就显示一部分内容，同时，可能还在通过网络下载其余内容。 Webkit渲染引擎主流程 Mozilla的Geoko渲染引擎主流程 从图1和图2中可以看出，尽管Webkit和Geoko使用的术语稍有不同，他们的主要流程基本相同。Geoko称可见的格式化元素组成的树为frame树，每个元素都是一个frame，Webkit则使用render树这个名词来命名由渲染对象组成的树。Webkit中元素的定位称为布局，而Geoko中称为回流。Webkit称利用DOM节点及样式信息去构建render树的过程为attachment，Geoko在HTML和DOM树之间附加了一层，这层称为内容接收器，相当于制造DOM元素工厂。 EOF 本文作者：Koen 参考链接：http://www.kuqin.com/shuoit/20160308/351057.html]]></content>
      <categories>
        <category>Web阵地</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask——模板]]></title>
    <url>%2Fck74yvgo7000ddhkc1tpdr0cg.html</url>
    <content type="text"><![CDATA[要想开发出易于维护的程序，关键在于编写形式简洁且结构良好的代码。视图函数的作用很明确，即生成请求的响应，对最简单的请求来说，这就足够了，但一般而言，请求会改变程序的状态，而这种变化也会在视图函数中产生。 例如：用户在网站中注册了一个新账户。用户在表单中输入电子邮件地址和密码，然后点击提交按钮。服务器接收到包含用户输入数据的请求，然后Flask把请求分发到处理注册请求的视图函数。这个视图函数需要访问数据库，添加新用户，然后生成响应回送浏览器。这两个过程分别称为业务逻辑和表现逻辑。 把业务逻辑和表现逻辑混在一起会导致代码难以理解和维护。假设要为一个大型表格构建HTML代码，表格中的数据由数据库中读取的数据以及必要的HTML字符串连接在一起。把表现逻辑移到模板中能够提升代码的可维护性。 模板是一个包含响应文本的文件，其中包含用占位变量表示的动态部分，其具体值只在请求的上下文中才能知道。使用真实值替换变量，再返回最终得到的响应字符串，这一过程称为渲染。为了渲染模板，Flask使用了一个名为Jinja2的强大模板引擎。 Jinja2模板引擎 形式最简单的Jinja2模板就是一个包含响应文本的文件。例如： templates/index.html:Jinja2模板： 1&lt;h1&gt;Hello World!&lt;/h1&gt; 返回的响应中包含一个使用变量表示的动态部分的Jinja2模板： templates/user.html:Jinja2模板 1&lt;h1&gt;Hello,&#123;&#123; name &#125;&#125;!&lt;/h1&gt; 渲染模板默认情况下，Flask在程序文件夹中的templates子文件夹中寻找模板。因此需要将定义的模板保存在templates文件夹中，然后修改视图函数，以便渲染这些模板。代码如下： 12345678910111213from flask import Flask,render_templateapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): return render_template(&apos;index.html&apos;)@app.route(&apos;/user/&lt;name&gt;&apos;)def user(name): return render_template(&apos;user.html&apos;,name=name)if __name__ == &apos;__main__&apos;: app.run(&apos;0.0.0.0&apos;) Flask提供的render_template函数把Jinja2模板引擎集成到了程序中。render_template函数的第一个参数是模板的文件名。随后的参数都是键值对，表示模板中变量对应的真实值。在这段代码中，第二个模板收到一个名为name的变量，左边的”name”表示参数名，就是模板中使用的占位符；右边的”name”是当前作用域中的变量，表示同名参数的值。 变量在模板中使用的结构表示一个变量，它是一种特殊的占位符，告诉模板引擎这个位置的值从渲染模板时使用的数据中获取。 Jinja2能识别所有类型的变量，甚至是一些复杂的类型，例如列表、字典和对象。在模板中使用变量的一些示例如下： 1234&lt;p&gt;A value from a dictionary:&#123;&#123; mydict[&apos;key&apos;] &#125;&#125;.&lt;/p&gt;&lt;p&gt;A value from a list:&#123;&#123; mylist[3] &#125;&#125;.&lt;/p&gt;&lt;p&gt;A value from a list,with a variable index:&#123;&#123; mylist[myintvar] &#125;&#125;.&lt;/p&gt;&lt;p&gt;A value from an object&apos;s method:&#123;&#123; myobj.somemethod() &#125;&#125;.&lt;/p&gt; 可以使用过滤器修改变量，过滤器名添加在变量名之后，中间使用竖线（|）分割。例如，下述模板以首字母大写形式显示变量name的值： 1Hello,&#123;&#123; name|capitalize &#125;&#125; 下表列出了Jinja2提供的部分常用过滤器： 过滤器名 说明 safe 渲染值时不转义 capitalize 把值的首字母转换成大写，其他字母转换成小写 lower 把值转换成小写形式 upper 把值转换成大写形式 title 把值中每个单词的首字母都转换成大写 trim 把值得首尾空格去掉 striptags 渲染之前把值中所有的HTML标签都删掉 safe过滤器特别说明一下：默认情况下，处于安全考虑，Jinja2会转义所有变量。例如，如果一个变量的值为&lt;h1&gt;Hello&lt;/h1&gt;，Jinja2会将其渲染成&amp;lt;h1&amp;gt;Hello&amp;lt;/h1&amp;gt;,浏览器能显示这个h1元素，但不会进行解释。很多情况下需要显示变量中存储的HTML代码，这时就可使用safe过滤器。 注意：千万别在不可信的值上使用safe过滤器，例如用户在表单中输入的文本。 控制结构Jinja2提供了多种控制结构，可用来改变模板的渲染流程。 条件控制语句 12345&#123;% if user %&#125; Hello,&#123;&#123; user &#125;&#125;!&#123;% else %&#125; Hello,Stranger!&#123;% endif %&#125; 循环语句 12345&lt;ul&gt; &#123;% for comment in comments %&#125; &lt;li&gt;&#123;&#123; comment &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt; Jinja2还支持宏。宏类似于Python代码中的函数，例如： 123456789&#123;% macro render_comment(comment) %&#125; &lt;li&gt;&#123;&#123; comment &#125;&#125;&lt;/li&gt;&#123;% endmacro %&#125;&lt;ul&gt; &#123;% for comment in comments %&#125; &#123;&#123; render_comment(comment) &#125;&#125; &#123;% endfor %&#125;&lt;/ul&gt; 为了重复使用宏，可以将其保存在单独的文件中，然后在需要使用的模板中导入： 123456&#123;% import &apos;macros.html&apos; as macros %&#125;&lt;ul&gt; &#123;% for comment in comments %&#125; &#123;&#123; macros.render_comment(comment) &#125;&#125; &#123;% endfor %&#125;&lt;/ul&gt; 需要在多处重复使用的模板代码片段可以写入单独的文件，再包含在所有模板中，以避免重复： 1&#123;% include &apos;common.html&apos; %&#125; 另一种重复使用代码的强大方式是模板继承，它类似于Python代码中的类继承。首先，创建一个名为base.html的基模板： 1234567891011&lt;html&gt;&lt;head&gt; &#123;% block head %&#125; &lt;title&gt;&#123;% block title %&#125;&#123;% end block %&#125; - My Application&lt;/title&gt; &#123;% endblock %&#125;&lt;/head&gt;&lt;body&gt; &#123;% block body %&#125; &#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; block标签定义的元素可在衍生模板中修改。在上述基类模板中定义了名为head、title和body的块。注意，titile包含在head中。下面是基模板的衍生模板： 12345678910&#123;% extends &quot;base.html&quot; %&#125;&#123;% block title %&#125;Index&#123;% endblock %&#125;&#123;% block head %&#125; &#123;&#123; super() &#125;&#125; &lt;style&gt; &lt;/style&gt;&#123;% endblock %&#125;&#123;% block body %&#125;&lt;h1&gt;Hello World!&lt;/h1&gt;&#123;% endblock %&#125; extends指令声明这个模板衍生自base.html。在extends指令后，基模板中的3个块被重新定义，模板引擎会将其插入适当的位置。注意新定义的head块，在基模板中其内容不是空的，所以使用super()获取原来的内容。 使用Flask-Bootstrap集成Twitter Bootstrap Bootstrap是Twitter开发的一个开源框架，它提供的用户界面组件可用于创建整洁且具有吸引力的网页，而且这些网页还能兼容所有现代Web浏览器。 Bootstrap是客户端框架，因此不会直接涉及服务器。服务器需要做的只是提供引用了Bootstrap层叠样式表（CSS）和JavaScript文件的HTML响应，并在HTML、CSS和JavaScript代码中实例化所需组件。这些操作最理想的执行场所就是模板。 要想在程序中集成Bootstrap，显然要对模板做所有必要的改动。不过，最简单的方法是使用一个名为Flask-Bootstrap的Flask扩展，简化集成的过程。Flask-Bootstrap使用pip安装： (venv) [root@server1 myproject]# pip install flask-bootstrap Flask-Bootstrap的初始化方法： 12from flask.ext.bootstrap import Bootstrapbootstrap = Bootstrap(app) 初始化Flask-Bootstrap之后，就可以在程序中使用一个包含所有Bootstrap文件的基模板。这个模板利用Jinja2的模板继承机制，让程序扩展一个具有基本页面结构的基模板，其中就有用来引入Bootstrap的元素。 /templates/user.html：使用Flask-Bootstrap的模板 123456789101112131415161718192021222324252627282930313233&#123;% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-taget=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello,&#123;&#123; name&#125;&#125;!&lt;/h1&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endblock %&#125; Jinja2中的extends指令从Flask-Bootstrap中导入bootstrap/base.html，从而实现模板继承。Flask-Bootstrap中的基模板提供了一个网页框架，引入了Bootstrap中的所有CSS和JavaScript文件。 基模板中定义了可在衍生模板中重定义的块。block和endblock指令定义的块中的内容可添加到基模板中。 在上面的user.html模板中定义了3个块，分别名为title、navbar和content。这些块都是基模板提供的，可在衍生模板中重新定义。title块的作用很明显，其中的内容会出现在渲染后的HTML文档头部，放在标签中。navbar和content这两个块分别表示页面中的导航条和主题内容。 在这个模板中，navbar块使用Bootstrap组件定义了一个简单的导航条。content块中有个容器，其中包含一个页面头部。之前版本的模板中的欢迎信息，现在就放在这个页面头部。 Flask-Bootstrap的base.html模板还定义了很多其他块，都可在衍生模板中使用。下表中是所有的可用的块 块名 说明 doc 整个HTML文档 html_attribs 标签的属性 html 标签中的内容 head 标签中的内容 title 标签中的内容 metas 一组标签 styles 层叠样式表定义 body_attribs 标签的属性 body 标签中的内容 navnar 用户定义的导航条 content 用户定义的页面内容 scripts 文档底部的JavaScript声明 以上很多块都是Flask-Bootstrap自用的，如果直接重定义可能会导致一些问题。例如：Bootstrap所需的文件在styles和scripts块中声明。如果程序需要向已经有内容的块中添加新内容，必须使用Jinja2提供的super()函数。例如，如果要在衍生模板中添加新的JavaScript文件，需要这么定义scripts块： 1234&#123;% block scripts %&#125;&#123;&#123; super() &#125;&#125;&lt;script type=&quot;text/javascript&quot; src=&quot;my-script.js&quot;&gt;&lt;/script&gt;&#123;% endblock %&#125; 自定义错误页面如果你在浏览器的地址栏中输入了不可用的路由，那么会显示一个状态码为404的错误页面。现在这个错误页面太简陋、平庸，而且样式和使用了Bootstrap的页面不一致。 像常规路由一样，Flask允许程序使用基于模板的自定义错误页面。最常见的错误代码有两个：404，客户端请求未知页面或路由时显示；500，有未处理的异常时显示。为这两个错误代码指定自定义处理程序的方式如下： 12345678910111213141516171819from flask import Flask,render_templatefrom flask.ext.bootstrap import Bootstrapapp = Flask(__name__)bootstrap = Bootstrap(app)@app.route(&apos;/user/&lt;name&gt;&apos;)def user(name): return render_template(&quot;user.html&quot;,name=name)@app.errorhandler(404)def page_not_found(e): return render_template(&apos;404.html&apos;),404@app.errorhandler(500)def internal_server_error(e): return render_template(&apos;500.html&apos;),500if __name__ == &apos;__main__&apos;: app.run(&apos;0.0.0.0&apos;) 和视图函数一样，错误处理程序也会返回响应，它们还返回与该错误对应的数字状态码。 错误处理程序中引用的模板也需要编写。这些模板应该和常规页面使用相同的布局，因此要有一个导航条和显示错误消息的页面头部。 编写这些模板最直观的方法是复制templates/user.html，分别创建templates/404.html和templates/500.html，然后把这两个文件中的页面头部元素改为响应的错误消息。但这种方式会带来很多重复劳动。 Jinja2的模板继承机制可以帮助我们解决这一问题。Flask-Bootstrap提供了一个具有页面基本布局的基模板，同样，程序可以定义一个具有更完整页面布局的基模板，其中包含导航条，而页面内容则可留到衍生模板中定义。以下文件为templates/base.html的内容，这是一个继承自bootstrap/base.html的新模板，其中定义了导航条。这个模板本身也可作为其他模板的基模板，例如templates/user.html、templates/404.html和templates/500.html。 templates/base.html： 12345678910111213141516171819202122232425262728293031&#123;% extends &quot;bootstrap/base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block navbar %&#125;&lt;div class=&quot;navbar navbar-inverse&quot; role=&quot;navigation&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;navbar-header&quot;&gt; &lt;button type=&quot;button&quot; class=&quot;navbar-toggle&quot; data-toggle=&quot;collapse&quot; data-taget=&quot;.navbar-collapse&quot;&gt; &lt;span class=&quot;sr-only&quot;&gt;Toggle navigation&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;span class=&quot;icon-bar&quot;&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=&quot;navbar-brand&quot; href=&quot;/&quot;&gt;Flasky&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;navbar-collapse collapse&quot;&gt; &lt;ul class=&quot;nav navbar-nav&quot;&gt; &lt;li&gt;&lt;a href=&quot;/&quot;&gt;Home&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;div class=&quot;container&quot;&gt; &#123;% block page_content %&#125;&#123;% endblock %&#125;&lt;/div&gt;&#123;% endblock %&#125; 这个模板的content块中只有一个容器，其中包含了一个名为page_content的新的空块，块中的内容由衍生模板定义。 现在，程序使用的模板继承自这个模板，而不直接继承自Flask-Bootstrap的基模板。通过继承templates/base.html模板编写自定义的404错误页面如下： templates/404.html： 123456789&#123;% extends &quot;base.html&quot; %&#125;&#123;% block title %&#125;Flasky - Page Not Found&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Not Found&lt;/h1&gt;&lt;/div&gt;&#123;% endblock %&#125; 错误页面在浏览器中的显示效果： templates/user.html现在可以通过继承这个基模板来简化内容，代码如下 templates/user.html： 123456789&#123;% extends &quot;base.html&quot; %&#125;&#123;% block title %&#125;Flasky&#123;% endblock %&#125;&#123;% block page_content %&#125;&lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt;Hello,&#123;&#123; name &#125;&#125;!&lt;/h1&gt;&lt;/div&gt;&#123;% endblock %&#125; 链接 任何具有多个路由的程序都需要可以连接不同页面的链接，例如导航条。 在模板中直接编写简单路由的URL链接不难，但对于包含可变部分的动态路由，在模板中构建正确的URL就很困难。而且，直接编写URL会对代码中定义的路由产生不必要的依赖关系。如果重新定义路由，模板中的链接可能会失效。 为了避免这些问题，Flask提供了url_for()辅助函数，它可以使用程序URL映射中保存的信息生成URL。 url_for()函数最简单的用法是以视图函数名（或者app.add_url_route()定义路由时使用的端点名）作为参数，返回对应的URL。 例如： 123@app.route(&apos;/&apos;)def index() return render_template(&apos;index.html&apos;) 在上述程序中调用url_for(‘index’)得到的结果是/。调用url_for(‘index’,_external=True)返回的则是绝对地址，即http://localhost:5000。 生成连接程序内不同路由的链接时，使用相对地址就足够了。如果要生成在浏览器之外使用的链接，则必须使用绝对地址，例如在电子邮件中发送的链接。 使用url_for()生成动态地址时，将动态部分作为关键字参数传入。例如url_for(‘user’,name=’john’,_external=True)的返回结果是http://localhost:5000/user/john。 传入url_for()的关键字参数不仅限于动态路由中的参数。函数能将任何额外参数添加到查询字符串中。例如url_for(‘index’,page=2)的返回结果是/?page=2。 静态文件 Web程序不是仅由Python代码和模板组成的。大多数程序还会使用静态文件，例如HTML代码中引用的图片、JavaScript源码文件和CSS。 在Flask——程序的基本结构中查看过run.py程序的URL映射，其中有一个static路由。这是因为对静态文件的引用被当成一个特殊的路由，即/static/。例如，调用url_for(‘static’,filename=’css/styles.css’,_external=True)得到的结果是http://localhost:5000/static/css/styles.css。 默认设置下，Flask在程序根目录中名为static的子目录中寻找静态文件。如果需要，可在static文件夹中使用子文件夹存放文件。服务器收到前面那个URL后，会生成一个响应，包含文件系统中static/css/styles.css文件的内容。 下面的代码展示了如何在程序的基模板中放置favicon.ico图标。这个图标会显示在浏览器的地址栏中。 templates/base.html：定义收藏夹图标 1234567&#123;% block head %&#125;&#123;&#123; super() &#125;&#125;&lt;link rel=&quot;shortcut icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;,filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&lt;link rel=&quot;icon&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;,filename=&apos;favicon.ico&apos;) &#125;&#125;&quot; type=&quot;image/x-icon&quot;&gt;&#123;% endblock %&#125; 图标的声明会插入head块的末尾。注意使用super()保留基模板中定义的块的原始内容。 使用Flask-Moment本地化日期和时间 如果Web程序的用户来自世界各地，那么处理日期和时间可不是一个简单的任务。 服务器需要统一时间单位，这和用户所在的地理位置无关，所以一般使用协调世界时间（Coordinated Universal Time，UTC）。不过用户看到UTC格式的时间会感到困惑，他们更希望看到当地时间，而且采用当地惯用的格式。 要想在服务器上只使用UTC时间，一个优雅的解决方案是，把时间单位发送给Web浏览器，转换成当地时间，然后渲染。Web浏览器可以更好地完成这一任务，因为它能获取用户电脑中的时区和区域设置。 有一个使用JavaScript开发的优秀客户端开源代码库，名为moment.js。(http://momentjs.com/)，它可以在浏览器中渲染日期和时间。Flask-Moment是一个Flask程序扩展，能把moment.js继承到Jinja2模板中。Flask-Moment可以使用pip安装： (venv) [root@server1 myproject]# pip install flask-moment Flask-Moment扩展的初始化方法： 12from flask.ext.moment import Momentmoment = Moment(app) 除了moment.js，Flask-Moment还依赖jquery.js。要在HTML文档的某个地方引入这两个库，可以直接引入，这样可以选择使用哪个版本，也可使用扩展提供辅助函数，从内容分发网络（Content Delivery Network，CDN）中引入通过测试的版本。Bootstrap已经引入了jquery.js，因此只需引入moment.js即可。 在templates/base.html中引入moment.js库: 1234&#123;% block scripts %&#125;&#123;&#123; super() &#125;&#125;&#123;&#123; moment.include_moment() &#125;&#125;&#123;% endblock %&#125; 为了处理时间戳，Flask-Moment向模板开放了moment类。 在run.py中设置响应路由： 12345from datetime import datetime@app.route(&apos;/&apos;)def index(): return render_template(&apos;index.html&apos;,current_time=datetime.utcnow()) 在templates/index.html中使用Flask-Moment渲染时间戳： 12&lt;p&gt;The local date and time is &#123;&#123; moment(current_time).format(&apos;LLL&apos;) &#125;&#125;.&lt;/p&gt;&lt;p&gt;That was &#123;&#123; moment(current_time).fromNow(refresh=True) &#125;&#125;&lt;/p&gt; format(‘LLL’)根据客户端电脑中的时区和区域设置渲染日期和时间。参数决定了渲染的方式，’L’到’LLLL’分别对应不同的复杂度。format()函数还可以接受自定义的格式说明符。 第二行中的fromNow()渲染相对时间戳，而且会随着时间的推移自动刷新显示的时间。这个时间戳最开始显示为“a few seconds ago”，但指定refresh参数后，其内容会随着时间的推移而更新。如果一直待在这个页面，几分钟后，会看到显示的文本编程”a minute ago”“2 minutes ago”等。 Flask-Moment实现了moment.js中的format()、fromNow()、fromTime()、calender()、valueOf()和unix()方法。具体的格式化选项可以查阅http://momentjs.com/docs/#/displaying/ Flask-Moment假定服务端程序处理的时间戳是“纯正”的datetime对象，且使用UTC表示。纯正的时间戳，英文为navie time，指不包含时区的时间戳；细致的时间戳，英文为aware time，指包含时区的时间戳。 Flask-Moment渲染的时间戳可实现多种语言的本地化。语言可在模板中选择，把语言代码传给lang()函数即可： 1&#123;&#123; moment.lang(&apos;es&apos;) &#125;&#125; EOF 本文作者：Koen 参考书籍：《Flask Web开发——基于Python的Web应用开发实战》]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask——程序的基本结构]]></title>
    <url>%2Fck74yvgoc000pdhkcdzlrfrmv.html</url>
    <content type="text"><![CDATA[初始化 所有Flask都必须创建一个程序实例。Web服务器使用一种名为Web服务器网关接口的（Web Server Gateway Interface，WSGI）的协议，把接收自客户端的所有请求都转交给这个对象处理。程序实例是Flask类的对象，经常使用下述代码构建： 12from flask import Flaskapp = Flask(__name__) Flask类的构造函数只有一个必须指定的参数，即程序主模块或包的名字。在大多数程序中，Python的__name__变量就是所需的值。 将构造函数的name参数传给Flask程序，Flask可以用这个参数决定程序的根目录，以便稍后能够找到相对于程序根目录的资源文件位置。 路由与视图函数 客户端（例如Web浏览器）把请求发送给Web服务器，Web服务器再把请求发送给Flask程序实例。程序实例需要知道对每个URL请求运行哪些代码，所以保存了一个URL到Python函数的映射关系。处理URL和函数之间关系的程序称为路由 在Flask程序中定义路由的最简便的方式，是使用程序实例提供的app.route修饰器，把修饰器的函数注册为路由。例如： 123@app.route(&apos;/&apos;)def index(): return &apos;&lt;h1&gt;Hello World!&lt;/h1&gt;&apos; 修饰器是Python语言的标准特性，可以使用不同的方式修改函数的行为。惯常用法是使用修饰器把函数注册为事件的处理程序。 前例把index()函数注册为程序根地址的处理程序。如果部署程序的服务器域名为www.example.com，在浏览器中访问http://www.example.com后，会触发服务器执行index()函数。这个函数的返回值称为**响应**，是客户端接收到的内容。如果客户端是Web浏览器，响应就是显示给用户查看的文档。 像index()这样的函数称为视图函数（view function）。视图函数返回的响应可以是包含HTML的简单字符串，也可以是复杂的表单。 另外，Flask还支持包含可变部分的URL，只需在route修饰器中使用特殊的句法即可。例如： 123@app.route(&apos;/user/&lt;name&gt;&apos;)def user(name): return &apos;&lt;h1&gt;Hello,%s!&lt;/h1&gt;&apos; %name 尖括号中的内容是动态部分，任何能匹配静态部分的URL都会映射到这个路由上。调用试图函数时，Flask会将动态部分作为参数传入函数。在这个视图函数中，参数用于生成针对个人的欢迎消息。路由中的动态部分默认使用字符串，不过也可使用类型定义。例如，路由/user/int:id只会匹配动态片段id为整数的URL。Flask支持在路由中使用int、float和path类型。path类型也是字符串，但不把斜线视作分隔符，而将其当做动态片段的一部分。 启动服务器 程序实例用run方法启动Flask集成的开发Web服务器： 12if __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) __name__==&#39;__main__&#39;是Python的惯常用法，在这里确保直接执行这个脚本时才启动开发Web服务器。如果这个脚本由其他脚本引入，程序假定父级脚本会启动不同的服务器，因此不会执行app.run()。 服务器启动后，会进入轮询，等待并处理请求。轮询会一直运行，直到程序停止，比如按Ctrl-C键。 有一些选项参数可被app.run()函数接受用于设置Web服务器的操作模式。在开发过程中启动调试模式会带来一些便利，比如说激活调试器和重载程序。要想启动调试模式，我们可以把debug参数设为True。 一个完整的程序 前面介绍了Flask Web程序的不同组成部分，现在尝试开发一个完整的程序，代码如下： 123456789from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): return &apos;&lt;h1&gt;Hello World!&lt;/h1&gt;&apos;if __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 使用下述命令启动程序： # python run.py * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) * Restarting with stat * Debugger is active! * Debugger pin code: 953-142-708 程序运行后，打开浏览器，在地址栏中输入http://:5000，能访问到Hello World页面，如果输入了其他地址，程序将不知道如何处理，因此会向浏览器返回错误代码404。 继续向上述代码中添加一个动态路由，访问这个地址http://:5000/user/xautlmx，你会看到一则针对个人的欢迎消息。 12345678910111213from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): return &apos;&lt;h1&gt;Hello World!&lt;/h1&gt;&apos;@app.route(&apos;/user/&lt;name&gt;&apos;)def user(name): return &apos;&lt;h1&gt;Hello,%s!&lt;/h1&gt;&apos; %nameif __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 请求-响应循环 程序和请求上下文Flask从客户端收到请求时，要让视图函数能访问一些对象，这样才能处理请求。请求对象就是一个很好的例子，它封装了客户端发送的HTTP请求。 要想让视图函数能够访问请求对象，一个显而易见的方式是将其作为参数传入视图函数，不过这会导致程序中的每个视图函数都增加一个参数。除了访问请求对象，如果视图函数在处理请求时还要访问其他对象，情况会变得更糟。 为了避免大量可有可无的参数把视图函数弄得一团糟，Flask使用上下文临时把某些对象变为全局可访问。有了上下文，就可以写出下面的视图函数： 12345678910from flask import Flask,requestapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): user_agent = request.headers.get(&apos;User-Agent&apos;) return &apos;&lt;h1&gt;Your browser is %s&lt;/h1&gt;&apos; %user_agentif __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 注意在这个视图函数中我们如何把request当做全局变量使用。事实上，request不可能是全局变量。试想，在多线程服务器中，多个线程同时处理不同客户端发送的不同请求时，每个线程看到的request对象必然不同。Flask使用上下文让特定的变量在一个线程中全局可访问，与此同时却不会干扰其他线程。 线程是可单独管理的最小指令集。进程经常使用多个活动线程，有时还会共享内存或文件句柄等资源。多线程Web服务器会创建一个线程池，再从线程池中选择一个线程用于处理接收到的请求。 在Flask中有两种上下文：程序上下文和请求上下文。 变量名 上下文 说明 current_app 程序上下文 当前激活程序的程序实例 g 程序上下文 处理请求时用作临时存储的对象。每次请求都会重设这个变量 request 请求上下文 请求对象，封装了客户端发出的HTTP请求中的内容 session 请求上下文 用户会话，用于存储请求之间需要“记住”的值的字典 Flask在分发请求之前激活（或推送）程序和请求上下文，请求处理完成后再将其删除。程序上下文被推送后，就可以在线程中使用current_app和g变量。类似地，请求上下文被推送后，就可以使用request和session变量。如果使用这些变量时我们没有激活程序上下文或请求上下文，就会导致错误。 下面这个Python shell会话演示了程序上下文的使用方法（run是上述程序Flask程序的文件名）： &gt;&gt;&gt; from run import app &gt;&gt;&gt; from flask import current_app &gt;&gt;&gt; current_app.name Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/root/myproject/venv/lib/python2.7/site-packages/werkzeug/local.py&quot;, line 343, in __getattr__ return getattr(self._get_current_object(), name) File &quot;/root/myproject/venv/lib/python2.7/site-packages/werkzeug/local.py&quot;, line 302, in _get_current_object return self.__local() File &quot;/root/myproject/venv/lib/python2.7/site-packages/flask/globals.py&quot;, line 34, in _find_app raise RuntimeError(&apos;working outside of application context&apos;) RuntimeError: working outside of application context &gt;&gt;&gt; app_ctx = app.app_context() &gt;&gt;&gt; app_ctx.push() &gt;&gt;&gt; current_app.name &apos;run&apos; &gt;&gt;&gt; app_ctx.pop() 请求调度程序收到客户端发来的请求时，要找到处理该请求的视图函数。为了完成这个任务，Flask会在程序的URL映射中查找请求的URL。URL映射是URL和视图函数之间的对应关系。Flask使用app.route修饰器或者非修饰器形式的app.add_url_rule()生成映射。 要想查看Flask程序中的URL映射是什么样子，我们可以在Python shell中检查为run.py生成的映射。测试之前，确保激活了虚拟环境： # python &gt;&gt;&gt; from run import app &gt;&gt;&gt; app.url_map Map([&lt;Rule &apos;/&apos; (HEAD, OPTIONS, GET) -&gt; index&gt;, &lt;Rule &apos;/static/&lt;filename&gt;&apos; (HEAD, OPTIONS, GET) -&gt; static&gt;]) /路由在程序中使用app.route修饰器定义。/static/&lt;filename&gt;路由是Flask添加的特殊路由，用于访问静态文件 URL映射中的HEAD、OPTIONS、GET是请求方法，由路由进行处理。Flask为每个路由都指定了请求方法，这样不同的请求方法发送到相同的URL上时，会使用不同的视图函数进行处理。HEAD和OPTIONS方法由Flask自动处理，因此可以说，在这个程序中，URL映射中的2个路由都使用GET方法。 请求钩子有时在处理请求之前或之后执行代码会很有用。例如，在请求开始时，我们可能需要创建数据库连接或者认证发起请求的用户。为了避免在每个视图函数中都使用重复的代码，Flask提供了注册通用函数的功能，注册的函数可在请求被分发到视图函数之前或之后调用。 请求钩子使用修饰器实现。Flask至此以下4种钩子： before_first_request：注册一个函数，在处理第一个请求之前运行。 before_request：注册一个函数，在每次请求之前运行。 after_request：注册一个函数，如果没有未处理的异常抛出，在每次请求之后运行。 teardown_request：注册一个函数，即使有未处理的异常抛出，也在每次请求之后运行。 在请求钩子函数和视图函数之间共享数据一般使用上下文全局变量g。例如：before_request处理程序可以从数据库中加载已登录用户，并将其保存到g.user中。随后调用视图函数时，视图函数再使用g.user获取用户。 响应Flask调用视图函数后，会将其返回值作为响应的内容。大多数情况下，响应就是一个简单的字符串，作为HTML页面回送客户端。 但HTTP协议需要的不仅是作为请求响应的字符串。HTTP响应中一个很重要的部分是状态码，Flask默认设为200，这个代码表明请求已经被成功处理。 如果视图函数返回的响应需要使用不同的状态码，那么可以把数字代码作为第二个返回值，添加到响应文本之后。例如，下述视图函数返回一个404状态码，表示请求无效： 12345678910from flask import Flask,requestapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): user_agent = request.headers.get(&apos;User-Agent&apos;) return &apos;&lt;h1&gt;Your browser is %s&lt;/h1&gt;&apos; %user_agent,404if __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 视图函数返回的响应还可以接受第三个参数，这是一个由首部（header）组成的字典，可以添加到HTTP响应中。一般情况下并不需要这么做。 如果不想返回由1个、2个或3个值组成的元组，Flask试图函数还可以返回Response对象。make_response()函数可接受1个、2个或3个参数（和视图函数的返回值一样），并返回一个Response对象。有时我们需要在视图函数中进行这种转换，然后在响应对象上调用各种方法，进一步设置响应。下例创建了一个响应对象，然后设置了cookie： 1234567891011from flask import Flask,make_responseapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): response = make_response(&apos;&lt;h1&gt;This document carries a cookie!&lt;/h1&gt;&apos;) response.set_cookie(&apos;answer&apos;,&apos;42&apos;) return responseif __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 有一种名为重定向的特殊响应类型。这种响应没有页面文档，只告诉浏览器一个新地址用以加载新页面。重定向经常在Web表单中使用。 重定向经常使用302状态码表示，指向的地址由Location首部提供。重定向响应可以使用3个值形式的返回值生成，也可在Response对象中设定。不过，由于使用频繁，Flask提供了redirect()辅助函数，用于生成这种响应： 123456789from flask import Flask,redirectapp = Flask(__name__)@app.route(&apos;/&apos;)def index(): return redirect(&apos;http://www.baidu.com&apos;)if __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 还有一种特殊的响应由abort函数生成，用于处理错误。在下面这个例子中，如果URL中动态参数id不存在，就返回状态码404： 123456789101112from flask import Flask,abortapp = Flask(__name__)@app.route(&apos;/user/&lt;id&gt;&apos;)def get_user(id): if id: return &apos;&lt;h1&gt;Hello %s&lt;/h1&gt;&apos; %id else: abort(404)if __name__ == &apos;__main__&apos;: app.run(debug=True,host=&apos;0.0.0.0&apos;) 注意：abort不会把控制权交还给调用它的函数，而是抛出异常把控制权交给Web服务器。 Flask扩展 Flask被设计为可扩展形式，故而没有提供一些重要的功能，例如数据库和用户认证，所以开发者可以自由选择最合适程序的包，或者按需求自行开发。 社区成员开发了大量不同用途的扩展，如果这还不能满足需求，你还可使用所有Python标准包或代码库。 使用Flask-Script支持命令行选项Flask的开发Web服务器支持很多启动设置选项，但只能在脚本中作为参数传给app.run()函数。这种方式并不十分方便，传递设置选项的理想方式是使用命令行参数。 Flask-Script是一个Flask扩展，为Flask程序添加了一个命令行解释器。Flask-Script自带了一组常用选项，而且还支持自定义命令。 Flask-Script扩展使用pip安装： (venv) [root@server1 myproject]# pip install flask-script 然后更改程序： 1234567891011from flask import Flask,abortfrom flask.ext.script import Managerapp = Flask(__name__)manager = Manager(app)@app.route(&apos;/&apos;)def index(): return &apos;&lt;h1&gt;Hello World!&lt;/h1&gt;&apos;if __name__ == &apos;__main__&apos;: manager.run() 专为Flask开发的扩展都包含在flask.ext命名空间下。Flask-Script输出了一个名为Manager的类，可从flask.ext.script中引入。 这个扩展的初始化方法也适用于其他很多扩展：把程序实例作为参数传给构造函数，初始化主类的实例。创建的对象可以在各个扩展中使用。在这里，服务器由manager.run()启动，启动后就能解析命令行了。 修改之后的程序可以使用一组基本命令行选项。现在运行run.py，会显示一个用法消息： # python run.py usage: run.py [-?] {shell,runserver} ... positional arguments: {shell,runserver} shell Runs a Python shell inside Flask application context. runserver Runs the Flask development server i.e. app.run() optional arguments: -?, --help show this help message and exit shell命令用于在程序的上下文中启动Python shell会话。可以使用这个会话中运行维护任务或测试，还可以调试异常。下面列举几个常用的命令行选项和参数： runserver 以调试模式启动Web服务器 runserver –host 指定Web服务器再哪个网络接口上监听来自客户端的连接 runserver –port 指定Web服务器监听的端口 EOF 本文作者：Koen 参考书籍：《Flask Web开发——基于Python的Web应用开发实战》]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask开发环境搭建]]></title>
    <url>%2Fck74yvgoa000kdhkcjjmlwcgl.html</url>
    <content type="text"><![CDATA[安装需要的类库及Python2.X 安装必要的开发包 12yum groupinstall &quot;Development tools&quot; -yyum install zlib-devel bzip2-devel pcre-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel wget -y RedHat6.X自带Python2.6.6，但我们可以再安装更新版本的Python，此处以为安装目前最新的Python2.7.11为例，Python3版本的安装请参照RedHat/Ubuntu下源码编译安装Python3.X 123456cdwget https://www.python.org/ftp/python/2.7.11/Python-2.7.11.tgztar zxf Python-2.7.11.tgzcd Python-2.7.11./configure --prefix=/usr/localmake &amp;&amp; make install 安装完毕后，可是使用python2.7命令进入python2.7的环境 安装Python包管理 easy_install包：https://pypi.python.org/pypi/distribute 安装easy_install后方便安装Python的开发包 123456cdwget https://pypi.python.org/packages/source/d/distribute/distribute-0.6.49.tar.gztar zxf distribute-0.6.49.tar.gzcd distribute-0.6.49python2.7 setup.py installeasy_install --version #能查看到easy_install的版本信息说明安装成功 注：下载distribute时可能会出现如下错误： ERROR: certificate common name “www.python.org” doesn’t match requested host name “pypi.python.org”. 解决方法： 只需在wget https://pypi.python.org/packages/source/d/distribute/distribute-0.6.49.tar.gz后添加--no-check-certificate参数即可 1wget https://pypi.python.org/packages/source/d/distribute/distribute-0.6.49.tar.gz --no-check-certificate 注:必须用python2.7命令运行安装程序，否则将安装到默认的2.6环境内 pip官方文档：https://pip.pypa.io/en/stable/ 安装pip的好处是可以pip list、pip uninstall管理Python包， easy_install没有这个功能，只有uninstall 12easy_install pippip --version #能查看到pip的版本信息说明安装成功 安装使用Python虚拟环境virtualenv virtualenv官方文档：https://virtualenv.pypa.io/en/latest/ 虚拟环境是Python解释器的一个私有副本，在这个环境中你可以安装私有包，而且不会影响系统中安装的全局Python解释器。 虚拟环境非常有用，可以在系统的Python解释器中避免包的混乱和版本的冲突，为每个程序单独创建虚拟环境可以保证程序只能访问虚拟环境中的包，从而保持全局解释器的干净整洁，使其只作为创建（更多）虚拟环境的源。使用虚拟环境还有个好处，那就是不需要管理员权限。虚拟环境使用第三方实用工具virtualenv创建，首先必须安装virtualenv，安装方法如下： 12pip install virtualenvvirtualenv --version #能查看到virtualenv的版本信息说明安装成功 新建一个项目文件夹，用来保存项目代码： 12mkdir myprojectcd myproject/ 使用virtualenv命令在myproject文件夹中创建Python虚拟环境。这个命令只有一个必需的参数，即虚拟环境的名字。创建虚拟环境后，当前文件夹中会出现一个子文件夹，名字就是上述命令中指定的参数，与虚拟环境相关的文件都保存在这个子文件夹中。按照惯例，一般虚拟环境会被命名为venv： 1234# virtualenv venvNew python executable in /root/myproject/venv/bin/python2.7Also creating executable in /root/myproject/venv/bin/pythonInstalling setuptools, pip, wheel...done. 现在myproject文件夹中就有了一个名为venv的子文件夹，它保存一个全新的虚拟环境，其中有一个私有的Python解释器。在使用这个虚拟环境之前，你需要先将其“激活”。命令如下： 1source venv/bin/activate 虚拟环境被激活后，其中Pythoon解释器的路径就被添加到PATH中，但这种改变不是永久性的，它只会影响当前的命令行会话。为了提醒你已经激活了虚拟环境，激活虚拟环境的命令会修改命令行提示符，加入环境名： (venv) [root@server1 myproject]# 当虚拟环境中的工作完成后，如果你想回到全局的Python解释器中，可以在命令行提示符下输入deactivate。 使用pip安装Python包 大多数Python包都使用pip实用工具安装，使用virtualenv创建虚拟环境时会自动安装pip。激活虚拟环境后，pip所在的路径会被添加进PATH。 执行如下命令可在虚拟环境中安装Flask： (venv) [root@server1 myproject]# pip install flask 执行上述命令，你就在虚拟环境中安装Flask及其依赖了。要想验证Flask是否正确安装，可以启动Python解释器，尝试导入Flask： (venv) [root@server1 myproject]# python Python 2.7.11 (default, Mar 14 2016, 13:40:19) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2 Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; import flask &gt;&gt;&gt; 如果没有看到错误提醒，就说明Flask安装成功，可以在此虚拟环境中进行Flask Web开发了。 EOF 本文作者：Koen 参考链接：http://www.cnblogs.com/xiongpq/p/3381069.html]]></content>
      <categories>
        <category>Web阵地</category>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符编码：ASCII、Unicode和UTF-8]]></title>
    <url>%2Fck74yvgp30035dhkc24ilb0th.html</url>
    <content type="text"><![CDATA[ASCII码 我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从00000000到11111111。 上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系做了统一规定。这被称为ASCII码，一直沿用至今。 ASCII码一共规定了128个字符的编码，比如空格”SPACE”是32（二进制00100000），大写的字符A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。 非ASCII编码 英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。 但是，这里又出现了新的问题。不同的国家有不同的字符，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0~127表示的符号是不一样的，不一样的只是128~255的这一段。 至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256*256=65536个符号。 虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。 Unicode 正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。 可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码。 Unicode当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如,U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字”严”。具体的符号对应表，可以查询http://www.unicode.org/，或者专门的汉字对应表 Unicode的问题 需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。 比如，汉字”严”的unicode是十六进制4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。 这里就有两个严重的问题，第一个问题是，如何才能区别Unicode和ASCII？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果Unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 它们造成的结果是：1）出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。2）Unicode在很长一段时间内无法推广，直到互联网的出现。 UTF-8 互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种Unicode的实现方式。其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有两条： 对于单字节的符号，字节的第一位设为0，后面7位为这个的符号的Unicode码。因此，对于英语字母，UTF-8编码和ASCII码是相同的。 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的Unicode码。下表总结了编码规则，字母x表示可用编码的位。 Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）——————–+———————————————0000 0000-0000 007F | 0xxxxxxx0000 0080-0000 07FF | 110xxxxx 10xxxxxx0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 根据上表，截图UTF-8编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。 下面，还是以汉字”严”为例，演示如何实现UTF-8编码。 已经”严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此”严”的UTF-8编码需要三个字节，即格式是”1110xxxx 10xxxxxx 10xxxxxx”。然后，从”严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，”严”的UTF-8编码是”11100100 10111000 10100101”，转换成十六进制就是E4B8A5。 Unicode与UTF-8之间的转换 可以看到”严”的Unicode码是4E25，UTF-8编码是E4B8A5，两者是不一样的。它们之间的转换可以通过程序实现。 在Windows平台下，有一个最简单的转化方法，就是使用内置的记事本小程序。打开文件后，点击”文件”菜单中的”另存为”命令，会跳出一个对话框，在最底部有一个”编码”的下拉条。 里面有四个选项：ANSI、Unicode、Unicode big endian和UTF-8 ANSI是默认的编码方式。对于英文文件是ASCII编码，对于简体中文文件是GB2312编码（只针对Windows简体中文版，如果是繁体中文版会采用BIG5码）。 Unicode编码指的是UCS-2编码方式，即直接用两个字节存入字符的Unicode码。这个选项用的little endian格式。 Unicode big endian编码与上一个选项相对应。 UTF-8编码 选择完”编码方式”后，点击”保存”按钮，文件的编码方式就立刻转换好了。 Little endian和Big endian Unicode码可以采用UCS-2格式直接存储。以汉字”严”为例，Unicode码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25,。存储的时候，4E在前，25在后，就是Big endian方式；25在前，4E在后，就是Little endian方式。 这两个古怪的名称来自英国作家斯威夫特的《格列佛游记》。在该书中，小人国里爆发了内战，战争起因是人们争论，吃鸡蛋时究竟是从大头（Big-Endian）敲开还是从小头（Little-Endian）敲开。为了这件事情，前后爆发了六次战争，一个皇帝送了命，另一个皇帝丢了王位。 因此，第一个字节在前，就是”大头方式”（Big endian），第二个字节在前就是”小头方式”（Little endian）。 那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？ Unicode规范中定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（ZERO WIDTH NO-BREAK SPACE），用FEFF表示。这正好是两个字节，而且FF比FE大1。 如果一个文本文件的头两个字节是FE FF，就表示该文件采用大头方式；如果头两个字节是FF FE，就表示该文件采用小头方式。 EOF 本文作者：Koen 参考链接：http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html]]></content>
      <categories>
        <category>通用技巧</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>字符编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下常用I/O模型]]></title>
    <url>%2Fck74yvgof000wdhkcneblam6q.html</url>
    <content type="text"><![CDATA[Linux下大概有同步阻塞、同步非阻塞、异步阻塞和异步非阻塞四种I/O模型。 同步与异步 在学校食堂排队等候打饭，必须等到队列前面没人了才会轮到自己，这场景就是同步。如果换成去餐馆，不需要排队直接点菜，菜好了之后服务员直接给我送上来，这种场景就是异步。异步与同步之间的区别就是消息是如何通知的，在上面场景中，排队打饭需要自己去关注是不是轮到我们了，而餐馆点菜是由服务员通知我们菜好了。 所以说在同步的情况下，是由处理消息者自己去等待消息是否被触发，而在异步情况下，是由触发机制来通知处理消息者，所以在异步情况下，需要一个触发机制，在Linux中的常用select/poll等IO多路复用机制中就是fd（文件描述符），触发机制就是通过fd找到处理该fd的函数。 阻塞与非阻塞 无论是排队打饭还是餐馆点菜，如果在等候过程中不能做其它事，这种情况就是阻塞；当然实际的情况是我们在等候的过程中还可以做其它很多事，这种情况就是非阻塞。 I/O模型 Linux异步I/O是Linux内核中提供的一个相当新的增强。是2.6版本内核的一个标准特性，异步非阻塞I/O背后的基本思想是允许进程发起很多I/O操作，而不用阻塞或等待任何操作完成。稍后或在接收到I/O操作完成的通知时，进程就可以检索I/O操作的结果。 本文将试图介绍最常用的一些模型来解释它们与异步I/O之间的区别。下图给出了同步和异步模型，以及阻塞和非阻塞的模型。 每个I/O模型都有自己的使用模式，它们对于特定的应用程序都有自己的优点。 同步阻塞I/O 最常用的一个模型是同步阻塞I/O模型。在这个模型中，用户空间的应用程序执行了一个系统调用，这会导致应用程序阻塞。这意味着应用程序会一直阻塞，直到系统调用完成为止（数据传输完成或发生错误）。调用应用程序处于一种不再消费CPU而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。 下图给出了传统的阻塞I/O模型，这也是目前应用程序中最为常用的一种模型。其行为非常容易理解，其用法对于典型的应用程序来说都非常有效。在调用read系统调用时，应用程序会阻塞并对内核进行上下文切换。然后会触发读操作，当响应返回时（从我们正在从中读取的设备中返回），数据就被移动到用户空间的缓冲区中。然后应用程序就会解除阻塞（read调用返回）。 从应用程序的角度来说，read调用会延续很长时间。实际上，在内核执行读操作和其他工作时，应用程序的确会被阻塞。 同步非阻塞I/O 同步阻塞I/O的一种效率稍低的变种就是同步非阻塞I/O。在这种模型中，设备以非阻塞的形式打开的。这意味着I/O操作不会立即完成，read操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGAIN或EWOULDBLOCK）,如下图所示： 非阻塞的实现是I/O命令可能并不会立即满足，需要应用程序调用许多次来等待操作完成。这可能效率不高，因为在很多情况下，当内核执行这个命令时，应用程序必须要进行忙绿等待，直到数据可用位置，或者试图执行其他工作。正如上图所示的一样，这个方法可以引入I/O操作的延时，因为数据在内核中变为可用到用户调用read返回数据之间存在一定的间隔，这会导致整体数据吞吐量的降低。 异步阻塞I/O 另外一个阻塞解决方案是带有阻塞通知的非阻塞I/O。在这种模型中，配置的是非阻塞I/O，然后使用阻塞select系统调用来确定一个I/O描述符何时有操作。使select调用非常有趣的是它可以用来为多个描述符提供通知，而不仅仅为一个描述符提供通知。对于每个提示符来说，我们可以请求这个描述符可以写数据、有读数据可用以及是否发生错误的通知。 select调用的主要问题是它的效率不是非常高。尽管这是异步通知使用的一种方便模型，但是对于高性能的I/O操作来说不建议使用。 异步非阻塞I/O 最后，异步非阻塞I/O模型是一种处理与I/O重叠进行的模型。读请求会立即返回，说明read请求已经成功发起了。在后台完成读操作时，应用程序然后会执行其他处理操作。当read的响应到达时，就会产生一个信号或执行一个基于线程的回调函数来完成这次I/O处理过程 在一个进程中为了执行多个I/O请求而对计算操作和I/O处理进行重叠处理的能力利用了处理速度与I/O速度之间的差异。当一个或多个I/O请求挂起时，CPU可以执行其他任务，或者更为常见的是在发起其他I/O的同时对已经完成的I/O进行操作。 EOF 本文作者：Koen 参考链接：http://blogread.cn/it/article/5357?f=wb]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统基础之inode和dentry]]></title>
    <url>%2Fck74yvgoe000udhkczovsme61.html</url>
    <content type="text"><![CDATA[inode和dentry在VFS和实体的文件系统（ext2、ext3等）中都是比较重要的概念。首先看一下虚拟文件系统的标准定义： 虚拟机文件系统（英语：Virtual File System，缩写为VFS），又称虚拟文件切换系统（Virtual Filesystem Switch），是操作系统的文件系统虚拟机层，在其下是实体的文件系统。虚拟文件系统的主要功能，在于让上层的软件，能够用单一的方式来跟底层不同的文件系统沟通。在操作系统与之下的各种文件系统之间，虚拟文件系统提供了标准的操作接口，让操作系统能够很快的支持新的文件系统。 VFS在Linux系统中的结构为： 一般是这样来描述inode的：inode是内核文件对象的元数据。inode中不包括文件的数据和文件名字信息。inode中只包含数据块的位置信息，数据结构相对稳定，其中没有数据和文件名等变长数据，可以固定其大小，进而可以实现将整个文件系统中的inode按照一定的组织方式来集中存储在硬盘起始的一个，文件系统加载时，可以方便查找。 inode仅仅只是保存了文件对象的属性信息，包括：权限、属组、数据块的位置、时间戳等信息。但是并没有包含文件名，文件在文件系统的目录树中所处的位置信息。那么内核又是怎么管理文件系统的目录树的呢？ 目录项在内核中起到了连接不同的文件对象inode的作用，进而起到了维护文件系统目录树的作用。dentry是一个纯粹的内存结构，由文件系统在提供文件访问的过程中在内存中直接建立。dentry中包含了文件名，文件的inode号等信息。 对于POSIX标准定义了文件系统的inode。VFS接口即是符合POSIX标准的，实体文件系统只要能对接上VFS，即可符合POSIX标准。因此，一般而言我们研究VFS文件系统即可了解大部分文件系统的结构。而在VFS中，定义了规范化的inode结构和dentry。 在读取一个文件时，总是从根目录开始读取，每一个目录或者文件，在VFS中，都是一个文件对象，每一个文件对象都有唯一的一个inode与之对应。根目录的inode号为0，在superblock里，可以很快根据inode号索引到具体的inode，因此读取到的第一个inode就是根目录的。读取到了该目录后，内核对象会为该文件对象建立一个dentry，并将其缓存起来，方便下一次读取时直接从内存中取。而目录本身也是一个文件，目录文件的内容即是该目录下的文件的名字与inode号，目录文件的内容就像一张表，记录的文件名与其inode号之间的映射关系。根据路径即可找到当前需要读取的下一级文件的名字和inode，同时继续为该文件建立dentry，dentry结构是一种含有指向父节点和子节点指针的双向结构，多个这样的双向结构构成一个内存里面的树状结构，也就是文件系统的目录在内存中的缓存了。有了这个缓存，我们在访问文件系统时，通常都非常快捷。 有了inode和dentry，也就非常容易理解文件的链接了。我们知道软链接，是一个特殊的文件，该文件通过内容指向目标文件。因此软链接有自己的inode，有自己的内容。其内容记录的是目标文件的inode号和自身的名字。软链接是一种特殊的文件。而硬链接则不一样，硬链接是文件的别名，硬链接不是一个完整的文件对象，硬链接只是将自己的名字写在上级目录的内容（文件名与inode号的映射表）中。而其inode号即是目标文件的inode。这样硬链接与目标文件一起共用一个inode，使用引用计数来管理硬链接。 EOF 本文作者：Koen 参考链接：http://blogread.cn/it/article/7911?f=wb]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedHat/Ubuntu/Windows下安装Docker]]></title>
    <url>%2Fck74yvgon001pdhkcpbmhfmxa.html</url>
    <content type="text"><![CDATA[什么是Docker Docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似iPhone的app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架包括系统。 关于Docker的更多介绍可以点击此处 Docker官网：http://www.docker.com/ 安装Docker RedHat6.X下安装Docker由于内核版本问题，最初仅Ubuntu可以较好的支持Docker。不过，由于RedHat系列OS（REHL、CentOS）是目前主流的Linux服务器操作系统，所以令RedHat系列OS支持Docker很有必要。目前Docker和RedHat已经展开深入合作，并在2013年年底推出了可以在RedHat系列OS上运行的Docker0.7。 目前有一些博客介绍了如何在CentOS上安装Docker，例如http://www.linuxidc.com/Linux/2014-01/95512.htm。但是这些博客安装方法是在升级操作系统内核版本的基础上完成。问题是，我们不可以随意升级生产环境的操作系统内核版本，而且Docker0.7的主旨就是：Docker使用者可以在不升级内核的前提下，在RedHat环境中使用Docker。因此，这里将介绍如何在RedHat6.X/CentOS6.X环境下，安装新版本的Docker。 确保系统中有curl命令 # yum install curl -y 下载并安装Docker # curl -fsSL https://get.docker.com/ | sh + sh -c &apos;sleep 3; yum -y -q install docker-engine&apos; This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. warning: rpmts_HdrFromFdno: Header V4 RSA/SHA1 Signature, key ID 2c52609d: NOKEY Importing GPG key 0x2C52609D: Userid: &quot;Docker Release Tool (releasedocker) &lt;docker@docker.com&gt;&quot; From : https://yum.dockerproject.org/gpg If you would like to use Docker as a non-root user, you should now consider adding your user to the &quot;docker&quot; group with something like: sudo usermod -aG docker your-user Remember that you will have to log out and back in for this to take effect! 出现类似以上输出说明安装成功。 启动Docker服务 # /etc/init.d/docker start 启动docker服务 # /etc/init.d/docker status 查看docker服务状态 docker dead but pid file exists 咦~怎么出现这样的错误提示，赶紧查看下错误日志~ # tail -f /var/log/docker \nFri Dec 4 17:54:39 CST 2015\n time=&quot;2015-12-04T17:54:39.795556694+08:00&quot; level=warning msg=&quot;You are running linux kernel version 2.6.32-431.el6.x86_64, which might be unstable running docker. Please upgrade your kernel to 3.10.0.&quot; time=&quot;2015-12-04T17:54:39.796561487+08:00&quot; level=info msg=&quot;Listening for HTTP on unix (/var/run/docker.sock)&quot; /usr/bin/docker: relocation error: /usr/bin/docker: symbol dm_task_get_info_with_deferred_remove, version Base not defined in file libdevmapper.so.1.02 with link time reference 在错误日志中发现version Base not defined in file libdevmapper.so.1.02 with link time reference，难道是少了libdevmapper.so.1.02？那就装上去试试。 # yum install libdevmapper.so.1.02 -y # /etc/init.d/docker restart Stopping docker: [FAILED] Starting docker: [ OK ] # /etc/init.d/docker status docker dead but pid file exists 发现问题依旧，使用tail -f /var/log/docker查看错误日志仍然有以上遇到的提示输出，于是网上查了下资料http://stackoverflow.com/questions/27216473/docker-1-3-fails-to-start-on-rhel6-5原来是RedHat6.X中自带的device-mapper-libs的版本过低了，更新下即可。下载链接： device-mapper-1.02.95-2.el6.x86_64.rpmdevice-mapper-libs-1.02.95-2.el6.x86_64.rpm 安装device-mapper # rpm -ivh device-mapper-1.02.95-2.el6.x86_64.rpm device-mapper-libs-1.02.95-2.el6.x86_64.rpm --force # /etc/init.d/docker restart Stopping docker: [FAILED] Starting docker: [ OK ] # /etc/init.d/docker status docker (pid 1584) is running... 问题解决，Docker成功启动了！最后再次验证下Docker是否正常工作： # docker run hello-world Unable to find image &apos;hello-world:latest&apos; locally latest: Pulling from hello-world 3f12c794407e: Pull complete 975b84d108f1: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker Hub account: https://hub.docker.com For more examples and ideas, visit: https://docs.docker.com/userguide/ Ubuntu下安装Docker 确保系统中有curl命令 $ sudo apt-get update $ sudo apt-get install curl -y 下载并安装Docker $ sudo curl -fsSL https://get.docker.com/ | sh 启动Docker服务 其实在Ubuntu中安装Docker后会默认启动Docker，你可以使用sudo service docker status查看 $ sudo service docker status docker start/running, process 7934 如果需要手动启动或者重启Docker可以使用sudo service docker start或sudo service docker restart 验证Docker是否正常工作： $ sudo docker run hello-world Unable to find image &apos;hello-world:latest&apos; locally latest: Pulling from library/hello-world 03f4658f8b78: Pull complete a3ed95caeb02: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker Hub account: https://hub.docker.com For more examples and ideas, visit: https://docs.docker.com/userguide/ Windows下安装Docker要在Windows下运行Docker，要求操作系统一定要是Win7及以上版本的64位操作系统，另外，你必须确保你的电脑支持硬件虚拟化技术并且已经开启该功能。 下载Docker Toolbox 下载链接：https://www.docker.com/products/docker-toolbox 安装Docker Toolbox 运行DockerToolbox安装包 点击”Next” 点击”Browse…”选择安装位置，然后点击”Next” 选择所要安装的组件，如果你的电脑上已经安装了某些组件可以把对应的勾号去掉，然后点击”Next”(我电脑上原本已经安装有Git，所以将Git前的勾号去掉) 点击”Next” 点击”Install” 等待安装完成…. 点击”Finish”完成安装 该安装包安装完成后，系统上会多出三个软件(如果选择安装所有组件的话)： Oracle VM VirtualBox Git Boot2Docker for Windows 桌面上将会多出三个图标: 启动Docker 打开文件资源管理器，切到Docker的安装目录下 运行start.sh 此处可能出现如下错误： Error creating machine:Error in drive during machine creation: Unable to start the VM:... ... Looks like something went wrong... Press any key to continue... 或 Error creating machine: Error in driver during machine creation: Maximum number of retries (5) exceeded Looks like something went wrong... Press any key to continue... 在网上搜索了下问题的解决方法，最终在这里找到了答案：http://superuser.com/questions/996785/docker-toolbox-error-creating-machine-error-in-driver-during-machine-creation 解决方法 打开桌面上的Oracle VM VirtualBox，会看到docker自动新建了一台名为default的虚拟机 右单击此虚拟机，选择”删除” 选择”删除所有文件”，最后重新运行一次start.sh 出现此输出表示docker启动成功~ 利用SSH工具进行管理 在windows命令行进入docker后，不能复制，而且操作也不方便，因此用支持SSH的工具来管理是最方便的，比如SECURECRT, PUTTY，XShell等，具体使用哪个工具看个人喜好. 从上图的位置可查看到IP地址 按照上图设置”名称”和”主机”(名称可以自己随便取名，主机为上面查看到的IP地址) 设置登录用户名和密码 注：默认的用户名和密码是： docker/tcuser 登录后的界面： 验证Docker是否正常工作： 自此你就可以开始Windows下的Docker之旅了！ 附： 因为我刚才在安装Docker Toolbox的时候没有安装Git，因此桌面上Docker Quickstart Terminal中的目标默认的是&quot;C:\Program Files\Git\bin\bash.exe&quot; --login -i &quot;D:\Program Files (x86)\Docker Toolbox\Docker Toolbox\start.sh&quot;，其中的Git路径是不正确的。 需要手动将其更改为正确的Git路径，例如我电脑上的Git是安装在D:\Program Files (x86)\Git，则需要将Docker Quickstart Terminal中的目标设置为：&quot;D:\Program Files (x86)\Git\Git\bin\bash.exe&quot; --login -i &quot;D:\Program Files (x86)\Docker Toolbox\Docker Toolbox\start.sh&quot; EOF 本文作者：Koen 参考链接： http://blog.csdn.net/zistxym/article/details/42918339 https://docs.docker.com/linux/step_one/ https://docs.docker.com/windows/step_one/]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedHat/Ubuntu下源码编译安装Python3.X]]></title>
    <url>%2Fck74yvgop001udhkcrecudmsl.html</url>
    <content type="text"><![CDATA[下载Python源码包 Python官网：https://www.python.org/Python源码包下载地址：https://www.python.org/downloads/source/ 安装Python 解压Python源码包 RedHat6.X/7.X 1tar zxf Python-3.5.1.tgz Ubuntu 1sudo tar zxf Python-3.5.1.tgz 注：由于我下的源码包是以.tgz为后缀，使用的参数是-zxf，若是其他格式的压缩文件，参数会有不同 编译安装Python RedHat6.X/7.X 12cd Python-3.5.1./configure --prefix=/usr/local/python-3.5.1 --prefix参数可以指定Python的安装目录，若未指定则默认安装在/usr/local/下；更多设置选项可通过./configure --help查找 执行./configure时可能会相继出现如下提示： 解决方法： 12yum install gcc -y./configure --prefix=/usr/local/python-3.5.1 设置好安装目录后进行编译并安装： 1make &amp;&amp; make install Ubuntu 12cd Python-3.5.1/sudo ./configure --prefix=/usr/local/python-3.5.1 --prefix参数可以指定Python的安装目录，若未指定则默认安装在/usr/local/下；更多设置选项可通过sudo ./configure --help查找 12sudo makesudo make install 配置环境 因为RedHat6.X/7.X/Ubuntu下默认自带有Python2.X，如果直接运行python命令进入的是python2.X的版本，除非输入绝对路径访问刚才安装好的新版本/usr/local/python-3.5.1/bin/python3，但这样每次都输绝对路径太麻烦了，所以就需要修改PATH环境变量 RedHat6.X/7.X 1234vim ~/.bash_profile...PATH=$PATH:$HOME/bin:/usr/local/python-3.5.1/bin... 在原本PATH变量的最后加上:/usr/local/python-3.5.1/bin，即之前设置的python的安装目录下的bin目录 1source ~/.bash_profile 配置好PATH之后，最后还要做一件事情，就是在/usr/bin/目录下建个链接文件指向/usr/local/python-3.3/bin/python3.3这个文件， 这样以后只要直接输入python就自动启动3.5.1版本了 1234567rm -rf /usr/bin/pythonln -s /usr/local/python-3.5.1/bin/python3 /usr/bin/pythonpythonPython 3.5.1 (default, Mar 5 2016, 19:08:10) [GCC 4.8.3 20140911 (Red Hat 4.8.3-9)] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 执行python后如果显示python的版本为3.5.1说明配置成功！ Ubuntu 1234sudo vim /etc/environment...PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/python-3.5.1/bin&quot;... 在原本PATH变量的最后加上:/usr/local/python-3.5.1/bin，即之前设置的python的安装目录下的bin目录 1source /etc/environment 配置好PATH之后，最后还要做一件事情，就是在/usr/bin/目录下建个链接文件指向/usr/local/python-3.3/bin/python3.3这个文件， 这样以后只要直接输入python就自动启动3.5.1版本了 1234567sudo rm -rf /usr/bin/pythonsudo ln -s /usr/local/python-3.5.1/bin/python3 /usr/bin/pythonpythonPython 3.5.1 (default, Dec 31 2015, 03:28:15) [GCC 4.8.2] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; 执行python后如果显示python的版本为3.5.1说明配置成功！ EOF 本文作者：Koen]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Extundelete--数据恢复软件]]></title>
    <url>%2Fck74yvgo30008dhkcgb2lk1wo.html</url>
    <content type="text"><![CDATA[前言 作为一名运维人员，保证数据的安全是根本职责，所以在维护系统的时候，要慎之又慎，但是有时难免会出现数据被误删除的情况，在这个时候该如何快速、有效地恢复数据显得至关重要，extundelete就是其中的一个选择。 如何使用”rm -rf”命令 在Linux系统下，通过命令“rm -rf”可以将任何数据直接从硬盘删除，并且没有任何提示，同时Linux下也没有与Windows下回收站类似的功能，也就意味着，数据在删除后通过常规的手段是无法恢复的，因此使用这个命令要非常慎重。在使用rm命令的时候，比较稳妥的方法是把命令参数放到后面，这样有一个提醒的作用。其实还有一个方法。那就是将要删除的东西通过mv命令移动到系统下的/tmp目录下，然后写个脚本定期执行清除操作，这样做就可以在一定程度上降低误删除数据的危险性。 其实保证数据安全最好的方法是做好备份，虽然备份不是万能的，但是没有备份是万万不行的。任何数据恢复工具都有一定局限性，都不能保证完整地恢复出所有数据，因此，把备份作为核心，把数据恢复工具作为辅助是运维人员必须坚持的一个准则。 extundelete与ext3grep的异同 在Linux下，基于开源的数据恢复工具有很多，常见的有debugfs、R-Linux、ext3grep、extundelete等，比较常用的有ext3grep和extundelete，这两个工具的恢复原理基本一样，只是extundelete功能更加强大。 extundelete是基于Linux的一个数据恢复工具，它通过分析文件系统的日志，解析出所有文件的inode信息，从而可以恢复Linux下主流的ext3、ext4文件系统下被误删除的文件。而ext3grep仅支持ext3文件系统的恢复。在恢复速度上，extundelete要快很多，因为extundelete的恢复机制是扫描inode和恢复数据同时进行，并且支持单个文件恢复、单个目录恢复、inode恢复、block恢复、完整磁盘恢复等，而ext3grep就略显笨拙了，它需要首先扫描完要恢复数据的所有inode信息，然后才能开始数据恢复，所以在恢复速度上相对较慢，并且在功能上也不支持目录恢复、时间段恢复等。 extundelete的恢复原理 在利用extundelete恢复文件时并不依赖特定文件格式，首先extundelete会通过文件系统的inode信息（根目录的inode一般为2）来获得当前文件系统下所有文件的信息，包括存在的和已经删除的文件，这些信息包括文件名和inode。然后利用inode信息结合日志去查询该inode所在的block位置，包括直接块、间接块等信息。最后利用dd命令将这些信息备份出来，从而恢复数据文件。 安装extundelete 下载地址：http://sourceforge.net/projects/extundelete/ 安装的先决条件 开发工具 1yum groupinstall &quot;Development Tools&quot; -y 安装依赖包e2fsprogs-devel 1yum install e2fsprogs-devel.x86_64 -y 安装extundelete12345tar jxf extundelete-0.2.4.tar.bz2cd extundelete-0.2.4./configuremakemake install 默认情况下，如果在./configure时未指定安装路径，会将extundelete装在/usr/local/文件夹下 extundelete用法详解 extundelete用法如下： extundelete --help 命令格式： extundelete [option] [action] device-file 其中，参数(options)有： –version，-[Vv]，显示软件版本号 –help，显示软件帮助信息 –superblock，显示超级块信息 –journal，显示日志信息 –after dtime，时间参数，表示在某段时间之后被删的文件或目录 –before dtime，时间参数，表示在某段时间之前被删的文件或目录 动作(action)有： –inode ino，显示节点“ino”的信息 –block blk，显示数据块“blk”的信息 –restore-inode ino[,ino,…]，恢复命令参数，表示恢复节点“ino”的文件，恢复的文件会自动放在当前目录下的RESTORED_FILES文件夹中，使用节点编号作为扩展名 –restore-file ‘path’，恢复命令参数，表示将恢复指定路径的文件，并把恢复的文件放在当前目录下的RESTORED_FILES目录中 –restore-files ‘path’，恢复命令参数，表示将恢复在路径中已列出的所有文件 –restore-all，恢复命令参数，表示将尝试恢复所有目录和文件 -j journal，表示从已经命名的文件中读取扩展日志 -b blocknumber，表示使用之前备份的超级块来打开文件系统，一般用于查看现有超级块是不是当前所要的文件 -B blocksize，通过制定数据块大小来打开文件系统，一般用于查看已经知道大小的文件 实战：使用extundelete恢复数据 在数据被误删除后，第一时间要做的是卸载被删除数据所在的磁盘或者磁盘分区，如果是系统根分区的数据遭到误删除，就需要将系统进入单用户，并且将根分区以只读模式挂载。这样做的原因很简单，因为将文件删除后，仅仅是将文件的inode节点中的扇区指针清零，实际文件还存储在磁盘上，如果磁盘以读写模式挂载，这些已删除的文件的数据块就可能被操作系统重新分配出去，在这些数据块被新的数据覆盖后，这些数据就真的丢失了，恢复工具也无力回天。所以，以只读模式挂载磁盘可以尽量降低数据块中数据被覆盖的风险，以提高恢复数据成功的比率。 通过extundelete恢复单个文件 模拟数据误删除环境 # mkdir /data # mkfs.ext4 /dev/sdb1 # mount /dev/sdb1 /data/ # cp /etc/passwd /data/ # cp -r /etc/sysconfig/network-scripts /data/ # mkdir /data/test # echo &quot;extundelete test&quot; &gt; /data/test/mytest.txt # ls /data/ lost+found network-scripts passwd test # md5sum passwd 499b16cbdef03e814f3405fccd188dcc passwd # md5sum test/mytest.txt eb42e4b3f953ce00e78e11bf50652a80 test/mytest.txt # rm -rf /data/* 卸载磁盘分区 在将数据误删除后，立即需要做的就是卸载这块磁盘分区： 1umount /data/ 注：卸载磁盘分区时必须先退出磁盘分区所挂载的目录，否则将出现类似如下报错 123umount: /data: device is busy. (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1)) 查询可恢复的数据信息 通过extundelete命令可以查询/dev/sdb1分区可恢复的数据信息： # extundelete /dev/sdb1 --inode 2 ... File name | Inode number | Deleted status . 2 .. 2 lost+found 11 Deleted passwd 12 Deleted network-scripts 8193 Deleted test 8194 Deleted 根据上面的输出，标记为Deleted状态的是已经删除的文件或目录。同时还可以看到每个已删除的文件的inode值，接下来就可以恢复文件了。 恢复单个文件 # extundelete /dev/sdb1 --restore-file passwd NOTICE: Extended attributes are not restored. Loading filesystem metadata ... 16 groups loaded. Loading journal descriptors ... 57 descriptors loaded. Successfully restored file passwd # cd RECOVERED_FILES/ # ls passwd # md5sum passwd 499b16cbdef03e814f3405fccd188dcc passwd 注：“–restore-file”后面指定的是恢复文件路径，这个路径是文件的相对路径。相对路径是相对于原来文件的存储路径而言的，比如，原来文件的存储路径是/data/passwd，那么参数后面直接指定passwd文件即可，如果原来文件的存储路径是/data/test/mytest.txt，那么在参数后面通过“test/mytest.txt”指定即可 在文件恢复成功后，extundelete命令默认会在执行命令的当前目录下创建一个RECOVERED_FILES目录，此目录用于存放恢复的文件，所以执行extundelete命令的当前目录是可写的。 恢复成功后，通过md5sum命令校验，校验码与之前的完全一致，表明文件恢复成功。 通过extundelete恢复单个目录extundelete除了支持恢复单个文件，也支持恢复单个目录，在需要恢复目录时，通过“–restore-directory”选项即可恢复指定目录的所有数据。 # extundelete /dev/sdb1 --restore-directory network-scripts NOTICE: Extended attributes are not restored. Loading filesystem metadata ... 16 groups loaded. Loading journal descriptors ... 57 descriptors loaded. Searching for recoverable inodes in directory /network-scripts ... 33 recoverable inodes found. Looking through the directory structure for deleted files ... 5 recoverable inodes still lost. # cd RECOVERED_FILES/ # ls network-scripts 可以看到之前删除的目录network-scripts已经成功恢复了，进入这个目录检查发现，所有文件内容和大小都正常。 通过extundelete恢复所有删除数据当需要恢复的数据较多时，一个个地指定文件或目录将是一项非常繁重和耗时的工作，此时可以通过“restore-all”选项来恢复所有被删除的文件或文件夹。 # extundelete /dev/sdb1 --restore-all NOTICE: Extended attributes are not restored. Loading filesystem metadata ... 16 groups loaded. Loading journal descriptors ... 57 descriptors loaded. Searching for recoverable inodes in directory / ... 33 recoverable inodes found. Looking through the directory structure for deleted files ... 0 recoverable inodes still lost. # cd RECOVERED_FILES/ # ls network-scripts passwd test # md5sum passwd 499b16cbdef03e814f3405fccd188dcc passwd # md5sum test/mytest.txt eb42e4b3f953ce00e78e11bf50652a80 test/mytest.txt 通过extundelete恢复某个时间段的数据有时候删除了大量的数据，其中很多数据都是么用的，我们仅需要恢复其中的一部分数据，此时，如果采用恢复全部数据的办法，不但耗时，而且浪费资源，在这种情况下，就需要采用另外一种恢复机制有选择地恢复，extundelete提供了“–after”和“–before”参数，可以通过指定某个时间段，进而只恢复这个时间段内的数据。 # date +%s 1449027652 # extundelete --after 1449020452 --restore-all /dev/sdb1 Only show and process deleted entries if they are deleted on or after 1449020452 and before 9223372036854775807. NOTICE: Extended attributes are not restored. Loading filesystem metadata ... 16 groups loaded. Loading journal descriptors ... 57 descriptors loaded. Searching for recoverable inodes in directory / ... 33 recoverable inodes found. Looking through the directory structure for deleted files ... 0 recoverable inodes still lost. # cd RECOVERED_FILES/ # ls network-scripts passwd test # md5sum passwd 499b16cbdef03e814f3405fccd188dcc passwd # md5sum test/mytest.txt eb42e4b3f953ce00e78e11bf50652a80 test/mytest.txt 在上面的例子中恢复的是两个小时之内被删除的文件。在这个操作过程中，需要注意的是“–after”参数后面跟的时间是个总秒数。起算时间是“1970-01-01 00:00:00 UTC”，通过”date +%s”命令即可将当前时间转换为总秒数，因为恢复的是两个小时之内的数据，所以“1449020452”这个值就是通过“1449027652”减去“60602=7200”获得的。 EOF 本文作者：Koen 参考书籍：《高性能Linux服务器构建实战：系统安全、故障排查、自动化运维与集群架构》]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ntopng--网络流量监控与分析工具]]></title>
    <url>%2Fck74yvgoh0013dhkclc4fxt9v.html</url>
    <content type="text"><![CDATA[当今世界，人们的计算机都相互连接，互联互通。小到你的家庭局域网（LAN），大到最大的一个被我们称为互联网。当你管理一台联网的计算机时，你就是在管理最关键的组件之一。由于大多数开发出的应用程序都基于网络，网络就连接起了这些关键点。 这就是为什么我们需要网络监控工具。Ntop是最好的网络监控工具之一。Ntop是网络流量监控中的新贵，它是一种网络嗅探器，以与top显示进程般类似的方式显示网络使用率，在监控网络数据传输、排除网络故障方面功能十分强大。它通过分析网络流量来判断网络上存在的各种问题，还可以监控是否有黑客正在攻击网络，如果网络突然变缓慢，通过Ntop截获的数据包，可以确定是什么类型的数据包占据了大量带宽，以及数据包的发送时间、数据包传送的延时、数据包的来源地址等，通过这些信息，运维人员可以及时做出相应，或者对网络进行调整，从而保持网络正常、稳定运行。在交互模式中，Ntop显示了用户终端上的网络状态。在网页模式中，Ntop作为网络服务器，创建网络状态的HTML转储文件。Ntop支持NetFlow/sFlowemitter/collector，这是一个基于HTTP的客户端界面，用于创建Ntop为中心的监控应用，并使用RRD来持续存储通信数据。 今天，你将见到Ntopng——下一代Ntop。 Ntopng是什么 Ntopng是一个基于网页的高速通信分析器和流量收集器。Ntopng基于ntop，它运行于所有Unix平台、MacOS X和Windows。 Ntop与Ntopng的功能 可以自动从网络中获取有用的信息 可以将获取的数据包信息转换为可识别的格式 可以记录网络的通信时间和过程 可以对网络中失败的通信进行分析 可以发现网络中通信的瓶颈 可以自动识别客户端正在使用的操作系统 Ntopng新功能 以图形的方式动态展示流量状态 实时监控网络数据并实时汇总 以矩阵图的方式显示IP流量 可以生成基于HTML5/AJAX的网络流量统计 支持历史流量数据分析 基于HTML5的动态图形用户界面 特性 按各种协议对网络通信排序 显示网络通信和IPv4/v6的激活主机 持续不断以RRD格式存储定位主机的通信数据到磁盘 通过nDPI，ntop的DPI框架，发现应用协议 显示各种协议间的IP通信分布 分析IP通信，并根据源/目的地址进行排序 显示IP通信子网的矩阵（谁在和谁通信？） 报告按协议类型排序的IP协议使用率 生成HTML5/AJAX网络通信数据 Ntopng的安装(RedHat6.X/7.X) 安装的先决条件 开发工具 1yum groupinstall &quot;Development Tools&quot; -y 安装TCL 1yum install tcl -y 安装libpcap和libpcap-devel 在RedHat6.X/7.X自带的软件源中只提供libpcap的安装，没有libpcap-devel，可自行到Linux Packages Search搜索对应系统版本的安装包进行安装，这里不再赘述 1yum localinstall libpcap-1.4.0-4.20130826git2dbcaa1.el6.x86_64.rpm libpcap-devel-1.4.0-4.20130826git2dbcaa1.el6.x86_64.rpm -y 安装Redis 在Redis官网下载Redis源码包，按照以下步骤进行安装： 12345tar zxf redis-2.6.13.tar.gzcd redis-2.6.13makemake testmake install 安装Ntopng1234git clone https://github.com/ntop/ntopng.gitcd ntopng/./autogen.sh./configure 执行./configure时会相继出现如下提示： 解决方法： 执行如下命令后重新执行./configure 12cd ..; git clone https://github.com/ntop/nDPI.git; cd nDPI; ./autogen.sh; make; cd ../ntopng./configure 解决方法： 12yum install libcurl-devel -y./configure 解决方法： 12yum install sqlite sqlite-devel -y./configure 解决方法： 12yum install mysql-devel -y./configure 解决方法： 12yum install wget -y./configure ./configure成功后，执行make 1make 执行make时会相继出现如下提示： 解决方法： 12yum install glib2-devel -ymake 解决方法： 12yum install libxml2-devel -ymake make成功后，执行make install完成安装 1make install 为Ntopng创建配置文件默认情况下，如果我们在./configure这一步没有明确修改安装文件夹的话，redis和ntopng将安装到/usr/local/文件夹下。接下来，我们需要为ntopng创建配置文件。 1234cd /usr/local/etc/mkdir ntopngcd ntopng/vim ntopng.start ntopng.start中的内容如下： 12--local-network &quot;192.168.220.0/24&quot; #指定要监控的本地子网段--interface eth0 #指定监听eth0网卡上的流量 1vim ntopng.pid ntopng.pid中的内容如下： 1-G=/var/run/ntopng.pid #指定存储Ntopng进程号的文件路径 运行Ntopng运行redis服务器 1/usr/local/bin/redis-server &amp; 运行Ntopng 1/usr/local/bin/ntopng &amp; 测试Ntopng现在，你可以通过访问http://yourserver.name:3000或http://your_ip:3000来测试ntopng应用，你将会看到ntopng登录页面。首次登录，你可以使用用户&#39;admin&#39;和密码&#39;admin&#39; 至此Ntopng安装配置完成，更过关于Ntopng的使用和信息可以访问Ntop官网 EOF 本文作者：Koen 参考书籍：《高性能Linux服务器构建实战：系统安全、故障排查、自动化运维与集群架构》 参考链接：https://linux.cn/article-5664-1.html]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PXE+Kickstart无人值守安装RedHat]]></title>
    <url>%2Fck74yvgol001jdhkcgyf29rcq.html</url>
    <content type="text"><![CDATA[简介 什么是PXEPXE(Pre-boot Execution Environment，预启动执行环境)是由Intel公司开发的最新技术，工作于Client/Server的网络模式，支持工作站通过网络从远端服务器下载映像，并由此支持通过网络启动操作系统，在启动过程中，终端要求服务器分配IP地址，再用TFTP（trivial file transfer protocol）或MTFTP(multicast trivial file transfer protocol)协议下载一个启动软件包到本机内存中执行，由这个启动软件包完成终端基本软件设置，从而引导预先安装在服务器中的终端操作系统。 严格来说，PXE 并不是一种安装方式，而是一种引导方式。进行 PXE 安装的必要条件是在要安装的计算机中必须包含一个 PXE 支持的网卡（NIC），即网卡中必须要有 PXE Client。PXE 协议可以使计算机通过网络启动。此协议分为 Client端和 Server 端，而PXE Client则在网卡的 ROM 中。当计算机引导时，BIOS 把 PXE Client 调入内存中执行，然后由 PXE Client 将放置在远端的文件通过网络下载到本地运行。运行 PXE 协议需要设置 DHCP 服务器和 TFTP 服务器。DHCP 服务器会给 PXE Client（将要安装系统的主机）分配一个 IP 地址，由于是给 PXE Client 分配 IP 地址，所以在配置 DHCP 服务器时需要增加相应的 PXE 设置。 此外，在 PXE Client 的 ROM 中，已经存在了 TFTP Client，那么它就可以通过 TFTP 协议到 TFTP Server 上下载所需的文件了。 PXE的工作过程 PXE Client 从自己的PXE网卡启动，向本网络中的DHCP服务器索取IP； DHCP 服务器返回分配给客户机的IP 以及PXE文件的放置位置(该文件一般是放在一台TFTP服务器上) ； PXE Client 向本网络中的TFTP服务器索取pxelinux.0 文件； PXE Client 取得pxelinux.0 文件后之执行该文件； 根据pxelinux.0 的执行结果，通过TFTP服务器加载内核和文件系统 ； 进入安装画面, 此时可以通过选择HTTP、FTP、NFS 方式之一进行安装； 详细工作流程，请参考下面这幅图： 什么是KickstartKickstart是一种无人值守的安装方式。它的工作原理是在安装过程中记录典型的需要人工干预填写的各种参数，并生成一个名为ks.cfg的文件。如果在安装过程中（不只局限于生成Kickstart安装文件的机器）出现要填写参数的情况，安装程序首先会去查找Kickstart生成的文件，如果找到合适的参数，就采用所找到的参数；如果没有找到合适的参数，便需要安装者手工干预了。所以，如果Kickstart文件涵盖了安装过程中可能出现的所有需要填写的参数，那么安装者完全可以只告诉安装程序从何处取ks.cfg文件，然后就去忙自己的事情。等安装完毕，安装程序会根据ks.cfg中的设置重启系统，并结束安装。 PXE+Kickstart 无人值守安装操作系统完整过程如下： 系统环境 实验环境：VMware Workstation Pro 12系统平台：RedHat Enterprise Linux 6.5 (最小化安装)网络模式：NAT模式（共享主机的IP地址）DHCP / TFTP IP：192.168.220.139HTTP / FTP / NFS IP：192.168.220.139防火墙已关闭/iptables: Firewall is not running.SELINUX=disabled 准备工作 生成ks.cfg 文件需要system-config-kickstart 工具，而此工具依赖于X Windows，所以我们需要安装X Windows 和Desktop 并重启系统，操作如下： 12yum groupinstall &quot;X Window System&quot; &quot;Desktop&quot; &quot;Desktop Platform&quot; &quot;chinese-support&quot; &quot;fonts&quot; -yreboot 配置HTTP安装方式 系统的安装方式可以选择HTTP、FTP、 NFS，我们这里介绍HTTP方式的安装。 安装并配置HTTP1yum install httpd –y 开启服务并设置开机启动 12/etc/init.d/httpd startchkconfig httpd on 加载ISO镜像在虚拟机中设置加载ISO镜像 将iso文件挂载至/mnt/cdrom 12mkdir /mnt/cdrommount /dev/cdrom /mnt/cdrom 复制光盘全部内容至HTTP的根目录/var/www/html下123cp -r /mnt/cdrom /var/www/html/umount /mnt/cdromrm -rf /mnt/cdrom 至此HTTP部分设置完毕。 配置TFTP 安装tftp-server1yum install xinetd tftp-server -y 启用tftp服务将/etc/xinetd.d/tftp中的disable选项设为no 123456789101112131415161718192021cp -a /etc/xinetd.d/tftp /etc/xinetd.d/tftp.bakcat &gt; /etc/xinetd.d/tftp &lt;&lt; EOF# default: off# description: The tftp server serves files using the trivial file transfer \# protocol. The tftp protocol is often used to boot diskless \# workstations, download configuration files to network-aware printers, \# and to start the installation process for some operating systems.service tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no per_source = 11 cps = 100 2 flags = IPv4&#125;EOF 启动tftp服务因为tftp服务是挂载在超级进程xinetd 下的，所以通过启动xinetd 来启动tftp服务 1/etc/init.d/xinetd restart 设置开机启动xinetd 1chkconfig xinetd on 配置支持PXE的启动程序 安装syslinux1yum install syslinux -y 说明：syslinux是一个功能强大的引导加载程序，而且兼容各种介质。更加确切地说：SYSLINUX是一个小型的Linux操作系统，它的目的是简化首次安装Linux的时间，并建立修护或其它特殊用途的启动盘。 复制pxelinux.0文件至/var/lib/tftpboot/文件夹中1cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ 复制iso镜像中的/image/pxeboot/initrd.img和vmlinux至/var/lib/tftpboot/文件夹中1cp /var/www/html/cdrom/images/pxeboot/&#123;initrd.img,vmlinuz&#125; /var/lib/tftpboot/ 复制iso镜像中的/isolinux/*.msg至/var/lib/tftpboot/文件夹中1cp /var/www/html/cdrom/isolinux/*.msg /var/lib/tftpboot/ 在/var/lib/tftpboot/中新建一个pxelinux.cfg目录1mkdir /var/lib/tftpboot/pxelinux.cfg 将iso镜像中的/isolinux目录中的isolinux.cfg复制到pxelinux.cfg目录中，同时更改文件名称为default1cp /var/www/html/cdrom/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default 修改default文件# vim /var/lib/tftpboot/pxelinux.cfg/default default autoinstall #默认启动的是&apos;label autoinstall&apos;中标记的启动内核 #prompt 1 timeout 600 display boot.msg #显示某个文件的内容，注意文件的路径。默认是在/var/lib/tftpboot/目录下。也可以指定位类似&apos;/install/boot.msg&apos;这样的，路径+文件名。 menu background splash.jpg menu title Welcome to Red Hat Enterprise Linux 6.5! menu color border 0 #ffffffff #00000000 menu color sel 7 #ffffffff #ff000000 menu color title 0 #ffffffff #00000000 menu color tabmsg 0 #ffffffff #00000000 menu color unsel 0 #ffffffff #00000000 menu color hotsel 0 #ff000000 #ffffffff menu color hotkey 7 #ffffffff #ff000000 menu color scrollbar 0 #ffffffff #00000000 label autoinstall #&apos;label&apos;指定你在&apos;boot:&apos;提示符下输入的关键字，比如boot:linux[ENTER]，这个会启动&apos;label linux&apos;下标记的kernel和initrd.img文件。 menu label ^AutoInstall RedHat System menu default kernel vmlinuz append initrd=initrd.img ks=http://192.168.220.139/ks.cfg #告诉系统，从哪里获取ks.cfg文件 label linux menu label ^Install or upgrade an existing system menu default kernel vmlinuz #kernel参数指定要启动的内核 append initrd=initrd.img #append指定追加给内核的参数，能够在grub里使用的追加给内核的参数，在这里也都可以使用。 label vesa menu label Install system with ^basic video driver kernel vmlinuz append initrd=initrd.img xdriver=vesa nomodeset label rescue menu label ^Rescue installed system kernel vmlinuz append initrd=initrd.img rescue label local menu label Boot from ^local drive localboot 0xffff label memtest86 menu label ^Memory test kernel memtest append - 配置DHCP 安装DHCP服务器1yum install dhcp -y 复制配置模板文件到DHCP的配置目录中1cp -f /usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcp/dhcpd.conf 修改/etc/dhcp/dhcpd.conf 配置文件# vim /etc/dhcp/dhcpd.conf option domain-name &quot;example.com&quot;; option domain-name-servers 192.168.220.139; default-lease-time 600; max-lease-time 7200; subnet 192.168.220.0 netmask 255.255.255.0 { range 192.168.220.40 192.168.220.60; #用于分配的IP地址池 option routers 192.168.220.2; #设置分配的网关 filename &quot;pxelinux.0&quot;; #pxelinux启动文件位置 next-server 192.168.220.139; #TFTP Server的IP地址 } 启动DHCP服务1/etc/init.d/dhcpd restart 设置开机自启 1chkconfig dhcpd on 生成ks.cfg文件 安装Kickstart1yum install system-config-kickstart -y 在桌面环境下配置Kickstart启动X Windows环境 1startx 配置Kickstart 1system-config-kickstart A. 设置语言，键盘，时区，Root密码，安装完毕后重启等。 B. 设置安装方式，这篇文章介绍的是HTTP方式的安装，故选择HTTP C. 安装MBR D. 设置分区 E. 配置网络 F. SELinux 和防火墙配置 G. 图形环境配置 H. 软件包安装选择 I. 生成ks.cfg 文件，保存在/var/www/html/文件夹下 我们可以打开/var/www/html/ks.cfg文件进行查看并做修改 # vim /var/www/html/ks.cfg #platform=x86, AMD64, or Intel EM64T #version=DEVEL # Firewall configuration firewall --disabled # Install OS instead of upgrade install # Use network installation url --url=&quot;http://192.168.220.139/cdrom&quot; #这个选项告诉安装程序：到服务器192.168.220.139的HTTP根目录下的cdrom文件夹下寻找安装介质 # Root password rootpw --iscrypted $1$Zhouns4l$z7kRWkkryGTWPElCS.SUm. # System authorization information auth --useshadow --passalgo=sha512 # Use text mode install text # System keyboard keyboard us # System language lang en_US # SELinux configuration selinux --disabled # Do not configure the X Window System skipx # Installation logging level logging --level=info # Reboot after installation reboot # System timezone timezone Asia/Shanghai # Network information network --bootproto=dhcp --device=eth0 --onboot=on # System bootloader configuration key --skip bootloader --location=mbr # Clear the Master Boot Record zerombr # Partition clearing information clearpart --all --initlabel # Disk partitioning information part /boot --fstype=&quot;ext4&quot; --size=200 part swap --fstype=&quot;swap&quot; --size=1024 part / --fstype=&quot;ext4&quot; --grow --size=1 %packages @base @chinese-support %end 说明： key –skip 如果是红帽系统，此选项可以跳过输入序列号过程；如果是CentOS 系列，则可以不保留此项内容 测试安装 自动化安装系统配置完毕，下面创建一台新的机器进行测试 新建虚拟机，选择自定义（高级） 选择“下一步” 选择“稍后安装操作系统” 选择客户机操作系统类型 命名虚拟机 设置处理器数量 设置此虚拟机的内存 设置网络类型，网络连接模式选择NAT模式 选择I/O控制器类型 选择磁盘类型 选择磁盘 指定磁盘大小 注：一定要勾选上“立即分配所有磁盘空间”，不然在后来安装的时候将提示没有磁盘空间。 指定磁盘文件 虚拟机总览 正在创建磁盘，过程会很慢，虚拟机需要产生一个20GB的文件。 启动虚拟机，选择从网卡启动，DHCP 服务器正在给客户机分配IP地址。 开始下载vmlinuz 和initrd.img 安装过程… 安装完毕，重启后，显示登录界面 至此PXE+Kickstart无人值守安装RedHat操作系统环境搭建完毕。 EOF 本文作者：Koen 参考链接：http://mp.weixin.qq.com/s?__biz=MzA3MzYwNjQ3NA==&amp;mid=400315209&amp;idx=2&amp;sn=44efa1be2b0f4f0280fa2e7f5ff1c171&amp;scene=2&amp;srcid=1103zVibNj0UTaW0KhUEBsoH#wechat_redirect]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedHat6.X系统管理]]></title>
    <url>%2Fck74yvgoq001xdhkclbtals4z.html</url>
    <content type="text"><![CDATA[网络应用配置 主机禁pingPing命令在网络检测中是最常用的一个命令，所用的就是ICMP协议，不过为了保护主机，通常会禁用ICMP协议，忽略ICMP数据包，再使用ping方法对这台主机检测，这时没有任何反应。 禁用ICMP协议 若要禁用ICMP协议，可以直接输入参数或编辑配置文件，配置完成后无需重新启动。 [root@bogon ~]# echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 再使用其他主机去ping该主机，会出现请求超时信息。 C:\Users\-Koen-&gt;ping 192.168.220.135 正在 Ping 192.168.220.135 具有 32 字节的数据: 请求超时。 请求超时。 请求超时。 请求超时。 192.168.220.135 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 0，丢失 = 4 (100% 丢失)， 启用ICMP协议 若要启用ICMP协议，可以直接输入参数或编辑配置文件，配置完成后无需重新启动。 [root@bogon ~]# echo 0 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 再使用其他主机去ping该主机，就会有回复的消息。 C:\Users\-Koen-&gt;ping 192.168.220.135 正在 Ping 192.168.220.135 具有 32 字节的 来自 192.168.220.135 的回复: 字节=32 时间 来自 192.168.220.135 的回复: 字节=32 时间 来自 192.168.220.135 的回复: 字节=32 时间 来自 192.168.220.135 的回复: 字节=32 时间 192.168.220.135 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 往返行程的估计时间(以毫秒为单位): 最短 = 0ms，最长 = 0ms，平均 = 0ms 双网卡带宽绑定通常想要实现带宽绑定，主要是为了实现设备容错、负载均衡、端口绑定。一台服务器都会有两块网卡，不过一般只会使用一块网卡，此时将服务器做带宽绑定是有必要的，以免浪费另一块网卡，也可以减轻一块网卡工作的负载。 检查网络配置可以看到有两块网卡eth0和eth1，现在要将两块网卡带宽绑定，必须配置这两块网卡 [root@bogon ~]# ifconfig eth0 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA inet addr:192.168.220.133 Bcast:192.168.220.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe29:d8fa/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:656 errors:0 dropped:0 overruns:0 frame:0 TX packets:413 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:58218 (56.8 KiB) TX bytes:56097 (54.7 KiB) eth1 Link encap:Ethernet HWaddr 00:0C:29:29:D8:04 inet addr:192.168.220.134 Bcast:192.168.220.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe29:d804/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:39 errors:0 dropped:0 overruns:0 frame:0 TX packets:13 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:4508 (4.4 KiB) TX bytes:1662 (1.6 KiB) Interrupt:16 Base address:0x2000 先进入network-scripts目录，编辑的第一块网卡eth0的配置文件，内容如以下所示，编辑完后保存文档。 [root@bogon ~]# cd /etc/sysconfig/network-scripts/ [root@bogon network-scripts]# vim ifcfg-eth0 DEVICE=eth0 ONBOOT=yes BOOTPROTO=none USERCTL=no MASTER=bond0 //带宽绑定后的网卡配置，bond0为绑定带宽的网卡名称 SLAVE=yes 再来编辑第二块网卡eht1的配置文件，增加内容与eth0配置文件一样，编辑完后保存文档。 [root@bogon network-scripts]# vim ifcfg-eth1 DEVICE=eth1 ONBOOT=yes BOOTPROTO=none USERCTL=no MASTER=bond0 //带宽绑定后的网卡配置，bond0为绑定带宽的网卡名称 SLAVE=yes 接下来创建一个新的配置文件ifcfg-bond0,内容如下，第5、6、7、8行请根据环境进行IP配置，编辑完后保存文档。 [root@bogon network-scripts]# vim ifcfg-bond0 DEVICE=bond0 ONBOOT=yes BOOTPROTO=none IPADDR=192.168.220.135 NETMASK=255.255.255.0 GATEWAY=192.168.220.2 DNS1=192.168.220.2 编辑modprobe.conf，增加两行配置信息，miimon=100为每100毫秒（0.1秒）检查网络一次，可根据个人需求进行设置，这代表网络如果断线，0.1秒就会恢复连接，mode为网卡工作模式，共有7种，通常设置0、1、6这几种。 [root@bogon ~]# vim /etc/modprobe.conf alias bond0 bonding options bond0 miimon=100 mode=1 Mode模式的功能如下表所示： mode 功能 功能说明 0 balance-rr 负载均衡模式需有switch配置（trunk）支持才能发挥实际效果，具有容错功能，其中一块网卡失效仍可持续工作 1 active-backup 同一时间只有一块网卡工作，Active Slave其中一块网卡断线时自动启用另一块网卡，不需switch支持 2 balance-xor 具容错作用 3 broadcast 所有网卡一起收发网络数据包，具容错功能，其中一块网络卡断线仍可持续工作 4 802.3ad 无实际功能，不建议使用 5 balance-tlb 发送数据包自动负载均衡，接收数据包由Current Active Slave负责，具容错功能，其中一块网络卡失效仍可持续工作，不需switch支持及配置 6 balance-alb 发送及接收皆自动负载均衡，具容错功能，其中一块网络卡断线时仍可持续工作，网络卡驱动程序需支持，setting hardware address功能，不需switch支持及配置 全部配置完成后，重新启动网卡，让bond0重新启动。 [root@bogon ~]# /etc/init.d/network restart 查看网卡配置信息，可以看到只有bond0有配置IP地址，不过其他两块网卡仍正常工作。 [root@bogon ~]# ifconfig bond0 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA inet addr:192.168.220.135 Bcast:192.168.220.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe29:d8fa/64 Scope:Link UP BROADCAST RUNNING MASTER MULTICAST MTU:1500 Metric:1 RX packets:3762 errors:0 dropped:0 overruns:0 frame:0 TX packets:2393 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:323472 (315.8 KiB) TX bytes:343087 (335.0 KiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1 RX packets:3667 errors:0 dropped:0 overruns:0 frame:0 TX packets:2380 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:313450 (306.1 KiB) TX bytes:341425 (333.4 KiB) eth1 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA UP BROADCAST RUNNING SLAVE MULTICAST MTU:1500 Metric:1 RX packets:95 errors:0 dropped:0 overruns:0 frame:0 TX packets:13 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:10022 (9.7 KiB) TX bytes:1662 (1.6 KiB) Interrupt:16 Base address:0x2000 查看bonding状态，可以看到bond0的配置信息，这样就是带宽绑定成功。 [root@bogon ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.6.0 (September 26, 2009) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: eth0 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: eth0 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0c:29:29:d8:fa Slave queue ID: 0 Slave Interface: eth1 MII Status: up Speed: Unknown Duplex: Unknown Link Failure Count: 0 Permanent HW addr: 00:0c:29:29:d8:04 Slave queue ID: 0 禁用IPv6支持提高网络效率IPv6协议是下一代IP地址的通信协议，目前所使用的IPv4协议，因IP地址随互联网用户的快速增长，很快会面临用完的困境，所以IPv6协议势必成为未来的趋势。而绝大对数的Linux操作系统都支持IPv6协议，甚至很多主流的Linux操作系统默认安装后可直接启用。可以根据实际应用禁用IPv6支持。检查网络配置，如果有inet6 addr相关信息，表示IPv6协议是开启状态。 [root@bogon ~]# ifconfig eth0 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA inet addr:192.168.220.135 Bcast:192.168.220.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe29:d8fa/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:285 errors:0 dropped:0 overruns:0 frame:0 TX packets:207 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:26187 (25.5 KiB) TX bytes:26759 (26.1 KiB) 禁用IPv6支持的方法很简单，即在disable-ipv6.conf配置文件中增加install ipv6 /bin/true，然后重新启动，配置才会生效。 [root@bogon ~]# echo &quot;install ipv6 /bin/true&quot; &gt; /etc/modprobe.d/disable-ipv6.conf 重新启动后，再次检查网卡信息，则不会再出现inet6 addr，代表IPv6已停用。 [root@bogon ~]# ifconfig eth0 Link encap:Ethernet HWaddr 00:0C:29:29:D8:FA inet addr:192.168.220.135 Bcast:192.168.220.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:35 errors:0 dropped:0 overruns:0 frame:0 TX packets:39 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:4522 (4.4 KiB) TX bytes:4939 (4.8 KiB) 有关闭就有开启，不然要使用IPv6时，却不知如何开启就麻烦了。要启用IPv6协议，只要删除配置文件中的install ipv6 /bin/true或删除disable-ipv6.conf文件然后重启网络服务即可。 [root@bogon ~]# rm -rf /etc/modprobe.d/disable-ipv6.conf 系统管理技巧 登录前后显示信息登录前显示的信息除了是一句标语，也可以达到提醒的效果，类似备忘录的功能。 RedHat6.X操作系统登录前的信息，默认只有操作系统版本号及内核版本号，接下来就是输入账号。 Red Hat Enterprise Linux Server release 6.5 (Santiago) Kernel 2.6.32-431.el6.x86_64 on an x86_64 bogon login: 如果需要显示信息，需编辑/etc/issue配置文件，在最后加上Welcome，保存后退出。 [root@bogon ~]# vim /etc/issue Red Hat Enterprise Linux Server release 6.5 (Santiago) Kernel \r on an \m Welcome //登录前显示的文字信息 若要测试刚才配置是否会生效，需要重新登录，输入账号和密码前就会有登录前配置的信息，如果出现配置的信息，表示配置成功。 Red Hat Enterprise Linux Server release 6.5 (Santiago) Kernel 2.6.32-431.el6.x86_64 on an x86_64 Welcome bogon login: 对于登录后显示的信息，需要编辑/etc/motd,输入所要显示的欢迎信息，保存后退出。 [root@bogon ~]# vim /etc/motd check system 测试登录后是否会显示文字信息，如果出现所配置的信息，表示配置成功。 配置Choose a Tool工具RedHat6.X操作系统内有一个很好用的工具，那就是输入setup命令就会出现Choose a Tool工具，可以配置防火墙、网络、系统服务等。 RedHat6.X操作系统如果是最小化安装就无法使用该工具，因为最小化安装几乎什么软件都不装，所以要使用该工具都要自行安装。 [root@bogon ~]# setup -bash: setup: command not found 可以使用yum在线安装方法安装以下软件setuptool、ntsysv、system-config-firewall-tui、system-config-network-tui。 [root@bogon ~]# yum install setuptool ntsysv system-config-firewall-tui system-config-network-tui -y 成功安装Choos a Tool工具后，再次输入setup检查是否可以使用。 自动调整错误路径通常输入路径时，会打错一两个字，就会出现错误信息，RedHat提供了一个小技巧，不过这个技巧不是万能的，只限于一两个字母路径打错，系统就会自动调整，其实系统也是根据输入的路径与相应的目录比对，然后修正，例如，要到etc目录却打成ect，就会出现找不到目录的情况 [root@bogon ~]# cd /ect -bash: cd: /ect: No such file or directory 修改.bashrc配置文件 在用户目录下修改.bashrc配偶文件，在最后一行添加shopt -s cdspell,修改完成后保存退出，此配置必须重新登录才会生效。 [root@bogon ~]# vim ~/.bashrc # .bashrc # User specific aliases and functions alias rm=&apos;rm -i&apos; alias cp=&apos;cp -i&apos; alias mv=&apos;mv -i&apos; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi shopt -s cdspell 注：如果要其他用户也有这样的功能，则必须编辑/etc/bashrc [root@bogon ~]# cd /ect /etc 自动注销登录账户系统使用完后，正确的习惯是要退出或锁定，Windows及Linux操作系统都是如此，Windows是锁定账号，Linux必须输入命令才会退出，不过这个操作很多使用者都会忘记，所以必须设置系统空闲时间过长，就会自动退出。 编辑/etc/profile，设置系统在空闲时间超过30秒后，自动退出，保存设置后，此设置在下一次登录时才会生效，无需重新启动。 [root@bogon ~]# vim /etc/profile ... export TMOUT=30 //增加此行 查询Linux内核与发行版信息如何查询Linux内核信息及发行版信息是很重要的，这是因为软件安装时要区分i386的32位平台和x86_64的64位平台，所以一定要掌握相关信息，其实不只是单纯要知道操作系统版本，还有很多信息是有意义。 若要查询Linux内核信息，利用uname命令可以看到最完整的内核信息。 [root@bogon ~]# uname -a Linux bogon 2.6.32-431.el6.x86_64 #1 SMP Sun Nov 10 22:19:54 EST 2013 x86_64 x86_64 x86_64 GNU/Linux 参数不一样可以查询到的信息就不一样，可按需求查询。 参数 说明 -a 输出所有信息 -s 显示内核名称（Linux） -n 显示完整主机名称（bogon） -r 显示内核版本（2.6.32-431.el6.x86_64） -v 显示内核发行日期（#1 SMP Sun Nov 10 22:19:54 EST 2013） -m 显示机器硬件类型（x86_64） -p 显示处理器类型（x86_64） -i 显示硬件平台类型（x86_64） -o 显示操作系统（GNU/Linux） 查询操作系统应用平台（32位或64位）查询Linux操作系统应用平台是非常重要的，以免在使用rpm方式安装软件时，才发现软件版本不符合系统应用平台，大多数人都知道使用uname命令去查询，但是看起来眼花缭乱，如何使用最简单的方式查询呢？以下示例能够识别32位或64位的操作系统。 在应用平台使用uname命令查询，再使用getconf命令查询，进行对比看是否一样。 [root@bogon ~]# uname -a Linux bogon 2.6.32-431.el6.x86_64 #1 SMP Sun Nov 10 22:19:54 EST 2013 x86_64 x86_64 x86_64 GNU/Linux [root@bogon ~]# getconf LONG_BIT 64 设置服务默认启动或关闭因为很多系统服务默认系统启动时不自动启动，每次开机后都要使用的服务，必须设置为默认启动，有些没有用到的服务则可以关闭，设置服务默认启动或关闭有图形和命令两种方式，建议使用命令方式去设置，有些服务是无法在图形工具中进行设置的。 图形界面设置 输入ntsysv命令启动Services选项，使用tab及空格键进行选择和修改。 命令界面设置 一般来说最常见的设置服务默认启动或默认关闭的方法是命令方式，常用命令是chkconfig，该命令主要是检查、设定系统各服务的运行级别和运行状态。 [root@bogon ~]# chkconfig httpd on //将httpd服务设为默认启动 [root@bogon ~]# chkconfig httpd --list //查看httpd的level状态 httpd 0:off 1:off 2:on 3:on 4:on 5:on 6:off [root@bogon ~]# chkconfig httpd off //将httpd服务设为默认关闭 [root@bogon ~]# chkconfig httpd --list //查看httpd的level状态 httpd 0:off 1:off 2:off 3:off 4:off 5:off 6:off 以上的方式较常见，不过在特殊环境下会设置不同的level启动。下表示chkconfig命令的完整说明。On表示启动，Off表示关闭。 命令 说明 chkconfig –list 显示所有服务启动情况 chkconfig –add 服务名称 增加指定的服务 chkconfig –del 服务名称 删除指定的服务 chkconfig –level 0~6 服务名称 on/off 设置服务Level启动/关闭 下表为chkconfig命令显示单个服务的运行状态，默认level2、3、4、5为on，其他level为off。 Level 0 1 2 3 4 5 6 on/off off off on on on on off 下表说明每个Level所代表的意义。 Level 说明 0 关机 1 单用户模式 2 多用户命令行模式，没有网络功能 3 多用户命令行模式，有网络功能 4 保留 5 带图形界面的多用户模式 6 重新启动 [root@bogon ~]# chkconfig httpd --list //检查httpd目前level状态 httpd 0:off 1:off 2:off 3:off 4:off 5:off 6:off [root@bogon ~]# chkconfig --level 0123456 httpd on //全部都开启 [root@bogon ~]# chkconfig httpd --list //检查httpd目前level状态 httpd 0:on 1:on 2:on 3:on 4:on 5:on 6:on [root@bogon ~]# chkconfig --level 0123456 httpd off //全部都关闭 [root@bogon ~]# chkconfig httpd --list //检查httpd目前level状态 httpd 0:off 1:off 2:off 3:off 4:off 5:off 6:off 安装图形界面采用最小化安装的RedHat操作系统默认是没有图形界面，这对于初学者来说是一件比较痛苦的事情。但是，可以通过yum来安装图形界面。 [root@bogon ~]# yum groupinstall &quot;X Window System&quot; &quot;Desktop&quot; &quot;Desktop Platform&quot; &quot;chinese-support&quot; &quot;fonts&quot; -y 安装完成后，执行init 5或者startx开启图形界面 EOF 本文作者：Koen 参考书籍：《CentOS6.X系统管理实战宝典》]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理机环回网卡桥接VMware虚拟机实现主机通信]]></title>
    <url>%2Fck74yvgp8003kdhkc4qs9gr0b.html</url>
    <content type="text"><![CDATA[原理简述 如上图所示，VMnet0充当着“桥”的角色，将虚拟机的eth0和物理机的环回网卡(Loopback)连接起来，使得物理机和虚拟机之间实现了物理层面上的连通，相当于你在实际应用中将两台电脑通过双绞线连接起来。 从图中可以发现，虚拟机的IP地址为物理机的网关，而虚拟机的网关为物理机的IP地址，两者之间通过设置互置网关来实现虚拟机和物理机之间的数据通信。 通信过程简述 物理机要通过终端模拟软件（Secure CRT、Xshell）登录VMware虚拟机，向虚拟机发送请求数据包，物理机会将请求数据包发给物理机的网关(1.1.1.1)，即发送至虚拟机，虚拟机收到物理机发来的请求数据包后，处理请求，然后将响应数据包发送给虚拟机的网关(1.1.1.2)，即返回给物理机，这样便实现了虚拟机和物理机之间的数据通信。 详细配置步骤 添加环回网卡(Loopback)设备 (1)点击开始菜单—&gt;在搜索栏中输入“hdwwiz”—&gt;回车 或者按Win键+R，在运行窗口中输入“hdwwiz”—&gt;回车 注： hdwwiz 仅限win7及以上windows版本使用，Windows XP用户可以在控制面板中通过”添加硬件”来添加Loopback环回网卡 (2)在弹出的添加硬件向导窗口中点击“下一步” (3)选择“安装我手动从列表选择的硬件(高级)(M)”，然后点击“下一步” (4)选择“网络适配器”，然后点击“下一步” (5)厂商选择“Microsoft”，网络适配器选择“Microsoft Loopback Adapter”，然后点击“下一步” 注：如果你是Win8系统，网络适配器选的名称就不叫“Microsoft Loopback Adapter”，叫做“XXXX环回适配器” (6)点击“下一步” (7)当弹出如上窗口时，说明你的环回网卡设备(Loopback)已经添加成功，点击“完成”关闭窗口 配置环回网卡 (1)打开“网络” 附：如果你发现你的桌面上没有网络这个图标怎么办？ 在桌面右单击—&gt;选择“个性化” 选择“更改桌面图标” 勾选“网络”选项，然后点击“确定” 注：也可直接通过控制面板进入，详细步骤这里不再赘述 (2)点击“网络与共享中心” (3)点击“更改适配器设置” (4)找到刚才添加的“Microsoft Loopback Adapter”，右单击—&gt;选择“属性” 注：在我的电脑上这块设备叫做“本地连接2“，具体名称在操作的时候根据自己电脑的情况来选择 (5)在弹出的“本地连接2 属性”窗口中选择“Internet协议版本 4 (TCP/Ipv4)”，然后选择“属性” (6)在弹出的“Internet协议版本 4 (TCP/Ipv4) 属性”窗口中选择“使用下面的IP地址(s)”，并手动设置IP地址、子网掩码、默认网关，然后点击“确定”，最后点击“关闭” 配置虚拟网络编辑器 (1)打开Vmware，在“编辑”选项卡中选择“虚拟网络编辑器” (2)在弹出的“虚拟网络编辑器”窗口中选择任意一块网卡(我选择的是VMnet0)，将此块网卡的“VMnet”信息设置为桥接模式，并桥接到之前添加的“Microsoft Loopback Adapter”设备上，设置完毕后点击“确定” 配置虚拟机网卡工作模式 (1)对虚拟机选项卡右单击，选择“设置” (2)在弹出的“虚拟机设置”窗口中选择“网络适配器”，将“网络连接”设置为“自定义(U)：特定虚拟网络”，并选择为之前设置的桥接到“Microsoft Loopback Adapter”设备上的VMnet0，然后点击“确定” 配置虚拟机的IP地址和网关 (1)登录虚拟机，右单击桌面右上角的电脑图标，选择“Edit Connections” (2)在弹出的“Network Connections”窗口中选择“System eth0”设备，然后点击“Edit…” (3)在弹出的“Editing System eth0”窗口中选择“Ipv4 Setting”选项卡，将“Method”设置为“Manual”，然后点击“Add”按钮，手动分配虚拟机的IP地址、子网掩码、网关 注：此处设置的虚拟机IP地址对应于物理机(真机)的网关，虚拟机网关对应于物理机(真机)的IP，子网掩码相同 (4)点击“Apply…”，最后点击“Close” 启动eth0 (1)选择“Applications”—&gt;“System Tools”—&gt;“Terminal”打开终端 (2)在终端中执行ifup eth0命令 如果没有任何报错，或者桌面右上角的电脑图标上的叉号消失了说明启动成功。此时可以通过执行ifconfig来查看虚拟机IP 在物理机上通过终端模拟软件(Secure CRT)登录虚拟机 (1)打开secure CRT，选择“文件”选项卡里的“快速连接” (2)在弹出的“快速连接”窗口中输入“主机名”（即虚拟机IP）和“用户名”（此处我以root用户登录），然后点击“连接” (3)如果可以顺利连接，首次登录会弹出一个“新建主机密钥”的窗口，点击“接受并保存(S)” (4)在弹出的“输入安全外壳密码”窗口中输入用户密码(用哪个用户登录就输对应用户的登录密码)，然后点击“确定” (5)如果弹出以下窗口，点击“确定”即可 如果出现如下命令提示符，说明已经登录成功！！&gt;_&lt; EOF 本文作者：Koen]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从apnic抓取所有中国区ipv4地址]]></title>
    <url>%2Fck74yvgot0029dhkc11jxjneh.html</url>
    <content type="text"><![CDATA[因为ip库里的数据需要及时更新，一个更新的依据就是apnic上的ip地址划分，所以需要定期地从apnic上抓取所有中国区的ip，来保证ip库里的数据的时效性。 下面是用python写的两个小程序，用于从apnic抓取所有的中国区ip，第二个程序会将结果写入到ips.txt文件中： 程序一： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bin/env python# -*- coding: utf-8 -*-import osimport reimport urllibimport socketimport struct#根据主机数量求对应子网掩码的函数def log2(x,pow=32): if x&lt;=1: return pow pow-=1 return log2(x/2,pow)def int2ip(intnum): return socket.inet_ntoa(struct.pack('I',socket.htonl(intnum)))def ip2int(ip): return socket.ntohl(struct.unpack("I",socket.inet_aton(ip))[0])def getchinaip(): #打开一个网页获取网页的内容 f=urllib.urlopen("http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest") #将要匹配的字符串用正则表达式表示并编译为pattern实例 regular=re.compile(r'apnic\|CN\|ipv4\|') for line in f: #查找f中有匹配的子串的行并返回 if regular.search(line): #print line.split("|")[3:5] #以|为分隔符取出匹配行中的第4个到第6个字段 iprange=line.split("|")[3:5] #将匹配行中第4个字段（起始IP地址）赋给ip ip=iprange[0] #将匹配第5个字段（主机数量）转换成整数并赋值给cnt cnt=int(iprange[1]) #计算终止IP地址 endip = int2ip(ip2int(ip)+cnt-1) #通过本网段主机数量计算子网掩码 mask=str(log2(cnt)) #打印出IP地址/子网掩码，起始IP地址，终止IP地址 print ip+'/'+mask+','+ip+','+endip #print ip+'/'+mask #打印出IP地址/子网掩码if __name__ == '__main__': getchinaip() 程序二： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#!/usr/bin/env python# -*- coding: utf-8 -*-import reimport urllibdef test(): # 将要匹配的字符串用正则表达式表示并编译为pattern实例 regularIpv4 = re.compile(r'apnic\|CN\|ipv4\|(.*)\|(.*)\|(.*)\|allocated') # 新建ips.txt文件并打开 with open("ips.txt", 'w') as f: # 逐行读取网址中的内容到i for i in urllib.urlopen("http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest"): # 判断是否匹配，如果匹配继续往下执行，否则匹配下一行 if regularIpv4.findall(i): """ sub(repl, string[, count]): 功能: 使用repl替换string中每一个匹配的子串后返回替换后的字符串。 当repl是一个方法时，这个方法应当只接受一个参数（Match对象, 并返回一个字符串用于替换(返回的字符串中不能再引用分组)。 count用于指定最多替换次数, 不指定时全部替换, 缺省值为1。 参考: http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html """ result = regularIpv4.sub(func, i) # print result # 将结果写入到ips.txt文件中 f.write(result)def func(m): """ 功能: sub函数第一个参数 repl, 用来返回一个字符串替换sub函数中的第二个参数 string apnic|CN|ipv4|27.112.0.0|16384|20100702|allocated m.group(1) 中存放的是 ip 地址 如上面的 27.112.0.0 m.group(2) 中存放的是 待处理的掩码数 如上面的 16384 """ return m.group(1) + "/" + str(32 - testlog2(m.group(2)))def testlog2(num): """ 功能: 已知 b 且 2^x=b, 求其中的x 具体实现请参考: http://blog.csdn.net/hackbuteer1/article/details/6681157 """ num = int(num) x = 0 while num &gt; 1: num &gt;&gt;= 1 x += 1 return x if __name__ == '__main__': test() 附：本程序由好友▌March\╲,帮忙书写，在此分享给大家，供借鉴学习&gt;_&lt; EOF 本文作者：Koen 参考链接： http://blog.daxuxu.info/2013/04/get_china_ip_from_apnic.html http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html http://blog.csdn.net/hackbuteer1/article/details/6681157]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在VMware下安装RedHat6.X虚拟机]]></title>
    <url>%2Fck74yvgp20031dhkc8rktxnsq.html</url>
    <content type="text"><![CDATA[安装VMware VMware官网：http://www.vmware.com/cn VMware10下载链接：https://share.weiyun.com/5hTJazF 密码: domcn9 VMware11下载链接：https://share.weiyun.com/5DgWKsn 密码: j3co0z VMware12下载链接：https://share.weiyun.com/56OyvlT 密码：4ydxpf 关于VMware的安装本文不再赘述，相信对于有点计算机基础的同学来说这个并不是什么难题，如果对这部分内容有任何疑问的话可以在本文最下方留言，我会尽快给您回复的&gt;_&lt; 在Vmware创建虚拟机 1、打开VMware，选择“创建新的虚拟机” 2、选择“自定义(高级)”，然后点击“下一步” 3、点击“下一步” 4、选择“稍后安装操作系统(S)”，然后点击“下一步” 5、选择要安装的系统类型和版本，以redhat6.5（64位）为例，客户机操作系统选择“Linux(L)”，版本选择“Red Hat Enterprise Linux 6 64位”，然后点击“下一步” 6、设置虚拟机名称，选择虚拟机存储位置（建议一台虚拟机对应一个文件夹，管理起来方便），然后点击“下一步” 7、点击“下一步” 8、设定给虚拟机分配的内存大小，（若要安装图形界面内存需要大于768M，否则大于512M即可），然后点击“下一步” 9、点击“下一步” 10、点击“下一步” 11、点击“下一步” 12、点击“下一步” 13、设置最大磁盘大小（大于8G即可，建议按默认值进行安装），然后点击“下一步” 注：建议不要勾选“立即分配所有磁盘空间” 14、设置磁盘文件的存储位置，建议跟第6步设置的存储位置一致 15、点击“完成” 16、对新创建的虚拟机的书签页右单击，选择“设置” 在弹出的“虚拟机设置”窗口中选择“CD/DVD（SATA）”选项，选择“使用ISO影响文件”，并按“浏览”找到系统的镜像文件（*.ISO）所在的路径并打开，然后点击“确定” 至此，一台VMware虚拟机新建完成，接下来将进行系统的安装。 安装RedHat6.X 1、点击“开启此虚拟机”，开启虚拟机 2、选择“Install or upgrade an existing system” 3、选择“Skip”，跳过磁盘检测 4、点击“Next”，跳过欢迎界面 5、选择语言，然后点击“Next” 6、选择键盘，然后点击“Next” 7、选择基本存储设备(Basic Storage Devices)，然后点击“Next” 8、选择“Yes，discard any data”，忽略所有磁盘数据 9、设置主机名（安装完成后再配置也可），然后点击“Next” 10、选择上海时区（注：地图上没有北京），取消“System clock uses UTC”选项，然后点击“Next” 11、设置超级用户（root）密码(注：密码不得少于6个字符)，然后点击“Next” 12、如果设置的密码强度不够，会出现如上提示，选择“Use Anyway” 13、选择“自定义分区（Create Custom Layout）”，然后点击“Next” 14、点击“Create” 15、选择“标准分区（Standard Partition）”，然后点击“Create” 16、建立/boot分区 选择“挂载点（Mount Point）”为/boot，大小（Size）在100M~200M之间即可，然后点击“OK” 17、点击“Create” 18、选择“标准分区（Standard Partition）”，然后点击“Create” 19、建立Swap分区 选择“文件系统(File System Type)”为swap，大小（Size）为虚拟机内存的一至两倍，然后点击“OK” 20、点击“Create” 21、选择“标准分区（Standard Partition）”，然后点击“Create” 22、建立根分区（/） 选择“挂载点（Mount Point）”为/，并选择“Fill to maximum allowable size”，将剩余空间全部划分到 / 下，也可以自定义大小，然后点击“OK” 23、创建完分区，点击“Next” 注：以上是最简单的一种分区方案，实际应用中请根据自己的需要设计相应的分区方案 24、点击“格式化（Format）” 25、点击“写入到磁盘（Write changes to disk）” 注：在此之前的所有步骤都是可逆的，可以选择返回（Back）进行调整 26、当用U盘在给物理机（真机）装系统时候，需要点击“Change device”更改boot loader的安装位置，否则直接点击“Next” 27、根据虚拟机的用途来选择所要安装的组件，此处以Desktop(有图形界面)为例，如还需安装必需组件之外的软件包，请勾选页面下方的“Customize now”，然后点击“Next” 28、根据需求选择要安装的软件包（由于我的语言选择的是英语，所以需要在Languages选项卡中选中“中文支持”（Chinese Support）），然后点击“Next” 29、接下来便是耐心的等待操作系统安装完成 30、安装完成后，点击右下方的“Reboot”按钮，重启虚拟机 首次启动系统的一些配置 1、点击“Forward” 2、选择“Yes，I agree to the License Agreement”，然后点击“Forward” 3、选择“No,I prefer to register at a later time”，点击“Forward” 4、选择“Register Later” 5、点击“Forward” 6、创建一个普通用户，点击“Forward”(注：也可不创建直接点击“Forward”) 7、点击“Forward” 8、点击“OK” 9、点击“Finish” 至此，一台Redhat6.X的虚拟机安装完毕，你可以输入用户名密码登录系统开始你的Linux之旅了&gt;_&lt; EOF 本文作者：Koen]]></content>
      <categories>
        <category>Linux营地</category>
      </categories>
      <tags>
        <tag>系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML基础入门]]></title>
    <url>%2Fck74yvgoc000qdhkc78c40lc4.html</url>
    <content type="text"><![CDATA[前言 本文主要对HTML基础中常用的一些概念、标签、属性进行讲解，其实HTML的知识远远不止这些，如果希望深入学习HTML的相关知识，可到W3school上进行详细，深入的学习。 HTML初识 什么是HTMLHTML 指的是超文本标记语言 (Hyper Text Markup Language) 是一种使用标记标签来描述网页的标记语言，而不是编程语言。所谓的超文本就是指页面内可以包含图片、链接、甚至音乐，等非文字元素。HTML文件的后缀名是.html，使用一般的文本编辑器就能编辑，之后再使用浏览器打开，就能看见你所编辑的网页。 HTML文件结构 上图展示的是html文件简单的机构图，由此可见，一般的html文件结构就是下面这样的： 123456789&lt;html&gt; &lt;head&gt; &lt;title&gt;.....&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;.....&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; HTML是一种标记语言，这些&lt;..&gt;就叫做标签，而HTML就是使用这些标签来描述网页的。 HTML文档HTML文档 也被称为网页，HTML 文档包含 HTML 标签 和 纯文本。Web 浏览器的作用是读取HTML文档，并以网页的形式显示出它们。浏览器不会显示 HTML标签（相当于是隐藏的格式描述），而是使用标签来解释页面的内容。 例如： 123456789&lt;html&gt; &lt;body&gt; &lt;h1&gt;First Heading&lt;/h1&gt; &lt;p&gt;first paragraph&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; &lt;html&gt; 与 &lt;/html&gt; 之间的文本描述网页 &lt;body&gt; 与 &lt;/body&gt; 之间的文本是可见的页面内容 &lt;h1&gt; 与 &lt;/h1&gt; 之间的文本被显示为标题 &lt;p&gt; 与 &lt;/p&gt; 之间的文本被显示为段落 HTML标签什么是标签标签就是上面这些&lt;head&gt;、&lt;body&gt;、&lt;table&gt; 等被尖括号“&lt;”和“&gt;”包起来的对象，绝大部分的标签都是成对出现的，如&lt;table&gt;&lt;/talbe&gt;、&lt;form&gt;&lt;/form&gt;。标签对中的第一个标签是开始标签，第二个标签是结束标签，开始和结束标签也被称为开放标签和闭合标签;当然还有少部分不是成对出现的，如&lt;br&gt;、&lt;hr&gt;等。标签就是用来标记HTML元素的。位于起始标签和结束标签之间的文本就是HTML元素的内容。 什么是元素HTML网页实际上就是由许许多多各种各样的HTML元素构成的文本文件，并且任何网页浏览器都可以直接运行HTML文件。所以可以这样说，HTML元素就是构成HTML文件的基本对象，HTML元素可以说是一个统称而已。HTML元素就是通过使用HTML标签进行定义的。 比如&lt;p&gt;这就是一个标签,&lt;p&gt;内容&lt;/p&gt;这就是一个元素，也就是说元素由一个开始的标签和结束的标签组成，用来包含某些内容。这里有一个值得注意的例外，即&lt;br/&gt;本身既是开始标签也是结束标签，但不包含任何内容，所以这只是个标签。 常用的标签我们知道，网页能实现各种各样的定制，实现各种各样的功能，反过来可以说明我们的标签种类是很多的，这样才能实现各种各样的功能及定义。这里我们先介绍四个最基本的标签： HTML标题 Heading 是通过 &lt;h1&gt;-&lt;h6&gt;等标签进行定义的。例如： 12345&lt;h1&gt;This is first heading&lt;/h1&gt;&lt;h2&gt;This is second heading&lt;/h2&gt;&lt;h3&gt;This is third heading&lt;/h3&gt;...... HTML段落 paragraph 是通过&lt;p&gt;标签进行定义的。例如： 1234&lt;p&gt;This is a paragraph.&lt;/p&gt;&lt;p&gt;This is another paragraph.&lt;/p&gt;...... HTML链接 链接 是通过&lt;a&gt;标签进行定义的。例如： 1&lt;a href="http://shiyanlou.com"&gt;This is a link&lt;/a&gt; HTML图像 image是通过&lt;img&gt;标签进行定义的。例如： 1&lt;img src="shiyanlou.jpg" width="100" height="142" /&gt; 感受HTML尽管现在我们还没有入门，尽管我们只知道了一丢丢，抛开一切，尝尝味道先。用上面学到的一两个标签，写一个简单的例子，体验一把HTML的魅力吧！ 12345678910&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt; My Firest Web &lt;/h1&gt; &lt;p&gt; Hello,My name is koen! &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; HTML文本 HTML元素什么是HTML元素 HTML 元素指的是从开始标签（start tag）到结束标签（end tag）的所有代码。 HTML网页实际上就是由许许多多各种各样的HTML元素构成的文本文件，并且任何网页浏览器都可以直接运行HTML文件。所以可以这样说，HTML元素就是构成HTML文件的基本对象，HTML元素可以说是一个统称而已。HTML元素就是通过使用HTML标签进行定义的。 &lt;开始标签&gt; 元 素 内 容 &lt;结束标签&gt; 下面这就是一个元素： &lt;p&gt; Hello,My name is koen! &lt;/p&gt; HTML元素语法 HTML 元素以开始标签起始 HTML 元素以结束标签终止 元素的内容是开始标签与结束标签之间的内容 某些 HTML 元素具有空内容（empty content） 空元素在开始标签中进行关闭（以开始标签的结束而结束） 大多数 HTML 元素可拥有属性 HTML元素嵌套示例HTML嵌套 顾名思义就是在一个HTML元素的内容中嵌入了另一个HTML元素，例如： 12345&lt;html&gt; &lt;body&gt; &lt;p&gt; Hello,My name is koen! &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 上述例子中一共有三个元素，这样你是否理解了所谓的HTML元素嵌套呢？ HTML空元素没有内容的 HTML 元素被称为空元素。&lt;br&gt; 就是没有关闭标签的空元素（&lt;br&gt;标签用来定义换行）。在 XHTML、XML 以及未来版本的 HTML 中，所有元素都必须被关闭。在开始标签中添加斜杠，比如&lt;br/&gt;，是关闭空元素的正确方法，即使 &lt;br&gt;在所有浏览器中都是有效的，但使用&lt;br/&gt;其实是更长远的保障，说了那么多就是想说以后换行就用&lt;br/&gt;。 前面我们从示例中看出,&lt;p&gt;标签结束以后也后一个换行的动作，那现在又介绍了下面我来给大家展示下&lt;p&gt;标签和&lt;br&gt;标签的区别: 相同之处是br和p都是有换行的属性及意思 区别&lt;br/&gt;是只需一个单独使用，而&lt;p&gt;和&lt;/p&gt;是一对使用 br标签是小换行提行（相当于我们平时文本中输入一个回车），p标签是大换行（分段，相当与两个回车）各行作用。 HTML属性某些标签要想按照作者的意愿来实现在网页上，就得需要一定信息的补充，这信息就叫属性，HTML标签可以加上属性的描述。属性提供了有关 HTML 元素的更多的信息。 是在 HTML 元素的开始标签中定义。 总是以名称和值对应的形式出现，比如：name=”value”。 属性值应该始终被包括在引号内。双引号是最常用的，不过使用单引号也没有问题。 例如： &lt;a href=&quot;http://www.baidu.com&quot;&gt;baidu&lt;/a&gt; href=&quot;http://www.baidu.com，这一部分就叫做&lt;a&gt;标签的属性，是对&lt;a&gt;标签的补充说明，即指向百度的网页。 再看几个例子： &lt;h1 align=&quot;center&quot;&gt; My Firest Web &lt;/h1&gt; #设置标题居中 &lt;body bgcolor=&quot;#000000&quot;&gt; &lt;body bgcolor=&quot;rgb(0,0,0)&quot;&gt; &lt;body bgcolor=&quot;black&quot;&gt; #设置网页背景颜色为黑色 以上三种方式都可以设置背景颜色（上面为黑色），这个属性值可以是十六进制数、RGB值或颜色名。 这里就简单的选择最直观的方式。颜色名支持aqua、black、blue、fuchsia、gray、green、lime、maroon、navy、olive、purple、red、silver、teal、white、yellow） HTML文本格式化一般我们在网页中能看见有各种各样的字体、文本样式，这就是文本格式化标签的功劳。下面我们就来学习使用文本格式化标签（比较常用的） 标签 描述 &lt;b&gt; (bold粗体) &lt;big&gt; (big)大字体 &lt;em&gt; (emphasized)强调字 &lt;i&gt; (italic)斜体 &lt;small&gt; (small)小字体) &lt;strong&gt; (strong)加重语气 例如： 1234567891011121314151617&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align="center"&gt; My Firest Web &lt;/h1&gt; &lt;p&gt; Hello,My name is koen! &lt;/p&gt; &lt;b&gt; bold words &lt;/b&gt;&lt;br/&gt; &lt;strong&gt; strong words &lt;/strong&gt;&lt;br/&gt; &lt;big&gt; big works &lt;/big&gt;&lt;br/&gt; &lt;em&gt; emphasized words &lt;em/&gt;&lt;br/&gt; &lt;i&gt; italic words &lt;/i&gt;&lt;br/&gt; &lt;small&gt; small words &lt;/small&gt;&lt;br/&gt; &lt;/body&gt;&lt;/html&gt; 编辑html文件如上并用浏览器打开即可直观的看出字体的区别。但是可以发现，每写完一句要想换行就要加一个换行标签&lt;br/&gt;比较麻烦，这个时候就可以使用预格式文本来处理。 预格式文本：指代码页和网页展示是一样的格式，不用额外添加换行符标签就能换行 &lt;pre&gt;...&lt;/pre&gt;标签的使用 将刚才的html文件中的换行符标签都删掉，将其内容丢到&lt;pre&gt;标签中，就可以得到与之前差不多的格式。 12345678910111213141516171819&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1 align="center"&gt; My Firest Web &lt;/h1&gt; &lt;p&gt; Hello,My name is koen! &lt;/p&gt;&lt;pre&gt;&lt;b&gt; bold words &lt;/b&gt;&lt;strong&gt; strong words &lt;/strong&gt;&lt;big&gt; big works &lt;/big&gt;&lt;em&gt; emphasized words &lt;em/&gt;&lt;i&gt; italic words &lt;/i&gt;&lt;small&gt; small words &lt;/small&gt;&lt;/pre&gt; &lt;/body&gt;&lt;/html&gt; 这个标签适用于代码的粘贴，你想过没有，要是没有这个标签，要想控制网页中显示的代码格式，是一件多么难的事。 HTML样式上面我们用了各种各样的标签来使HTML文本格式符合我们的意愿，其实有一个属性能帮助我们减少不少的麻烦。 style 提供了一种改变所有 HTML 元素的样式的通用方法。这里可以将背景颜色、字体样式、字体尺寸、字体颜色、对齐方式一并定义好。 123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body style="background-color:powderblue"&gt; &lt;h1 style="text-align:center"&gt; show some function of style &lt;/h1&gt; &lt;p style="text-align:center;font-family:verdana;color:gray"&gt; verdana and white &lt;/p&gt; &lt;p style="font-family:time;color:green"&gt; time and green words &lt;/p&gt; &lt;p style="font-size:40px"&gt; the size of these words is 40 pixels &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 编辑完成后用浏览器打开，看了效果以后是不是有倍感亲切的感觉，以后就不用再单独使用多种标签了，在style中可以一气呵成，将大部分的文本格式全都处理掉了。 HTML超文本 HTML链接之所以你可以在浏览器屏幕上单击鼠标或在键盘上按下按键，从而选择并自动跳转到文档中自己感兴趣的那个主题，或跳转到世界上某处完全不同的集合中的某个文档。那是因为你点击的这就是超链接 相信大家对超链接不会陌生吧，天天都不知道点了多少个呢。超链接可以是一个字，一个词，或者一组词，也可以是一幅图像，你可以点击这些内容来跳转到新的文档或者当前文档中的某个部分。我们在前面的例子中只简单使用了&lt;a&gt;标签 ，用字符作为网页的超链接。下面我们要讲到的都是关于&lt;a&gt;标签的属性。 给文字及图片添加超链接首先我们还是回顾一下最简单的链接使用，直接给文字添加链接到网页和另外的HTML文件。 HTML内容如下： 123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; let's have an example &lt;/p&gt; &lt;p&gt; &lt;a href="http://www.baidu.com"&gt; baidu &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 这是最简单的超链接,接下来我们就来让这个HTML文件链接到另一个HTML文件(在相同的文件夹，再添加一个HTMl文件）。两个html文件内容如下: test.html: 123456789101112131415&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; let's have an example &lt;/p&gt; &lt;p&gt; &lt;a href="http://www.baidu.com"&gt; baidu &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &lt;a href="lianjie.html"&gt; lianjie.html &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; lianjie.html： 123456789&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; This is lianjie.html &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 说完了给文字添加超链接，下面我们就来说说给给图片添加超链接，点击图片，链接到另一个页面，html文件内容如下： 123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; let's have an example &lt;/p&gt; &lt;p&gt; &lt;a href="http://www.baidu.com"&gt; &lt;img src="happy.png" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 超链接的打开方式打开方式分为在本页打开和在新的浏览器窗口打开，默认情况下，超级链接打开新页面的方式是自我覆盖（就是在本页打开）。根据浏览者的不同需要，读者可以指定超级链接的其他打开新窗口的方式。超级链接标签提供了target属性进行设置，取值分别为_self（自我覆盖，默认）、_blank（创建新窗口打开新页面）。 123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; let's have an example &lt;/p&gt; &lt;p&gt; &lt;a href="http://www.baidu.com" target="_blank"&gt; &lt;img src="happy.png" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 在上一个例子中的&lt;a&gt;标签里加入target属性并设置为_blank后，会发现链接到的网页是在新窗口中打开的，而默认的_self属性则是在页面以覆盖的形式打开。 超链接添加提示文字有些时候超链接文字不足以说明点击以后所要链接的内容，所以这个时候我们就需要给超链接添加提示文字，加以描述下一个链接的内容，当光标停留在超链接上时，提示语言就会显现，会让页面显现的很简介。涉及到的属性就是title 123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's First Web &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; let's have an example &lt;/p&gt; &lt;p&gt; &lt;a href="http://www.baidu.com" target="_blank" title="this word will link to the web of baidu"&gt; &lt;img src="happy.png" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 超链接实现书签也许你在网页看过小说，当你在页首点击章节的题目，就会自动的跳转到相应的章节，这是怎样实现的呢？。要实现书签，你就要了解，什么是锚（anchor）。锚（anchor）是引自于船只上的锚，锚被抛下后，船只就不容易飘走、迷路。实际上锚就是用于在单个页面内不同位置的跳转，有的地方叫做书签。涉及到的标签当然还是&lt;a&gt;标签,超级链接标签的name属性用于定义锚的名称，一个页面可以定义多个锚，通过超级链接的href属性可以根据name跳转到对应的锚。如下实现跳转： &lt;a href=&quot;#跳转目的地名称&quot;&gt;跳转起始字符&lt;/a&gt; ... ... ... &lt;a name=&quot;跳转目的地名称&quot;&gt;跳转目的地字符&lt;/a&gt; 具体实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;html&gt; &lt;head&gt; &lt;title&gt;HTML&lt;/title&gt; &lt;/head&gt; &lt;body style="font-size:20px"&gt; &lt;p style="text-align:center"&gt;HTML LEARNING&lt;/p&gt; &lt;p&gt; &lt;a href="#c1"&gt; HTML chushi&lt;/a&gt; &lt;/p&gt; &lt;p&gt; &lt;a href="#c2"&gt;HTML wenben &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &lt;a href="#c3"&gt;HTML chaowenben 1 &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &lt;a href="#c4"&gt; HTML chaowenben 2 &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &lt;a href="#c5"&gt;HTML shiyan &lt;/a&gt; &lt;/p&gt; &lt;h1&gt;&lt;a name="c1"&gt;&lt;/a&gt;chapter 1 chushi HTML&lt;/h1&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;h1&gt;&lt;a name="c2"&gt;&lt;/a&gt;chapter 2 wenben HTML&lt;/h1&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;h1&gt;&lt;a name="c3"&gt;&lt;/a&gt;chapter 3 chaowenben 1 HTML&lt;/h1&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;h1&gt;&lt;a name="c4"&gt;&lt;/a&gt;chapter 4 chaowenben 2 HTML&lt;/h1&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;h1&gt;&lt;a name="c5"&gt;&lt;/a&gt;chapter 5 shiyan HTML&lt;/h1&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;p&gt;lalalaalalal&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; HTML表格HTML 网页设计不可或缺的元素就是表格（Table），通常表格用来做版面的排版，而表格的用法包含了几个重要的标签，分別是&lt;table&gt;、&lt;tr&gt; 与&lt;td&gt;这几个重点，组合起來才是个完整的表格，表格由&lt;table&gt;标签来定义。每个表格均有若干行（由&lt;tr&gt;标签定义），每行被分割为若干单元格（由&lt;td&gt;标签定义）。字母 td 指表格数据（table data），即数据单元格的内容。&lt;th&gt;标签用来定义表头。数据单元格可以包含文本、图片、列表、段落、表单、水平线、表格等等。 例如：123456789101112131415161718192021&lt;html&gt; &lt;head&gt; &lt;title &gt;TABLE&lt;/title&gt; &lt;/head&gt; &lt;body style="font-size:20px"&gt; &lt;p style="text-align:center"&gt;table practice&lt;/p&gt; &lt;table align="center" border="1"&gt; &lt;tr&gt; &lt;td&gt;first row and first column&lt;/td&gt; &lt;td&gt;first row and second column&lt;/td&gt; &lt;td&gt;first row and third column&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;second row and first column&lt;/td&gt; &lt;td&gt;second row and second column&lt;/td&gt; &lt;td&gt;thirt row and third column&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; border=”1”定义的是最外面边框粗细，为1，你也可以设置为0，就是不显示边框（默认就是没有边框） 下面再介绍表格两个属性： colspan：控制此单位所占列数 rowspan：控制此单位所占行数 123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;title &gt;TABLE&lt;/title&gt; &lt;/head&gt; &lt;body style="font-size:30px"&gt; &lt;p style="text-align:center"&gt;table practice&lt;/p&gt; &lt;table align="center" border="15" &gt; &lt;tr&gt; &lt;td align="center" colspan="2"&gt;first row and first column&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;second row and first column &lt;/td&gt; &lt;td&gt;second row and second column &lt;/td&gt; &lt;td &gt;second row and third column&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;third row and first column &lt;/td&gt; &lt;td&gt;third row and second column &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 如果不是很理解，我们就来看看在网页上的表现，对比起来有助于我们理解。 让第一行第一列这个单位占两列，让第二行第一列这个单位占两行，就是这个效果。 表格还有很多细节可以定义,我们在这里就简单叙述，具体的可以参考W3School 标签：&lt;th&gt;表头&lt;/th&gt;：设置表头 标签：&lt;caption&gt;标题&lt;/caption&gt;：设置表的标题 属性：cellpadding=”…”设置单元格边距 属性：bgcolor=”…”设置表格背景颜色 属性：background=”…” 以某张图片作为表格背景 HTML图像上面我们简单提到过用图像作为链接使用，接下来我们来详细讲述下图像的应用。 一般我们用到的就是插入图片、将图片多为背景、再者将图片作为链接。涉及到的标签就是&lt;img&gt; 先设置一张图片作为网页背景图片，在body属性中加入background属性添加背景图片 1234567&lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;/body&gt;&lt;/html&gt; 插入一张图片,写法如下： &lt; img src=”路径加文件名” &gt; 12345678&lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;p&gt;let's have an example&lt;img src="2.png"&gt;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 插入图片后： 这时我们可以看出，字体和图片的低端是对齐的，下面我们就来调整下对齐方式 添加属性调整图文的对齐方式 在&lt;img&gt;标签中加入align属性，调整对齐。相对字体上下可加的参数有bottom、middle、top，默认就是我们刚看见的bottom，相对字体左右可加的参数有right，left默认为right 1234567891011&lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;p&gt;let's have an example&lt;img src="2.png"&gt;&lt;/p&gt; &lt;p&gt;align top&lt;img src="2.png" align="top"&gt;&lt;/p&gt; &lt;p&gt;align middle&lt;img src="2.png" align="middle"&gt;&lt;/p&gt; &lt;p&gt;align left&lt;img src="2.png" align="left"&gt;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 效果如下： 调整插入图片尺寸 大多数的尺寸都没有那么合适，直接插入以后会破换整体页面的效果。所以在插入图片时，很有必要控制其尺寸，这是很容易办到的，只需要在&lt;img&gt;标签中加入width、height两个属性。 1234567891011&lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;p&gt;let's have an example&lt;img src="2.png" width="80" height="80"&gt;&lt;/p&gt; &lt;p&gt;align top&lt;img src="2.png" align="top" width="80" height="80"&gt;&lt;/p&gt; &lt;p&gt;align middle&lt;img src="2.png" align="middle" width="80" height="80"&gt;&lt;/p&gt; &lt;p&gt;align left&lt;img src="2.png" align="left" width="80" height="80"&gt;&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 创建图片映射 在这之前我们动手试验过将图片作为链接来使用，触发链接的方式就是点击图片的任何地方都可以链接到跳转地址，有时我们需要实现的是点击图片的不同地方跳转到不同的地方。意思就是，一张图片我们可以创建带有可供点击区域的图像地图，其中每个区域就是一个超链接。涉及到的标签就是&lt;map&gt;标签，用来指定图片,&lt;area&gt;用来指定超链接区域。写法如下： &lt;img src=&quot;xx.jpg&quot; usemap=&quot;#mp&quot;/&gt; &lt;map name=&quot;mp&quot; id=&quot;mp&quot;&gt; &lt;area&gt; ... ... ... &lt;/area&gt; &lt;/map&gt; 这里以一张图片作为地图，在&lt;area&gt;标签中我们会涉及到shape、coords、 href属性，分别用来指定超链接区域形状，超链接区域坐标，还有超链接跳转地。 12345678910111213141516&lt;html&gt; &lt;head&gt; &lt;title&gt;image test&lt;/title&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;p&gt;image map test &lt;/p&gt; &lt;img src="2.png" usemap="#koen"/&gt; &lt;map name="koen"&gt; &lt;area shape="rect" coords="50,10,100,60" href="lianjie.html" target="_blank" &lt;/map&gt; &lt;/body&gt;&lt;/html&gt; 然后，当你点击你所设置的区域内时，会跳转到所指定的html页面 shape属性的取值可以是：rect(矩形)、circle(圆形)、poly(多边形)和default(整个图像区域)。这里采用的是矩形。 coords属性对于矩形而言，coords有4个值，分别用逗号隔开，表示矩形区域左上角x坐标、左上角y坐标、右下角x坐标和右下角y坐标，这里获取坐标的方式，用截图工具帮忙就好。 HTML列表HTML列表标记主要有三种：有序列表、无序列表和定义列表。 有序列表有序列表始于&lt;ol&gt;标签。每个列表项始于&lt;li&gt;标签。列表项内部可以使用段落、换行符、图片、链接以及其他列表等等。 12345678910111213&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;/body&gt;&lt;/html&gt; 在有序列表中我们还能定义其他的排序方式，上面是默认的是数字排序，下面我们再加上字母排序和罗马数字排序。只需要添加type属性就可以了，”a”表示以小写字母来排序;”A”就是使用大写字母来排序;”i”就是以小写罗马数字来排序;”I”就是以大写罗马数字来排序。还可以添加start属性来决定起始地。 123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;ol start="2"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;ol type="a"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;ol type="A"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;ol type="i"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;ol type="I"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;/body&gt;&lt;/html&gt; 无序列表无序列表在HTML中还是很常用的。无序列表始于&lt;ul&gt;标签。每个列表项始于&lt;li&gt;（有序无序是一样的）。无序列表排序的时候就是给每个列表项加各种小符号其中分为Disc（默认）实心黑点、Cirle小圈、square方点，用type属性来指定。 1234567891011121314151617181920212223&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;ul&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ul&gt; &lt;ul type="circle"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ul&gt; &lt;ul type="square"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt;&lt;/html&gt; 定义列表定义列表通常用于术语的定义和解释。定义列表由&lt;dl&gt;开始，术语由&lt;dt&gt;开始，解释说明有&lt;dd&gt;开始，&lt;dd&gt;....&lt;/dd&gt;里的文字缩进显示。 123456789101112131415161718192021222324&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body background="1.jpg"&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ol&gt; &lt;ul type="square"&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;C language&lt;/li&gt; &lt;/ul&gt; &lt;dl&gt; &lt;dt&gt;hadoop&lt;/dt&gt; &lt;dd&gt;it's useful!!!&lt;/dd&gt; &lt;dt&gt;linux&lt;/dt&gt; &lt;dd&gt;it's nice!!!&lt;/dd&gt; &lt;/dl&gt; &lt;/body&gt;&lt;/html&gt; HTML块首先，我们要知道，HTML元素被定义为块级元素和内联元素。 块级元素(block)特性： 总是独占一行，表现为另起一行开始，而且其后的元素也必须另起一行显示 宽度(width)、高度(height)、内边距(padding)和外边距(margin)都可控制 就像以前用到的&lt;h1&gt;,&lt;p&gt;,&lt;ul&gt;,&lt;table&gt;标签。 内联元素(inline)特性： 和相邻的内联元素在同一行 宽度(width)、高度(height)、内边距的top/bottom(padding-top/padding-bottom)和外边距的top/bottom(margin-top/margin-bottom)都不可改变，就是里面文字或图片的大小 就像以前用到的&lt;b&gt;,&lt;td&gt;,&lt;a&gt;,&lt;img&gt;标签。 在这里我们先介绍两个标签&lt;div&gt;标签和&lt;span&gt;标签。 &lt;div&gt;用来定义文档中的分区或节（division/section），没有特定的含义。它是可用于组合其他 HTML 元素的容器 &lt;span&gt;用来组合文档中的行内元素，也没有特定的含义 &lt;div&gt;的用法： 12345678910111213&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body style="font-size:20px;background-color:gray"&gt; &lt;div style="color:white"&gt; &lt;h3&gt;This is a header&lt;/h3&gt; &lt;p&gt;This is a paragraph.&lt;/p&gt; &lt;p&gt;we can control all style in div&lt;/p&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; HTML布局大多的网页布局要配合CSS来完成,CSS用于对元素进行定位或者为页面创建背景以及色彩丰富的外观。由于这里我们涉及到HTML的基础知识，我们就用我们现有的知识来进行布局。 网页布局可以通过&lt;table&gt;元素，或者&lt;div&gt;元素实现。先来个简单的&lt;table&gt;布局网页 我们在之前已经学习了表格，下面我们就来将一个网页的一个板块用没有边框的表格来布局（添加背景颜色和布置文本内容） 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;html&gt; &lt;head&gt; &lt;title&gt; Koen's Test Web &lt;/title&gt; &lt;/head&gt; &lt;body bgcolor="gray"&gt; &lt;table width="1000"&gt; &lt;tr&gt; &lt;td colspan="2" style="background-color: royalblue"&gt; &lt;h1 align="center"&gt;shiyanlou book store&lt;/h1&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr valign="top"&gt; &lt;td style="background-color: darkorange;width:300px"&gt; &lt;dl&gt; &lt;dt&gt;list of book&lt;/dt&gt; &lt;dd&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;c&lt;/li&gt; &lt;/ol&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/td&gt; &lt;td style="background-color: forestgreen;height:500px;width:700px;"&gt; &lt;h1 style="font-size: 20px;text-align: center"&gt;the summary of the book&lt;/h1&gt; &lt;p&gt;i will lead you to travel in the season of linux&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td colspan="2" style="background-color: powderblue;text-align:center;height: 100px"&gt; good good study day day up&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 这个网页只是一个简单的表格，所用的都是我们学过的标签而已，橙色中还加入了我们上面刚学习的定义性列表嵌套有序列表。 下面我们再使用&lt; div&gt;元素进行布局（尽量达到上面的页面效果）： 一般的div元素结构如下图（思路也是用table的思路）： 具体实现内容： 123456789101112131415161718192021222324252627282930313233343536&lt;html&gt; &lt;head&gt; &lt;style&gt; div#container&#123;width:1000px&#125; div#header &#123;background-color: royalblue ;height: 100px;text-align:center;font-size: 20px&#125; div#sidebar&#123;background-color: darkorange;height:400px;width:300px;float:left;&#125; div#mainbody &#123;background-color: forestgreen;height:400px;width:700px;float:left;&#125; div#footer &#123;background-color: powderblue;height: 100px;clear:both;text-align:center;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt; &lt;h1&gt;shiyanlou book store&lt;/h1&gt; &lt;/div&gt; &lt;div id="sidebar"&gt; &lt;dl&gt; &lt;dt&gt;list of book&lt;/dt&gt; &lt;dd&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;c&lt;/li&gt; &lt;/ol&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div id="mainbody"&gt; &lt;h1&gt;the summary of the book&lt;/h1&gt; &lt;p&gt;i will lead you to travel in the season of linux&lt;/p&gt; &lt;/div&gt; &lt;div id="footer"&gt;good good study day day up&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; HTML表单学习表单首先我们要知道，表单标签是什么，表单标签就是用于网页中的数据提交，比如我们注册网页，在留言板中留言、评论等可以填写数据、提交、处理的地方都需要表单标签，form表单标签内有输入框input、单选、多选、select下拉列表菜单与跳转菜单、提交按钮等标签内容。 我们就直接在上面的代码中修改，首先我们尝试的是搜集不同类型的用户输入，这里我们就只涉及文本和密码只需要涉及到一个&lt;input&gt;标签和type属性就能完成 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;style&gt; div#container&#123;width:1000px&#125; div#header &#123;background-color: royalblue ;height: 100px;text-align:center;font-size: 20px&#125; div#sidebar&#123;background-color: darkorange;height:400px;width:300px;float:left;&#125; div#mainbody &#123;background-color: forestgreen;height:400px;width:700px;float:left;&#125; div#footer &#123;background-color: powderblue;height: 100px;clear:both;text-align:center;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt; &lt;h1&gt;shiyanlou book store&lt;/h1&gt; &lt;/div&gt; &lt;div id="sidebar"&gt; &lt;dl&gt; &lt;dt&gt;list of book&lt;/dt&gt; &lt;dd&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;c&lt;/li&gt; &lt;/ol&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div id="mainbody"&gt; &lt;h1&gt;the summary of the book&lt;/h1&gt; &lt;p&gt;i will lead you to travel in the season of linux&lt;/p&gt; &lt;form&gt; user： &lt;input type="text" name="user"&gt; &lt;br /&gt; password： &lt;input type="password" name="password"&gt; &lt;/form&gt; &lt;/div&gt; &lt;div id="footer"&gt;good good study day day up&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 当你输入时你会发现，username是可见的，password是被点替换了的，这就是这两个类型的区别。 下面我们再增添两种选框，一种是多选框，一种是单选框。当用户从若干给定的的选择中选取其一时，就会用到单选框。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;style&gt; div#container&#123;width:1000px&#125; div#header &#123;background-color: royalblue ;height: 100px;text-align:center;font-size: 20px&#125; div#sidebar&#123;background-color: darkorange;height:400px;width:300px;float:left;&#125; div#mainbody &#123;background-color: forestgreen;height:400px;width:700px;float:left;&#125; div#footer &#123;background-color: powderblue;height: 100px;clear:both;text-align:center;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt; &lt;h1&gt;shiyanlou book store&lt;/h1&gt; &lt;/div&gt; &lt;div id="sidebar"&gt; &lt;dl&gt; &lt;dt&gt;list of book&lt;/dt&gt; &lt;dd&gt; &lt;ol&gt; &lt;li&gt;hadoop&lt;/li&gt; &lt;li&gt;linux&lt;/li&gt; &lt;li&gt;c&lt;/li&gt; &lt;/ol&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;/div&gt; &lt;div id="mainbody"&gt; &lt;h1&gt;the summary of the book&lt;/h1&gt; &lt;p&gt;i will lead you to travel in the season of linux&lt;/p&gt; &lt;form&gt; user： &lt;input type="text" name="user"&gt; &lt;br /&gt; password： &lt;input type="password" name="password"&gt; &lt;/form&gt; &lt;form&gt; &lt;input type="radio" name="sex" value="male" /&gt; Male &lt;br/&gt; &lt;input type="radio" name="sex" value="female" /&gt; Female &lt;/form&gt; &lt;form&gt; &lt;input type="checkbox" name="married" /&gt; married &lt;br/&gt; &lt;input type="checkbox" name="have a job" /&gt; have a job &lt;br/&gt; &lt;input type="checkbox" name="chinese" /&gt; chinese &lt;/form&gt; &lt;/div&gt; &lt;div id="footer"&gt;good good study day day up&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; EOF 本文作者：Koen 参考链接：https://www.shiyanlou.com/courses/19]]></content>
      <categories>
        <category>Web阵地</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扩展正则表达式]]></title>
    <url>%2Fck74yvgp40039dhkcw0rvgeyb.html</url>
    <content type="text"><![CDATA[基础正则表达式 字符 含义 字符 含义 ^ 只匹配行首 $ 只匹配行尾 * 匹配0个或多个在*之前的字符 [ ] 只匹配[]内字符，可以是一个单字符，也可以是符号序列，使用-表示[ ]内字符序列范围，如用[1-5]代替[12345] \ 只用来屏蔽一个元字符的特殊含义 . 只匹配任意单字符 pattem\ {n\ } 只用来匹配前面pattem出现次数，n为次数 pattem\ {n,\ } 含义同上，但次数最少为n pattem\ {n,m\ } 含义同上，但pattem出现次数在n和m之间 与基础正则表达式简单对比 正规表示法: 过滤掉文件 regular_express.txt 中的空行和注释行： # grep -v &apos;^$&apos; regular_express.txt |grep -v &apos;^#&apos; 需要使用到管线命令来搜寻两次！ 那么如果使用延伸型的正规表示法，我们可以简化为： # egrep -v &apos;^$|^#&apos; regular_express.txt 利用支持延伸型正规表示法的 egrep 与特殊字符 “|” 的组功能来区隔两组字符串，如此一来，就方便了许多。 此外，grep 默认仅支持基础正则表达式，如果要使用扩展性正则表达式，可以使用 grep - E,grep -E 与 egrep 相当于命令别名关系。 扩展规则 + 表示重复一个或一个以上的前一个 RE 字符# egrep -n &apos;go+d&apos; regular_express.txt 普通写法： # grep -n &apos;goo*d&apos; regular_express.txt 上面两条命令匹配的字符串是：god、good、goood… ? 表示重复零个或一个前一个 RE 字符# egrep -n &apos;go?d&apos; regular_express.txt 上述命令匹配的字符串是：gd、god. | 表示用或的方式找出数个字符串# egrep -n &apos;gd|good&apos; regular_express.txt 匹配有 gd 或 good 的行 ( ) 表示找出群组字符串# egrep -n &apos;g(la|oo)d&apos; regular_express.txt 匹配有 glad 或 good 这两个字符串 ( )+ 多个重复群组判别# echo &apos;AxyzxyzxyzxyzC&apos;|egrep &apos;A(xyz)+C&apos; # echo &apos;AxyzxyzxyzxyzC&apos;|egrep &apos;A(xz)+C&apos; 要找开头是 A 结尾是 C 中间有一个以上的 ‘xyz’ 或 ‘xz’ 字符串的意思。 EOF 本文作者：koen]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP网络协议基础]]></title>
    <url>%2Fck74yvgoz002tdhkc4tf3wegy.html</url>
    <content type="text"><![CDATA[TCP/IP简介 TCP/IP背景和介绍上世纪 70 年代，随着计算机技术的发展，计算机使用者意识到：要想发挥计算机更大的作用，就要将世界各地的计算机连接起来。但是简单的连接是远远不够的，因为计算机之间无法沟通。因此设计一种通用的“语言”来交流是必要可少的，这时 TCP/IP 协议就应运而生了。 TCP/IP（Transmission Control Protocol/Internet Protocol）是传输控制协议和网络协议的简称，它定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准。 TCP/IP 不是一个协议，而是一个协议族的统称，里面包括了 IP 协议、IMCP 协议、TCP 协议、以及 http、ftp、pop3 协议等。网络中的计算机都采用这套协议族进行互联。 网络协议栈架构提到网络协议栈结构，最著名的当属 OSI 七层模型，但是 TCP/IP 协议族的结构则稍有不同，它们之间的层次结构有如图对应关系： 可见 TCP/IP 被分为 4 层，每层承担的任务不一样，各层的协议的工作方式也不一样，每层封装上层数据的方式也不一样： 应用层：应用程序通过这一层访问网络，常见 FTP、HTTP、DNS 和 TELNET 协议 传输层：TCP 协议和 UDP 协议 网络层：IP 协议，ARP、RARP 协议，ICMP 协议等 网络接口层：是 TCP/IP 协议的基层，负责数据帧的发送和接收 预备知识IP地址网络上每一个节点都必须有一个独立的 IP 地址，通常使用的 IP 地址是一个 32bit 的数字，被 . 分成 4 组，例如，255.255.255.255 就是一个 IP 地址。有了 IP 地址，用户的计算机就可以发现并连接互联网中的另外一台计算机。 在 Linux 系统中，可以用这样一条命令查看自己的 IP 地址： # ifconfig -a 域名用 12 位数字组成的 IP 地址很难记忆，在实际应用时，用户一般不需要记住 IP 地址，互联网给每个 IP 地址起了一个别名，习惯上称作域名。 域名与计算机的 IP 地址相对应，并把这种对应关系存储在域名服务系统 DNS(Domain Name Service)中，这样用户只需记住域名就可以与指定的计算机进行通信了。 常见的域名包括 com、net 和 org 三种顶级域名后缀，除此之外每个国家还有自己国家专属的域名后缀（比如我国的域名后缀为 cn）。目前经常使用的域名诸如百度（www.baidu.com）、Linux 组织（www.lwn.net）等等。 我们可以使用命令”nslookup”、“dig”或者“ping”来查看与域名相对应的 IP 地址 # ping www.baidu.com # dig www.baidu.com MAC地址MAC（Media Access Control）地址，或称为物理地址、硬件地址，用来定义互联网中设备的位置。 在 TCP/IP 层次模型中，网络层管理 IP 地址，链路层则负责 MAC 地址。因此每个网络位置会有一个专属于它的 IP 地址，而每个主机会有一个专属于它 MAC 地址。 端口号IP 地址是用来发现和查找网络中的地址的，但是不同程序如何互相通信呢，这就需要端口号来识别了。如果把 IP 地址比作一间房子 ，端口就是出入这间房子的门。真正的房子只有几个门，但是端口采用 16 比特的端口号标识，一个 IP 地址的端口可以有 65536（即：2^16）个之多！ 服务器的默认程序一般都是通过人们所熟知的端口号来识别的。例如，对于每个 TCP/IP 实现来说，SMTP（简单邮件传输协议）服务器的 TCP 端口号都是 25，FTP（文件传输协议）服务器的 TCP 端口号都是 21，TFTP(简单文件传输协议)服务器的 UDP 端口号都是 69。任何 TCP/IP 实现所提供的服务都用众所周知的 1－1023 之间的端口号。这些人们所熟知的端口号由 Internet 端口号分配机构（Internet Assigned Numbers Authority, IANA）来管理。 封装与分用封装：当应用程序发送数据的时候，数据在协议层次当中从顶向下通过每一层，每一层都会对数据增加一些首部或尾部信息，如下图所示，传输层传给网络层的数据单元称作 TCP 报文段(TCP segment) 或 UDP数据报(UDP datagram) 。网络层传给链路层的数据单元称作 IP 数据报(IP datagram)。链路层上的传输单元称作帧(Frame)。 分用：当主机收到一个数据帧时，数据就从协议层底向上升，通过每一层时，检查并去掉对应层次的报文首部或尾部，与封装过程正好相反。 RFCRFC（Request for Comment）文档是所有以太网协议的正式标准，并在其官网上面公布，由 IETF 标准协会制定。大量的 RFC 并不是正式的标准，出版的目的只是为了提供信息。RFC 的篇幅不一，从几页到几百页不等。每一种协议都用一个数字来标识，如 RFC 3720 是 iSCSI 协议的标准，数字越大说是 RFC 的内容越新或者是对应的协议（标准）出现的比较晚。 所有的 RFC 文档都可以从网络上找到，其官网为IETF。在网站上面可以通过分类以及搜索快速找到目标协议的 RFC 文档。目前在 IETF 网站上面的 RFC 文档有数千个，但是我们不需要全部掌握，在工作或学习中如果遇到可以找到对应的解释，理论与实际结合会有更好地效果，单纯阅读 RFC 的效果一般。 链路层介绍 简介网络层协议的数据单元是 IP 数据报 ，而数据链路层的工作就是把网络层交下来的 IP 数据报 封装为 帧（frame）发送到链路上，以及把接收到的帧中的数据取出并上交给网络层。 为达到这一目的，数据链路必须具备一系列相应的功能，主要有： 将数据封装为帧（frame），帧是数据链路层的传送单位 控制帧的传输，包括处理传输差错，调节发送速率与接收方相匹配 在两个网络实体之间提供数据链路通路的建立、维持和释放的管理 数据帧的结构是这样的： 控制帧的传输差错控制通信系统必须具备发现差错的能力，并采取措施纠正之，使差错控制在所能允许的尽可能小的范围内，这就是差错控制过程，也是数据链路层的主要功能之一。 反馈重发接收方通过对差错编码(奇偶校验码或 CRC 码)的检查，可以判定一帧在传输过程中是否发生了差错。一旦发现差错，一般可以采用反馈重发的方法来纠正。这就要求接受方收完一帧后，向发送方反馈一个接收是否正确的信息，使发送方据此做出是否需要重新发送的决定。发送方仅当收到接收方已正确接收的反馈信号后才能认为该帧已经正确发送完毕，否则需要重发直至正确为止。 计时器如果某一帧发送出现问题，一直不能发送成功，为了避免传输过程停滞不前，通常引入 计时器 (Timer) 来限定接收方发回反馈消息的时间间隔。当发送方发送一帧的同时也启动计时器，若在限定时间间隔内未能收到接收方的反馈信息，即计时器超时(Timeout)，则可认为传出的帧以出错或丢失，就要重新发送。 序号由于同一帧数据可能被重复发送多次，就可能引起接收方多次收到同一帧并将其递交给网络层的情况。为了防止这种情况，可以采用对发送的帧编号的方法，即赋予每帧一个序号，从而使接收方能从该序号来区分是新发送来的帧还是重发的帧，以此来确定要不要将接收到的帧递交给网络层。 流量控制由于收发双方各自使用的设备工作速率和缓冲存储空间的差异，可能出现发送方的发送能力大于接收方接收能力的现象，此时若不对发送方的发送速率做适当的限制，前面来不及接收的帧将被后面不断发送来的帧“淹没”，从而造成帧的丢失而出错。 由此可见，流量控制实际上是对发送方数据流量的控制，使其发送速率不超过接收方的速率。所以需要一些规则使得发送方知道在什么情况下可以接着发送下一帧，而在什么情况下必须暂停发送，以等待收到某种反馈信息后再继续发送。这就是流量控制。 以太网以太网(Ether-net)是指 DEC 公司、Intel 公司和 Xerox 公司在 1982 年联合公布的一个标准，这个标准里面使用了一种称作 CSMA/CD 的接入方法。而 IEEE802 提供的标准集 802.3(还有一部分定义到了 802.2 中)也提供了一个 CSMA/CD 的标准。 这两个标准稍有不同，因此链路层数据帧的的封装格式也有所不同（数据帧中的地址为 MAC 地址）： PPP（点对点协议）PPP（点到点协议）是为在同等单元之间传输数据设计的链路层协议。这种链路提供全双工操作，并按照顺序传递数据。设计目的主要是用来通过 拨号或专线 方式建立 点对点 连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案。 点对点协议（PPP）为在点对点连接上传输多协议数据包提供了一个标准方法。PPP 最初设计是为两个对等节点之间的 IP 流量传输提供一种封装协议。在 TCP/IP 协议集中它是一种用来同步调制连接的数据链路层协议。 SLIP 与 PPPSLIP协议SLIP 的全称为 Serial Line IP（串行线路 IP）。它是一种对 IP 数据报进行封装的简单形式。 SLIP 协议规定的帧格式规则： IP 数据报以一个称作 END（0xc0）的特殊字符结束。同时为了防止数据报传输之前的线路噪音被误认为是数据报内容，在数据报开始处添加一个 END 字符 如果 IP 数据报中含有 END 字符，就连续传输 0xdb 和 0xdc 来取代它。0xdb 是 SLIP 的 ESC 字符，但它的值与 ASCⅡ码中的 ESC（0x1b）不同 如果 IP 数据报中含有 ESC 字符，就连续传输 0xdb 和 0xdd 来取代它 SLIP 的缺陷： 每一端必须知道对端的 IP 地址，没有办法把本端 IP 地址传递给对端 数据帧中无类型字段，当一条串行线路使用 SLIP 时则不能使用其他协议 SLIP 数据帧中无 checksum，只能依靠上层协议来发现和纠正错误 PPP协议PPP 协议修改了 SLIP 协议中的缺陷，包括以下三个部分： PPP 封装 IP 数据报既支持数据为 8 位和无奇偶校验的异步模式，又支持面向比特的同步链接 通过 LCP（链路控制协议）允许双方进行协商 通过 NCP（网络控制协议）允许双方在网络层上进行协商 PPP 协议的字符规则与 SLIP 有所不同： PPP 帧以标志字符 0x7e 开始和结束，紧接着是一个值为 0xff 的地址字节，然后是一个值为 0x03 的控制字节 由于标志字符是 0x7e，当它出现在信息字段中时，需要连续传送 0x7d 和 0x5e 来替代它 当在信息字段中遇到 0x7d 时，需要连续传送 0x7d 和 0x5d 来替代它 默认情况下，如果字符的值小于 0x20，需要连续传送 0x7d 和 0x21 来替代它 PPP 与 SLIP 相比具有下列优点： PPP 支持在单根串行线路上运行多种网络层协议 每一帧都有 CRC 校验 通信双方可以用 NCP 进行 IP 地址的动态协商 可以类似于 CSLIP 对 TCP 和 IP 首部进行压缩 LCP 可以对多个数据链路选项进行设置 MTU为了提供足够快的响应时间，以太网和 IEEE802.3 对数据帧长度都有限制，其最大值分别为 1500 字节和 1492 字节，链路层的这个特性称作 MTU ，即 最大传输单元 。 当网络层传下来一个 IP 数据报，并且其长度比链路层的 MTU 大，那么网络层就需要对数据报进行分片，使每一片都小于 MTU。 MTU 分为接口 MTU 和路径 MTU：接口 MTU 是所指定的接口所允许发送的最大数据长度；路径 MTU 指两台通信主机路径中最小的 MTU 值。路径 MTU 是不对称的，它在两个方向上不一定一致。 用命令 netstat -in 可以查看网络接口的 MTU: netstat -in IP 网际协议 IP 协议位于网络层，它是 TCP/IP 协议族中最为核心的协议，所有的 TCP、UDP、ICMP 及 IGMP 数据都以 IP 数据报格式传输。IP 协议提供的是 不可靠 、 无连接 的数据报传送服务。 不可靠（unreliable）：IP 协议不能保证数据报能成功地到达目的地，它仅提供传输服务。当发生某种错误时，IP 协议会丢弃该数据报。传输的可靠性全由上层协议来提供。 无连接（connectionless）：IP 协议对每个数据报的处理是相互独立的。这也说明， IP 数据报可以不按发送顺序接收。如果发送方向接收方发送了两个连续的数据报（先是 A，然后是 B），每个数据报可以选择不同的路线，因此 B 可能在 A 到达之前先到达。 IP数据报首先看一下 IP 数据报的格式，其中没有一个字段是多余的，学习 IP 协议就应从学习它的报文字段意义和作用开始。 如上图所示，普通的 IP 数据报的报头长度 20 字节(除非有选项字段)，各个部分的作用： 版本号 ：4 位，用于标明 IP 版本号，0100 表示 IPv4，0110 表示 IPv6。目前常见的是 IPv4。 首部长度 ：4 位，表示 IP 报头长度，包括选项字段。 服务类型(TOS) ：分别有：最小时延、最大吞吐量、最高可靠性、最小花费 4 种服务，如下图所示。4 个标识位只能有一个被置为 1 ： 总长度 ：16 位，报头长度加上数据部分长度，便是数据报的总长度。IP 数据报最长可达 65535 字节。 标识 ：16 位，接收方根据分片中的标识字段相不相同来判断这些分片是不是同一个数据报的分片，从而进行分片的重组。通常每发送一份报文它的值就会加 1。 标志 ：3 位，用于标识数据报是否分片。其中的第 2 位是不分段（DF）位。当 DF 位被设置为 1 时，则不对数据包进行分段处理；第 3 位是分段（MF）位，除了最后一个分段的 MF 位被设置为 0 外，其他的分段的 MF 位均设置为 1。 偏移 ：13 位，在接收方进行数据报重组时用来标识分片的顺序。 生存时间(TTL) ：8 位，用于设置数据报可以经过的最多的路由器个数。TTL 的初始值由源主机设置（通常为 32 或 64），每经过一个处理它的路由器，TTL 值减 1。如果一个数据报的 TTL 值被减至 0，它将被丢弃。 协议 ：8 位，用来标识是哪个协议向 IP 传送数据。ICMP 为 1，IGMP 为 2，TCP 为 6，UDP 为 17，GRE 为 47，ESP 为 50。 首部校验和 ：根据 IP 首部计算的校验和码。 源 IP 和目的 IP ：数据报头还会包含该数据报的发送方 IP 和接收方 IP。 选项 ：是数据报中的一个可变长、可选的信息，不常用，多用于安全、军事等领域。 IP 地址分类为了便于寻址以及层次化构造网络，每个 IP 地址可被看作是分为两部分，即 网络号 和 主机号 。同一个区域的所有主机有相同的网络号(即 IP 地址的前半部分相同)，区域内的每个主机（包括路由器）都有一个主机号与其对应。 IP 地址被分为 A,B,C,D,E 五类，其中 A 类给大型网络或政府机构等，B 类分配给中型网络、跨国企业等，C 类分配给小型网络，D 类用于多播，E 类用于实验，各类可容纳的地址数目不同。其中我们最常见的为 A,B,C 这三类。 IP 地址用 32 位二进制数字表示的时候，A,B,C 类 IP 的网络号长度分别为 8 位、16 位、24 位： A 类地址 A 类地址网络号范围：1.0.0.0—127.0.0.0 A 类 IP 地址范围：1.0.0.0—127.255.255.255 A 类 IP 的私有地址范围：10.0.0.0—10.255.255.255 （所谓的私有地址就是在互联网上不使用，而被用在局域网络中的地址） 127.X.X.X 是保留地址，用做循环测试用的 因为主机号有 24 位，所以一个 A 类网络号可以容纳 2^24-2=16777214 个主机号 B 类地址 B 类地址网络号范围：128.0.0.0—191.255.0.0 B 类 IP 地址范围：128.0.0.0—191.255.255.255 B 类 IP 的私有地址范围：172.16.0.0—172.31.255.255 169.254.X.X 是保留地址；191.255.255.255 是广播地址 因为主机号有 16 位，所以一个 B 类网络号可以容纳 2^16-2=65534 个主机号 C 类地址 C 类地址网络号范围：192.0.0.0—223.255.255.0 C 类 IP 地址范围：192.0.0.0—223.255.255.255 C 类 IP 的私有地址范围：192.168.0.0—192.168.255.255 因为主机号有 8 位，所以一个 C 类网络号可以容纳 2^8-2=254 个主机号 子网划分IP 地址如果只使用 ABCDE 类来划分，会造成大量的浪费：一个有 500 台主机的网络，无法使用 C 类地址。但如果使用一个 B 类地址，6 万多个主机地址只有 500 个被使用，造成 IP 地址的大量浪费。 因此，可以在 ABC 类网络的基础上，进一步划分子网：占用主机号的前几个位，用于表示子网号 。 这样 IP 地址就可看作 IP = 网络号 + 子网号 + 主机号 子网号的位数没有硬性规定，于是我们用 子网掩码 来确定一个 IP 地址中哪几位是主机号，具体使用方法如图： 子网掩码中的 1 标识了 IP 地址中相应的网络号，0 标识了主机号。将 IP 地址和子网掩码进行 逻辑与运算 ，结果就能得到网络号和子网号。 IP 路由选择如果发送方与接收方直接相连（点对点）或都在一个共享网络上（以太网），那么 IP 数据报就能直接送达。 而大多数情况则是发送方与接收方通过若干个路由器(router)连接，那么数据报就需要经过若干个路由器的转发才能送达，它是怎么选择一个合适的路径来”送货”的呢？ IP 层在内存中有一个路由表（输入命令 route -n可以查看路由表），当收到一份数据报并进行发送时，都要对该表进行搜索： 1、搜索路由表，如果能找到和目的 IP 地址完全一致的主机，则将 IP 数据报发向该主机； 2、搜索路由表，如果匹配主机失败，则匹配同子网的路由器(这需要子网掩码的协助)。如果找到路由器，则将 IP 该数据报发向该路由器； 3、搜索路由表，如果匹配同子网路由器失败，则匹配同网络号路由器，如果找到路由器，则将该 IP 数据报发向该路由器； 4、如果以上都失败了，就搜索默认路由，如果默认路由存在，则发报； 5、如果都失败了，就丢掉这个包； 6、接收到数据报的路由器再按照它自己的路由表继续转发，直到数据报被转发到目的主机； 7、如果在转发过程中，IP 数据报的 TTL（生命周期）已经被减为 0，则该 IP 数据报就被抛弃。 NAT 技术当你用 ifconfig 查看 IP 地址时，有时你会发现自己的 IP 地址是这样的———192.186.X.X 或 172.16.X.X这是 C 类网和 B 类网的私有地址，这就是俗称的内网 IP。这是因为你的路由器采用了 NAT 技术。 NAT（Network Address Translation，网络地址转换）是 1994 年提出的。当在专用网内部的一些主机本来已经分配到了内网 IP 地址，但现在又想和因特网上的主机通信时，NAT 技术将其内网 IP 地址转换成全球 IP 地址，然后与因特网连接，也就是说，内网的数台主机使用了同一个全球 IP 地址在上网。 NAT 技术实现了宽带共享，而且有助于缓解 IP 地址空间枯竭的问题。 IP 的未来我们现在使用的 IPv4 协议版本从理论上讲，可以编址 1600 万个网络、40 亿台主机。但采用 A、B、C 三类编址方式后，可用的网络地址和主机地址的数目大打折扣，以至 IP 地址 已于 2011 年 2 月 3 日分配完毕 。 其中北美占有 3/4，约 30 亿个，而人口最多的亚洲只有不到 4 亿个，中国截止 2010 年 6 月 IPv4 地址数量达到 2.5 亿，落后于 4.2 亿网民的需求。地址不足，严重地制约了中国及其他国家互联网的应用和发展。 随着网络技术的发展，计算机网络将进入人们的日常生活，可能身边的每一样东西都需要连入全球因特网，在这样的环境下，IPv6 应运而生。 IPv6 的地址长度是 128 位，通常将这 128 位的地址按每 16 位划分为一个段，将每个段转换成十六进制数字，并用冒号隔开，比如：2000:0000:0000:0000:0001:2345:6789:abcd 就是一个 IPv6 地址。 单从数量级上来说，IPv6 所拥有的地址容量是 IPv4 的约 8×10^28 倍，达到 2^128（算上全零的）个。这不但解决了网络地址资源数量的问题，同时也为除电脑外的设备连入互联网在数量限制上扫清了障碍。 随着 IPv4 不足，支持 IPv6 的网络迅速增长，现在全球已经有 5%的网络使用 IPv6 网络层其它协议 网络层不仅有 IP 协议，还有其它如 ARP、ICMP 等其它协议。 ARP(Address Resolution Protocol)地址解析协议功能当主机通过数据链路发送数据的时候， IP 数据报 会先被封装为一个 数据帧 ，而 MAC 地址 会被添加到数据帧的 报头 （链路层介绍时已讲过）。 ARP 便是在这个过程中通过目标主机的 IP 地址，查询目标主机的 MAC 地址。 原理在你的电脑和路由器中都有一个 ARP 缓存表 ，其中保存的是近期(20 分钟)与自己有过通信的主机的 IP 地址与 MAC 地址的对应关系。 ARP 缓存表使用过程： 当主机要发送一个 IP 数据报的时候，会首先查询一下自己的 ARP 缓存表； 如果在 ARP 缓存表中找到对应的 MAC 地址，则将 IP 数据报封装为数据帧，把 MAC 地址放在帧首部，发送数据帧； 如果查询的 IP－MAC 值对不存在，那么主机就向网络中广播发送一个 ARP 请求数据帧，ARP 请求中包含待查询 IP 地址； 网络内所有收到 ARP 请求的主机查询自己的 IP 地址，如果发现自己符合条件，就回复一个 ARP 应答数据帧，其中包含自己的 MAC 地址； 收到 ARP 应答后，主机将其 IP - MAC 对应信息存入自己的 ARP 缓存，然后再据此封装 IP 数据报，再发送数据帧。 你可以通过命令 arp -a 查看 ARP 缓存表(表项记录 20 分钟超时)，这里还有其它 ARP 命令可以对缓存表做查看、修改： ARP代理如果 ARP 请求是从一个网络上的主机发往另一个网络上的主机，那么连接这两个网络的路由器就可以回答该 ARP 请求，这个过程称作 代理 ARP（Proxy ARP）。 当连接这两个网络的路由器收到该 ARP 请求时，它会发现自己有通向目的主机的路径，随后它会将自己(路由器)的 MAC 地址回复给源主机。源主机会认为路由器的 MAC 地址就是目的主机的 MAC 地址，而对于随后发来的数据帧，路由器会转发到它后面真实 MAC 地址的目的主机。 两个物理网络之间的路由器可以使这两个网络彼此透明化，在这种情况下，只要路由器设置成一个 ARP 代理，以响应一个网络到另一个网络主机的 ARP 请求，两个物理网络就可以使用相同的网络号。 ARP 欺骗从 ARP 代理的原理可以看出来：IP - MAC 的对应信息很容易被伪造！黑客可以伪造 ARP 应答数据帧而欺骗 ARP 请求者，从而达到截获数据的目的。 RARP(Reverse Address Resolution Protocol)逆向地址解析协议听名字就知道，RARP 与 ARP 是相反的关系，用于将 MAC 地址转换为 IP 地址。对应于 ARP，RARP 请求以广播方式传送，而 RARP 应答一般是单播传送的。 某些设备，比如无盘机在启动时可能不知道自己的 IP 地址，它们可以将自己的 MAC 地址使用 RARP 请求广播出去，RARP 服务器就会响应并回复无盘机的 IP 地址。 RARP 在目前的应用中已极少被使用，不再赘述了。 ICMP(Internet Control Message Protocol)控制报文协议通信过程中的发生各种问题时，ICMP 将问题反馈，通过这些信息，管理者可以对所发生的问题作出诊断，然后采取适当的措施去解决它。 ICMP 报文由 8 位错误类型、8 位条件代码和 16 位校验和组成，被封装在一个 IP 数据报中： 报文的类型字段可以有 15 个不同的值，以便描述特定类型的 ICMP 报文，代码字段的值进一步描述不同的条件，各类型的报文及其处理方法如图所示： 也有一些出现差错而不产生 ICMP 报文的情况： 1.ICMP 差错报文 2 . 目的地址是广播或多播地址 3.作为链路层广播的数据报 4.不是 IP 分片的第一片 5.源地址不是单个主机的数据报（源不能为零地址、环回地址、广播多播地址） ping 程序和 traceroute 程序ping 程序和 traceroute 程序是两个常见的 基于 ICMP 协议 的工具。 pingping 程序是对两台主机之间连通性进行测试的基本工具，它只是利用 ICMP 回显请求和回显应答报文，而不用经过传输层（TCP/UDP）。 ping 程序通过在 ICMP 报文数据中存放发送请求的时间值来计算往返时间，当应答返回时，用当前时间减去存放在 ICMP 报文中的时间值，即是往返时间。 ping 程序使用方法为 ping IP 地址 ，ping 命令还可以加上参数，实现更多的功能： -n 只输出数值。 -q 不显示任何传送封包的信息，只显示最后的结果。 -r 忽略普通的 Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题。 -R 记录路由过程。 -v 详细显示指令的执行过程。 -c 数目：在发送指定数目的包后停止。 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。 -t 存活数值：设置存活数值 TTL 的大小。 traceroutetraceroute 程序是用来侦测主机到目的主机之间所经路由情况的重要工具。刚才 ping 程序中讲过，带 -R 参数的 ping 命令也可以记录路由过程，但是，因为 IP 数据报头的长度限制(最多能保存 9 个 IP 地址)，ping 不能完全的记录下所经过的路由器，traceroute 正好就填补了这个缺憾。 traceroute 程序的工作原理很简单： 它发送一份 TTL 为 1 的 IP 数据报给目的主机，经过第一个路由器时，TTL 值被减为 0，则第一个路由器丢弃该数据报，并返回一份超时 ICMP 报文，于此得到了路径中第一个路由器的地址 然后再发送一份 TTL 值为 2 的数据报，便可得到第二个路由器的地址 -以此类推，一直到到达目的主机为止，这样便记录下了路径上所有的路由 IP。 IGMP(Internet Group Management Protocol)组管理协议IGMP 是用于管理多播组成员的一种协议，它的作用在于，让其他所有需要知道自己处于哪个多播组的主机和路由器知道自己的状态。只要某一个多播组还有一台主机，多播路由器就会把数据传输出去，这样，接受方就会通过网卡过滤功能来得到自己想要的数据。 为了知道多播组的信息，多播路由器需要定时的发送 IGMP 查询，各个多播组里面的主机要根据查询来回复自己的状态。路由器来决定有几个多播组，自己要对某一个多播组发送什么样的数据。 传输层：UDP协议 传输层协议从之前介绍的网络层协议来看，通信的两端是两台主机，IP 数据报首部就标明了这两台主机的 IP 地址。但是从传输层来看，是发送方主机中的一个进程与接收方主机中的一个进程在交换数据，因此，严格地讲，通信双方不是主机，而是主机中的进程。 主机中常常有多个应用进程同时在与外部通信(比如你的浏览器和 QQ 在同时运行)，下图中，A 主机的 AP1 进程在于 B 主机的 AP3 进程通信，同时主机 A 的 AP2 进程也在与 B 主机的 AP4 进程通信。 两个主机的传输层之间有一个灰色双向箭头，写着“传输层提供应用进程间的逻辑通信”。 逻辑通信：看起来是数据似乎是沿着双向箭头在传输层水平传输的，但实际上是沿图中的虚线经多个协议层次而传输。 TCP/IP 协议栈传输层有两个重要协议——UDP 和 TCP，不同的应用进程在传输层使用 TCP 或 UDP 之一： 端口刚才的图中，AP1 与 AP3 的通信与 AP2 与 AP4 的通信可以使用同一个传输层协议来传输(TCP 或 UDP)，根据 IP 地址或 MAC 地址都只能是把数据传到正确的主机，但具体需要传到哪一个进程，是通过端口来辨认的。比如同时使用浏览器和 QQ，浏览器占用 80 端口，而 QQ 占用 4000 端口，那么发送过来的 QQ 消息便会通过 4000 端口显示在 QQ 客户端，而不会错误地显示在浏览器上。 端口号有 0～65535 的编号，其中： 编号 0～1023 为 系统端口号 ，这些端口号可以在网址 www.iana.org 查询到，它们被指派给了 TCP/IP 最重要的一些应用程序，以下是一些常见的系统端口号： 编号 1024～49151 为 登记端口号 ，为没有系统端口号的应用程序使用，使用这类端口号必须在 IANA 按规定手续登记，以防止重复。 编号 49152～65535 为 短暂端口号 ，是留给客户进程选择暂时使用的，使用结束后，这类端口号会被放开以供其它程序使用。 UDP 概述UDP(User Datagram Protocol)用户数据报协议，它只在 IP 数据报服务之上增加了很少一点功能，它的主要特点有： (1).UDP 是无连接的，发送数据之前不需要建立连接(而 TCP 需要)，减少了开销和时延。 (2).UDP尽最大努力交付，不保证交付可靠性。 (3).UDP 是面向报文的，对于从应用层交付下来的 应用层数据报，只做很简单的封装(8 字节 UDP 报头)，首部开销小。 (4).UDP 没有拥塞控制，出现网络拥塞时发送方也不会降低发送速率。这种特性对某些实时应用是很重要的，比如 IP 电话，视频会议等，它们允许拥塞时丢失一些数据，因为如果不抛弃这些数据，极可能造成时延的累积。 (5).UDP 支持一对一、一对多、多对一和多对多的交互通信。 从应用层到传输层，再到网络层的各层次封装： UDP报文UDP 数据报可分为两部分：UDP 报头和数据部分。其中数据部分是应用层交付下来的数据。UDP 报头总共 8 字节，而这 8 字节又分为 4 个字段： 源端口 2 字节 在对方需要回信时可用，不需要时可以全 0 目的端口 2 字节 必须，也是最重要的字段 长度 2 字节 长度值包括报头和数据部分 校验和 2 字节 用于检验 UDP 数据报在传输过程中是否有出错，有错就丢弃 tcpdump 抓取 UDP 报文现在我们动手实践，尝试抓取一个 UDP 数据报，并解读其内容。 我们需要编写一个小程序，用于向 指定IP地址 的 指定端口 发送一个 指定内容 的 UDP 数据报，这个小程序的代码如下： 1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/types.h&gt;#include &lt;string.h&gt;int main(void)&#123; int sockfd; struct sockaddr_in server; char msg[20]=&#123;0&#125;; sockfd = socket(AF_INET,SOCK_DGRAM,0); if (sockfd &lt; 0) &#123; perror("socket error!\n"); exit(-1); &#125; memset(&amp;server,0,sizeof(server)); server.sin_family = AF_INET; server.sin_addr.s_addr = inet_addr("192.168.1.1"); server.sin_port = htons(7777); strncpy(msg,"hello",sizeof("hello")); printf("send message:%s\n",msg); if (sendto(sockfd,msg,20,0,(struct sockaddr *)&amp;server,sizeof(server)) != 20) &#123; perror("sendto error!\n"); exit(-1); &#125; exit(0);&#125; 这个 C 程序会向 IP 地址 192.168.1.1 的 7777 端口 发送一条 “hello” 消息。你可以用编辑器修改程序，向不同的 IP 不同的 IP 发送不同的内容。 然后安装一个知名的抓包工具tcpdump，并运行tcpdump Ubuntu下： $ sudo apt-get update $ sudo apt-get install tcpdump $ sudo tcpdump -vvv -X udp port 7777 CentOS/RedHat下： # yum install tcpdump # tcpdump -vvv -X udp port 7777 最后另启动一个终端，编译运行刚才编写的C语言小程序test.c： # gcc -o test test.c # ./test test 程序运行结束，返回刚才运行 tcpdump 的终端查看抓包结果 传输层：TCP协议 概述TCP 和 UDP 处在同一层——运输层，但是它们有很多的不同。TCP 是 TCP/IP 系列协议中最复杂的部分，它具有以下特点： (1) TCP 提供 可靠的 数据传输服务，TCP 是 面向连接的 。应用程序在使用 TCP 通信之前，先要建立连接，这是一个类似“打电话”的过程，通信结束后还要“挂电话” (2) TCP 连接是 点对点 的，一条 TCP 连接只能连接两个端点 (3) TCP 提供可靠传输，无差错、不丢失、不重复、按顺序 (4) TCP 提供 全双工 通信，允许通信双方任何时候都能发送数据，因为 TCP 连接的两端都设有发送缓存和接收缓存 (5) TCP 面向 字节流, TCP 并不知道所传输的数据的含义，仅把数据看作一连串的字节序列，它也不保证接收方收到的数据块和发送方发出的数据块具有大小对应关系 TCP 报文段结构TCP 是面向字节流的，而 TCP 传输数据的单元是 报文段 。一个 TCP 报文段可分为两部分：报头和数据部分。数据部分是上层应用交付的数据，而报头则是 TCP 功能的关键。 TCP 报文段的报头有前 20 字节的固定部分，后面 4n 字节是根据需要而添加的字段。如图则是 TCP 报文段结构： 20 字节的固定部分，各字段功能说明： 1.源端口和目的端口:各占 2 个字节，分别写入源端口号和目的端口号。这和 UDP 报头有类似之处，因为都是运输层协议。 2.序号:占 4 字节序，序号范围[0，2^32-1]，序号增加到 2^32-1 后，下个序号又回到 0。 TCP 是面向字节流的，通过 TCP 传送的字节流中的每个字节都按顺序编号，而报头中的序号字段值则指的是本报文段数据的第一个字节的序号。 3.确认序号:占 4 字节，期望收到对方下个报文段的第一个数据字节的序号。 4.数据偏移:占 4 位，指 TCP 报文段的报头长度，包括固定的 20 字节和选项字段。 5.保留:占 6 位，保留为今后使用，目前为 0。 6.控制位:共有 6 个控制位，说明本报文的性质，意义如下： URG 紧急:当 URG=1 时，它告诉系统此报文中有紧急数据，应优先传送(比如紧急关闭)，这要与紧急指针字段配合使用。 ACK 确认:仅当 ACK=1 时确认号字段才有效。建立 TCP 连接后，所有报文段都必须把 ACK 字段置为 1。 PSH 推送:若 TCP 连接的一端希望另一端立即响应，PSH 字段便可以“催促”对方，不再等到缓存区填满才发送。 RET 复位:若 TCP 连接出现严重差错，RST 置为 1，断开 TCP 连接，再重新建立连接。 SYN 同步:用于建立和释放连接，稍后会详细介绍。 FIN 终止:用于释放连接，当 FIN=1，表明发送方已经发送完毕，要求释放 TCP 连接。 7.窗口:占 2 个字节。窗口值是指发送者自己的接收窗口大小，因为接收缓存的空间有限。 8.检验和:2 个字节。和 UDP 报文一样，有一个检验和，用于检查报文是否在传输过程中出差错。 9.紧急指针:2 字节。当 URG=1 时才有效，指出本报文段紧急数据的字节数。 10.选项:长度可变，最长可达 40 字节。具体的选项字段，需要时再做介绍。 连接的建立和释放刚才说过，TCP 是面向连接的，在传输 TCP 报文段之前先要创建连接，发起连接的一方被称为客户端，而响应连接请求的一方被称为服务端，而这个创建连接的过程被称为 三次握手： (1) 客户端发出请求连接报文段，其中报头控制位 SYN=1，初始序号 seq=x。客户端进入 SYN-SENT(同步已发送)状态。 (2) 服务端收到请求报文段后，向客户端发送确认报文段。确认报文段的首部中 SYN=1，ACK=1，确认号是 ack=x+1，同时为自己选择一个初始序号 seq=y。服务端进入 SYN-RCVD(同步收到)状态。 (3) 客户端收到服务端的确认报文段后，还要给服务端发送一个确认报文段。这个报文段中 ACK=1，确认号 ack=y+1，而自己的序号 seq=x+1。这个报文段已经可以携带数据，如果不携带数据则不消耗序号，则下一个报文段序号仍为 seq=x+1。 至此 TCP 连接已经建立，客户端进入 ESTABLISHED(已建立连接)状态，当服务端收到确认后，也进入 ESTABLISHED 状态，它们之间便可以正式传输数据了。 当传输数据结束后，通信双方都可以释放连接，这个释放连接过程被称为 释放连接 : (1) 此时 TCP 连接两端都还处于 ESTABLISHED 状态，客户端停止发送数据，并发出一个 FIN 报文段。首部 FIN=1，序号 seq=u（u 等于客户端传输数据最后一字节的序号加 1）。客户端进入 FIN-WAIT-1(终止等待 1)状态。 (2) 服务端回复确认报文段，确认号 ack=u+1，序号 seq=v（v 等于服务端传输数据最后一字节的序号加 1），服务端进入 CLOSE-WAIT(关闭等待)状态。现在 TCP 连接处于半开半闭状态，服务端如果继续发送数据，客户端依然接收。 (3) 客户端收到确认报文，进入 FIN-WAIT-2 状态，服务端发送完数据后，发出 FIN 报文段，FIN=1，确认号 ack=u+1，然后进入 LAST-ACK(最后确认)状态。 (4) 客户端回复确认确认报文段，ACK=1，确认号 ack=w+1（w 为半开半闭状态时，收到的最后一个字节数据的编号） ，序号 seq=u+1，然后进入 TIME-WAIT(时间等待)状态。 注意此时连接还没有释放，需要时间等待状态结束后(4 分钟) 连接两端才会 CLOSED。设置时间等待是因为，有可能最后一个确认报文丢失而需要重传。 TCP 可靠传输的实现 (1) TCP 报文段的长度可变，根据收发双方的缓存状态、网络状态而调整。 (2) 当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。 (3) 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段，如果不能及时收到一个确认，将重发这个报文段。这就是稍后介绍的超时重传。 (4) TCP 将保持它首部和数据的检验和。如果通过检验和发现报文段有差错，这个报文段将被丢弃，等待超时重传。 (5) TCP 将数据按字节排序，报文段中有序号，以确保顺序的正确性。 (6) TCP 还能提供流量控制。TCP 连接的每一方都有收发缓存。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。 可见超时重发机制是 TCP 可靠性的关键，只要没有得到确认报文段，就重新发送数据报，直到收到对方的确认为止。 超时重传TCP 规定，接收者收到数据报文段后，需回复一个确认报文段，以告知发送者数据已经收到。而发送者如果一段时间内(超时计时器)没有收到确认报文段，便重复发送： 为了实现超时间重传，需要注意： 1.发送者发送一个报文段后，暂时保存该报文段的副本，为发生超时重传时使用，收到确认报文后删除该报文段。 2.确认报文段也需要序号，才能明确是发出去的那个数据报得到了确认。 3.超时计时器比传输往返时间略长，但具体值是不确定的，根据网络情况而变。 连续 ARQ 协议也许你也发现了，按上面的介绍，超时重传机制很费时间，每发送一个数据报都要等待确认。 在实际应用中的确不是这样的，真实情况是，采用了流水线传输：发送方可以连续发送多个报文段(连续发送的数据长度叫做窗口)，而不必每发完一段就停下来等待确认。 实际应用中，接收方也不必对收到的每个报文都做回复，而是采用累积确认方式：接收者收到多个连续的报文段后，只回复确认最后一个报文段，表示在这之前的数据都已收到。 这样，传输效率得到了很大的提升。 流量控制和拥塞控制由于接收方缓存的限制，发送窗口不能大于接收方接收窗口。在报文段首部有一个字段就叫做窗口(rwnd)，这便是用于告诉对方自己的接收窗口，可见窗口的大小是可以变化的。 那么窗口的大小是如何变化的呢？TCP 对于拥塞的控制总结为“慢启动、加性增、乘性减”，如图所示： 慢启动 ：初始的窗口值很小，但是按指数规律渐渐增长，直到达到慢开始门限(ssthresh)。 加性增 ：窗口值达到慢开始门限后，每发送一个报文段，窗口值增加一个单位量。 乘性减 ：无论什么阶段，只要出现超时，则把窗口值减小一半。 tcpdump 抓取 TCP 报文段现在我们尝试用 tcpdump 抓取TCP报文，首先还是要安装并运行 tcpdump： Ubuntu下： $ sudo apt-get update $ sudo apt-get install tcpdump $ sudo tcpdump -vvv -X -i lo tcp port 7777 CentOS/RedHat下： # yum install tcpdump # tcpdump -vvv -X -i lo tcp port 7777 然后编写一个基于 TCP 的聊天小程序，分为 server(服务端)和 client(客户端)： Server端程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#define BUFLEN 10int main(int argc, char *argv[])&#123; int sockfd, newfd; struct sockaddr_in s_addr, c_addr; char buf[BUFLEN]; socklen_t len; unsigned int port, listnum; /*建立socket*/ if((sockfd = socket(AF_INET, SOCK_STREAM, 0)) == -1)&#123; perror("socket"); exit(errno); &#125; /*设置服务器端口*/ if(argv[2]) port = atoi(argv[2]); else port = 7777; /*设置侦听队列长度*/ if(argv[3]) listnum = atoi(argv[3]); else listnum = 3; /*设置服务器ip*/ bzero(&amp;s_addr, sizeof(s_addr)); s_addr.sin_family = AF_INET; s_addr.sin_port = htons(port); if(argv[1]) s_addr.sin_addr.s_addr = inet_addr(argv[1]); else s_addr.sin_addr.s_addr = INADDR_ANY; /*把地址和端口帮定到套接字上*/ if((bind(sockfd, (struct sockaddr*) &amp;s_addr,sizeof(struct sockaddr))) == -1)&#123; perror("bind"); exit(errno); &#125; /*侦听本地端口*/ if(listen(sockfd,listnum) == -1)&#123; perror("listen"); exit(errno); &#125; while(1)&#123; printf("*****************server start***************\n"); len = sizeof(struct sockaddr); if((newfd = accept(sockfd,(struct sockaddr*) &amp;c_addr, &amp;len)) == -1)&#123; perror("accept"); exit(errno); &#125; while(1)&#123; _retry: /******发送消息*******/ bzero(buf,BUFLEN); printf("enter your words:"); /*fgets函数：从流中读取BUFLEN-1个字符*/ fgets(buf,BUFLEN,stdin); /*打印发送的消息*/ //fputs(buf,stdout); if(!strncasecmp(buf,"quit",4))&#123; printf("server stop\n"); break; &#125; /*如果输入的字符串只有"\n"，即回车，那么请重新输入*/ if(!strncmp(buf,"\n",1))&#123; goto _retry; &#125; /*如果buf中含有'\n'，那么要用strlen(buf)-1，去掉'\n'*/ if(strchr(buf,'\n')) len = send(newfd,buf,strlen(buf)-1,0); /*如果buf中没有'\n'，则用buf的真正长度strlen(buf)*/ else len = send(newfd,buf,strlen(buf),0); if(len &gt; 0) printf("send successful\n"); else&#123; printf("send failed\n"); break; &#125; /******接收消息*******/ bzero(buf,BUFLEN); len = recv(newfd,buf,BUFLEN,0); if(len &gt; 0) printf("receive massage:%s\n",buf); else&#123; if(len &lt; 0 ) printf("receive failed\n"); else printf("client stop\n"); break; &#125; &#125; /*关闭聊天的套接字*/ close(newfd); /*是否退出服务器*/ printf("exit?：y-&gt;yes；n-&gt;no "); bzero(buf, BUFLEN); fgets(buf,BUFLEN, stdin); if(!strncasecmp(buf,"y",1))&#123; printf("server stop\n"); break; &#125; &#125; /*关闭服务器的套接字*/ close(sockfd); return 0;&#125; Client端程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#define BUFLEN 10int main(int argc, char *argv[])&#123; int sockfd; struct sockaddr_in s_addr; socklen_t len; unsigned int port; char buf[BUFLEN]; /*建立socket*/ if((sockfd = socket(AF_INET, SOCK_STREAM, 0)) == -1)&#123; perror("socket"); exit(errno); &#125; /*设置服务器端口*/ if(argv[2]) port = atoi(argv[2]); else port = 7777; /*设置服务器ip*/ bzero(&amp;s_addr, sizeof(s_addr)); s_addr.sin_family = AF_INET; s_addr.sin_port = htons(port); if (inet_aton(argv[1], (struct in_addr *)&amp;s_addr.sin_addr.s_addr) == 0) &#123; perror(argv[1]); exit(errno); &#125; /*开始连接服务器*/ if(connect(sockfd,(struct sockaddr*)&amp;s_addr,sizeof(struct sockaddr)) == -1)&#123; perror("connect"); exit(errno); &#125;else printf("*****************client start***************\n"); while(1)&#123; /******接收消息*******/ bzero(buf,BUFLEN); len = recv(sockfd,buf,BUFLEN,0); if(len &gt; 0) printf("receive massage:%s\n",buf); else&#123; if(len &lt; 0 ) printf("receive failed\n"); else printf("server stop\n"); break; &#125; _retry: /******发送消息*******/ bzero(buf,BUFLEN); printf("enter your words:"); /*fgets函数：从流中读取BUFLEN-1个字符*/ fgets(buf,BUFLEN,stdin); /*打印发送的消息*/ //fputs(buf,stdout); if(!strncasecmp(buf,"quit",4))&#123; printf("client stop\n"); break; &#125; /*如果输入的字符串只有"\n"，即回车，那么请重新输入*/ if(!strncmp(buf,"\n",1))&#123; goto _retry; &#125; /*如果buf中含有'\n'，那么要用strlen(buf)-1，去掉'\n'*/ if(strchr(buf,'\n')) len = send(sockfd,buf,strlen(buf)-1,0); /*如果buf中没有'\n'，则用buf的真正长度strlen(buf)*/ else len = send(sockfd,buf,strlen(buf),0); if(len &gt; 0) printf("send successful\n"); else&#123; printf("send failed\n"); break; &#125; &#125; /*关闭连接*/ close(sockfd); return 0;&#125; 最后分别编译并运行Server端和Client端程序： # gcc -o Server Server.c # ./Server 127.0.0.1 # gcc -o Client Client.c # ./Client 127.0.0.1 应用层协议 在传输层之上，便是应用层。传输层的 UDP 报文和 TCP 报文段的数据部分就是应用层交付的数据。 不同类型的网络应用有不同的通信规则，因此应用层协议是多种多样的，比如 DNS、FTP、Telnet、SMTP、HTTP、RIP、NFS 等协议都是用于解决其各自的一类问题。 DNSDNS (Domain Name Service 域名服务) 协议基于 UDP，使用端口号 53。 由数字组成的 IP 地址很难记忆，所以我们上网使用网站 IP 地址的别名——域名。实际使用中，域名与 IP 地址是对应的，这种对应关系保存在 DNS服务器 之中。 在浏览器中输入一个域名后，会有 DNS 服务器将域名解析为对应的 IP 地址。注意这和网络层的 ARP 协议的不同之处：DNS 提供的是域名与 IP 地址的对应关系，而 ARP 提供的是 IP 地址和 MAC 地址的对应关系。 DNS 服务器DNS 服务器是个分层次的系统： 根 DNS 服务器 ：全世界共有 13 台根域名服务器，编号 A 到 M，其中大部分位于美国 顶级(TLD)DNS 服务器 ：负责如 com 、org 、edu 等顶级域名和所有国家的顶级域名(如 cn 、uk 、jp ) 权威 DNS 服务器 ：大型组织、大学、企业的域名解析服务 本地 DNS 服务器 ：通常与我们主机最近的 DNS 服务器 而域名解析的过程，有迭代查询和递归查询两种方式： host命令在 linux 系统中，可以用 host 命令 进行 DNS 查询，查看一个指定域名的 IP，比如要查询 百度 的IP地址： host www.baidu.com DNS报文主机向 DNS 服务器发出的查询叫做DNS报文，大致结构： DNS 问答报文的内容，都是 IP 和域名的对应信息，关于 DNS 首部和内容 各字段这里不做详细介绍。深入了解，可以先 host 一个域名，再使用 tcpdump 抓取报文并解读。 DNS 缓存和 hosts 文件刚才 DNS 解析查询过程的图中，共发出了 8 份 DNS 报文，这是非常消耗时间的，所以实际应用上使用 DNS 缓存 ：当一个 DNS 服务器接收到一个 DNS 回答后，会将其信息缓存一段时间，当再有一个对相同域名的查询时，便可直接回复。 通过 DNS 缓存，其实很多查询都只需要本地 DNS 服务器便可完成。 有“翻墙”爱好的同学应该知道 hosts 文件，其实 hosts 文件可以看作是一个小型的 DNS 服务器。 使用命令打开 hosts 文件： # vim /etc/hosts 查看文件内容，可以发现里面全是类似下图中的 IP 和域名对应记录： 在实际上网过程中，域名解析的的优先顺序是：先在 DNS 缓存查询，若没有找到记录，再查询 hosts 文件，若还是没找到记录，再向 DNS 服务器发出 DNS 查询报文。 FTPFTP (File Transfer Protocol 文件传输协议) 基于 TCP，使用端口号 20(数据)和 21(控制)。 它的主要功能是减少或消除在不同操作系统下处理文件的不兼容性，以达到便捷高效的文件传输效果。 FTP 只提供文件传输的基本服务，它采用 客户端—服务器 的方式，一个 FTP 服务器可同时为多个客户端提供服务 在进行文件传输时，FTP 的客户端和服务器之间会建立两个 TCP 连接：21 号端口建立控制连接，20 号端口建立数据连接 FTP 的传输有两种方式：ASCII 传输模式和二进制数据传输模式 HTTPHTTP (HyperText Transfer Protocol 超文本传输协议) 基于 TCP，使用端口号 80 或 8080。 每当你在浏览器里输入一个网址或点击一个链接时，浏览器就通过 HTTP 协议将网页信息从服务器提取再显示出来，这是现在使用频率最大的应用层协议。 这个原理很简单： 点击一个链接后，浏览器向服务器发起 TCP 连接 连接建立后浏览器发送 HTTP 请求报文，然后服务器回复响应报文 浏览器将收到的响应报文内容显示在网页上 报文收发结束，关闭 TCP 连接 HTTP 报文会被传输层封装为 TCP 报文段，然后再被 IP 层封装为 IP 数据报。HTTP 报文的结构： 可见报文分为 3 部分： 开始行：用于区分是请求报文还是响应报文，请求报文中开始行叫做请求行，而响应报文中，开始行叫做状态行*。在开始行的三个字段之间都用空格分开，结尾处 CRLF 表示回车和换行。 首部行：用于说明浏览器、服务器或报文主体的一些信息。 实体主体：请求报文中通常不用实体主体。 请求报文的方法字段是对所请求对象进行的操作，而响应报文的状态码是一个 3 位数字，分为 5 类 33 种： 1xx 表示通知信息，如收到或正在处理 2xx 表示成功接收 3xx 表示重定向 4xx 表示客户的差错，如 404 表示网页未找到 5xx表示服务器的差错，如常见的 502 Bad Gateway EOF 本文作者：Koen 参考链接：https://www.shiyanlou.com/courses/98]]></content>
      <categories>
        <category>网络营地</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git简明教程]]></title>
    <url>%2Fck74yvgoi0018dhkc8ex5pmnu.html</url>
    <content type="text"><![CDATA[前言 本文主要是参考廖雪峰博客上的Git教程所写，有适当的删改，但是实验部分都是自己在虚拟机中实验过的。 Git简介 Git是目前世界上最先进的分布式版本控制系统 什么是版本控制系统如果你用Microsoft Word写过长篇大论，那你一定有这样的经历： 想删除一个段落，又怕将来想恢复找不回来怎么办？有办法，先把当前文件“另存为……”一个新的Word文件，再接着改，改到一定程度，再“另存为……”一个新文件，这样一直改下去，最后你的Word文档变成了这样： 过了一周，你想找回被删除的文字，但是已经记不清删除前保存在哪个文件里了，只好一个一个文件去找，真麻烦。 看着一堆乱七八糟的文件，想保留最新的一个，然后把其他的删掉，又怕哪天会用上，还不敢删，真郁闷。 更要命的是，有些部分需要你的财务同事帮助填写，于是你把文件Copy到U盘里给她（也可能通过Email发送一份给她），然后，你继续修改Word文件。一天后，同事再把Word文件传给你，此时，你必须想想，发给她之后到你收到她的文件期间，你作了哪些改动，得把你的改动和她的部分合并，真困难。 于是你想，如果有一个软件，不但能自动帮我记录每次文件的改动，还可以让同事协作编辑，这样就不用自己管理一堆类似的文件了，也不需要把文件传来传去。如果想查看某次改动，只需要在软件里瞄一眼就可以，岂不是很方便？ 这个软件用起来就应该像这个样子，能记录每次文件的改动： 版本 用户 说明 日期1 张三 删除了软件服务条款5 7/12 10:382 张三 增加了License人数限制 7/12 18:093 李四 财务部门调整了合同金额 7/13 9:514 张三 延长了免费升级周期 7/14 15:17这样，你就结束了手动管理多个“版本”的史前时代，进入到版本控制的20世纪。 Git的诞生很多人都知道，Linus在1991年创建了开源的Linux，从此，Linux系统不断发展，已经成为最大的服务器系统软件了。 Linus虽然创建了Linux，但Linux的壮大是靠全世界热心的志愿者参与的，这么多人在世界各地为Linux编写代码，那Linux的代码是如何管理的呢？ 事实是，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码！ 你也许会想，为什么Linus不把Linux代码放到版本控制系统里呢？不是有CVS、SVN这些免费的版本控制系统吗？因为Linus坚定地反对CVS和SVN，这些集中式的版本控制系统不但速度慢，而且必须联网才能使用。有一些商用的版本控制系统，虽然比CVS、SVN好用，但那是付费的，和Linux的开源精神不符。 不过，到了2002年，Linux系统已经发展了十年了，代码库之大让Linus很难继续通过手工方式管理了，社区的弟兄们也对这种方式表达了强烈不满，于是Linus选择了一个商业的版本控制系统BitKeeper，BitKeeper的东家BitMover公司出于人道主义精神，授权Linux社区免费使用这个版本控制系统。 安定团结的大好局面在2005年就被打破了，原因是Linux社区牛人聚集，不免沾染了一些梁山好汉的江湖习气。开发Samba的Andrew试图破解BitKeeper的协议（这么干的其实也不只他一个），被BitMover公司发现了（监控工作做得不错！），于是BitMover公司怒了，要收回Linux社区的免费使用权。 Linus可以向BitMover公司道个歉，保证以后严格管教弟兄们，嗯，这是不可能的。实际情况是这样的： Linus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！一个月之内，Linux系统的源码已经由Git管理了！牛是怎么定义的呢？大家可以体会一下。 Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，包括jQuery，PHP，Ruby等等。 历史就是这么偶然，如果不是当年BitMover公司威胁Linux社区，可能现在我们就没有免费而超级好用的Git了。 集中式vs分布式Linus一直痛恨的CVS及SVN都是集中式的版本控制系统，而Git是分布式版本控制系统，集中式和分布式版本控制系统有什么区别呢？ 先说集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。 集中式版本控制系统最大的毛病就是必须联网才能工作，如果在局域网内还好，带宽够大，速度够快，可如果在互联网上，遇到网速慢的话，可能提交一个10M的文件就需要5分钟，这还不得把人给憋死啊。 那分布式版本控制系统与集中式版本控制系统有何不同呢？首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 在实际使用分布式版本控制系统的时候，其实很少在两人之间的电脑上推送版本库的修改，因为可能你们俩不在一个局域网内，两台电脑互相访问不了，也可能今天你的同事病了，他的电脑压根没有开机。因此，分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 当然，Git的优势不单是不必联网这么简单，后面我们还会看到Git极其强大的分支管理，把SVN等远远抛在了后面。 CVS作为最早的开源而且免费的集中式版本控制系统，直到现在还有不少人在用。由于CVS自身设计的问题，会造成提交文件不完整，版本库莫名其妙损坏的情况。同样是开源而且免费的SVN修正了CVS的一些稳定性问题，是目前用得最多的集中式版本库控制系统。 除了免费的外，还有收费的集中式版本控制系统，比如IBM的ClearCase（以前是Rational公司的，被IBM收购了），特点是安装比Windows还大，运行比蜗牛还慢，能用ClearCase的一般是世界500强，他们有个共同的特点是财大气粗，或者人傻钱多。 微软自己也有一个集中式版本控制系统叫VSS，集成在Visual Studio中。由于其反人类的设计，连微软自己都不好意思用了。 分布式版本控制系统除了Git以及促使Git诞生的BitKeeper外，还有类似Git的Mercurial和Bazaar等。这些分布式版本控制系统各有特点，但最快、最简单也最流行的依然是Git！ 安装Git 在Linux上安装GitDebian/Ubuntu$ sudo apt-get install git Fedora/RedHat/CentOS$ yum install git 更多Linux版本安装方法可以参考Git官方安装指南 在Windows上安装Git下载Git for Windows 进入上面的链接，然后点击 “Windows” 即可自动下载符合你Windows平台的Git安装包 运行Git安装包 点击“ Next ” 点击” Next “ 选择 Git 的安装路径，然后点击” Next “ 勾选要安装的组件，然后点击” Next “ 配置开始菜单文件夹名称，如果不创建就勾选左下角的” Don’t create a Start Menu folder”，然后点击” Next “ 选择是否将Git加入到系统环境变量Path中，建议选择“ Use Git from the Windows Command Prompt”，也可根据自己的喜好选择，然后点击” Next “ 点击” Next “ 开始安装，等待安装完毕 安装成功！你可以开始你的Git之旅了&gt;_&lt; 按win+R打开运行窗口，运行 cmd 打开命令提示符窗口，然后输入&gt; git并回车，你是不是看到了如下结果？是就说明你成功了，否则请检查系统上的Path系统环境变量是否有误。 也可直接运行桌面上的“Git Bash” 在Mac OS X上安装Git由于作者是个穷屌丝，买不起Mac，关于Git在Mac上的安装方法无法给出相应的教程，如果有需要的可以到廖雪峰博客上查看啊T_T 创建版本库 版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。 所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录： # mkdir learngit # cd learngit/ 然后通过git init命令把这个目录变成Git可以管理的仓库： # git init Initialized empty Git repository in /root/learngit/.git/ 瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。 如果你没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -a命令就可以看见。 也不一定必须在空目录下创建Git仓库，选择一个已经有东西的目录也是可以的。不过，不建议你使用自己正在开发的公司项目来学习Git，否则造成的一切后果概不负责。 把文件添加到版本库首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。 因为文本是有编码的，比如中文有常用的GBK编码，日文有Shift_JIS编码，如果没有历史遗留问题，强烈建议使用标准的UTF-8编码，所有语言使用同一种编码，既没有冲突，又被所有平台所支持。 编写一个readme.txt文件，内容如下： Git is a version control system. Git is free software. 注：一定要放到learngit目录下（子目录也行），因为这是一个Git仓库，放到其他地方Git再厉害也找不到这个文件。 第一步，用命令git add告诉Git，把文件添加到仓库： # git add readme.txt 第二步，用命令git commit告诉Git，把文件提交到仓库： # git commit -m &quot;wrote a readme file&quot; [master (root-commit) 6dd2141] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt 简单解释一下git commit命令，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。 嫌麻烦不想输入-m &quot;xxx&quot;行不行？确实有办法可以这么干，但是强烈不建议你这么干，因为输入说明对自己对别人阅读都很重要。 git commit命令执行成功后会告诉你，1个文件被改动（我们新添加的readme.txt文件），插入了两行内容（readme.txt有两行内容）。 commit可以一次提交很多文件，所以你可以多次add不同的文件，比如： # git add file1.txt # git add file2.txt file3.txt # git commit -m &quot;add 3 files&quot; 时光机穿梭 修改并提交文件我们已经成功地添加并提交了一个readme.txt文件，现在，是时候继续工作了，于是，我们继续修改readme.txt,改成如下内容： Git is a distributed version control system. Git is free software. 然后运行git status命令时刻掌握仓库当前的状态 # git status # On branch master # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 上面的命令告诉我们，readme.txt被修改过了，但还没有准备提交的修改，而且命令也没有告诉我们具体修改了什么内容，因此如果你需要查看具体修改的内容是什么，你可以使用git diff命令查看： # git diff readme.txt diff --git a/readme.txt b/readme.txt index 46d49bf..9247db6 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -Git is a version control system. +Git is a distributed version control system. Git is free software. git diff顾名思义就是查看difference，显示的格式正是Unix通用的diff格式，可以从上面的命令输出看到，我们在第一行添加了一个“distributed”单词。 知道了对readme.txt作了什么修改后，再把它提交到仓库就放心多了，提交修改和提交新文件是一样的两步，第一步是git add： # git add readme.txt 在执行git commit之前先查看下当前仓库的状态： # git status # On branch master # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # modified: readme.txt # git status告诉我们，将要被提交的修改包括readme.txt，下一步，就可以放心地提交了： # git commit -m &quot;add distributed&quot; [master 8e400b9] add distributed 1 file changed, 1 insertion(+), 1 deletion(-) 提交之后再查看仓库的当前状态： # git status # On branch master nothing to commit, working directory clean Git告诉我们当前没有需要提交的修改，而且，工作目录是干净的（working directory clean）。 版本回退git log 命令显示从最近到最远的提交日志，我们可以看到我们之前所有的提交 # git log commit fd0731deda3c47d8765e2518a8c4fc4f3cface79 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:47:00 2015 +0800 append GPL commit 590ed9b0198da49ae494921cf790d91781ffc910 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:46:00 2015 +0800 add distributed commit 6dd2141838357913f302af97cecba7177bfa58a9 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:02:17 2015 +0800 wrote a readme file 如果嫌输出信息太多，看得眼花缭乱，可以试试加上--pretty=oneline参数: # git log --pretty=oneline fd0731deda3c47d8765e2518a8c4fc4f3cface79 append GPL 590ed9b0198da49ae494921cf790d91781ffc910 add distributed 6dd2141838357913f302af97cecba7177bfa58a9 wrote a readme file 你看到的一大串类似fd0731de...cface79的是commit id（版本号），和SVN不一样，Git的commit id不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示，而且你看到的commit id和我的肯定不一样，以你自己的为准。为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。 现在如果我们需要把当前版本回退到上一个版本”add distributed”，该怎么做呢？ 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，也就是最新的提交fd0731de…cface79（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 然后使用git reset命令: # git reset --hard HEAD^ HEAD is now at 590ed9b add distributed 这个时候你再去查看readme.txt的内容看是否是”add distributed”版本的内容 # cat readme.txt Git is a distributed version control system. Git is free software. 但是这个时候如果你用git log命令再查看现在的版本库状态： # git log commit 590ed9b0198da49ae494921cf790d91781ffc910 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:46:00 2015 +0800 add distributed commit 6dd2141838357913f302af97cecba7177bfa58a9 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:02:17 2015 +0800 wrote a readme file 发现刚才最新的那个版本”append GPL”已经看不到了，好比你从21世纪坐时光穿梭机来到了19世纪，想再回去已经回不去了，肿么办？ 办法其实还是有的，只要上面的命令行窗口还没有被关掉，你就可以顺着往上找啊找啊，找到那个append GPL的commit id是fd0731de...cface79，于是就可以指定回到未来的某个版本： # git reset --hard fd0731d HEAD is now at fd0731d append GPL 注：版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了 再小心翼翼地看看readme.txt的内容： # cat readme.txt Git is a distributed version control system. Git is free software distributed under the GPL. 发现又回到了”append GPL”版本的内容 Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL: 改为指向add distributed： 然后顺便把工作区的文件更新了。所以你让HEAD指向哪个版本号，你就把当前版本定位在哪。 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？ 在Git中，总是有后悔药可以吃的。当你用$ git reset –hard HEAD^回退到add distributed版本时，再想恢复到append GPL，就必须找到append GPL的commit id。Git提供了一个命令git reflog用来记录你的每一次命令： # git reflog fd0731d HEAD@{0}: reset: moving to fd0731d 590ed9b HEAD@{1}: reset: moving to HEAD^ fd0731d HEAD@{2}: commit: append GPL 590ed9b HEAD@{3}: commit: add distributed 终于舒了口气，第三行显示append GPL的commit id是fd0731d，现在，你又可以乘坐时光机回到未来了。 工作区和暂存区工作区(Workinig Directory)就是你在电脑里能看到的目录，比如之前建立的learngit文件夹就是一个工作区 版本库(Repository)工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD. 前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 俗话说，实践出真知。现在，我们再练习一遍，先对readme.txt做个修改，比如加上一行内容： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. 然后，在工作区新增一个LICENSE文本文件（内容随便写）。 先用git status查看一下状态： # git status # On branch master # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # # Untracked files: # (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) # # LICENSE no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) Git非常清楚地告诉我们，readme.txt被修改了，而LICENSE还从来没有被添加过，所以它的状态是Untracked。 现在，使用两次命令git add，把readme.txt和LICENSE都添加后，用git status再查看一下: # git add readme.txt # git add LICENSE # git status # On branch master # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # new file: LICENSE # modified: readme.txt # 现在，暂存区的状态就变成这样了： 所以git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后执行git commit就可以一次性把暂存区的所有修改提交到分支 # git commit -m &quot;understand how stage works&quot; [master 428c18c] understand how stage works 2 files changed, 2 insertions(+) create mode 100644 LICENSE 一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的： # git status # On branch master nothing to commit, working directory clean 现在版本库变成了这样，暂存区就没有任何内容了： 管理修改现在，假定你已经完全掌握了暂存区的概念。下面，我们要讨论的就是，为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。 你会问，什么是修改？比如你新增了一行，这就是一个修改，删除了一行，也是一个修改，更改了某些字符，也是一个修改，删了一些又加了一些，也是一个修改，甚至创建一个新文件，也算一个修改。 为什么说Git管理的是修改，而不是文件呢？我们还是做实验。第一步，对readme.txt做一个修改，比如加一行内容： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes. 然后，添加： # git add readme.txt # git status # On branch master # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # modified: readme.txt # 然后再修改readme.txt： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. 提交： # git commit -m &quot;git tracks changes&quot; [master eea201d] git tracks changes 1 file changed, 1 insertion(+) 提交后，再看看状态： # git status # On branch master # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 咦，怎么第二次的修改没有被提交？ 别激动，我们回顾一下操作过程： 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; `git commit 你看，我们前面讲了，Git管理的是修改，当你用git add命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，git commit只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。 提交后，用git diff HEAD -- readme.txt命令可以查看工作区和版本库里面最新版本的区别： # git diff HEAD -- readme.txt diff --git a/readme.txt b/readme.txt index 76d770f..a9c5755 100644 --- a/readme.txt +++ b/readme.txt @@ -1,4 +1,4 @@ Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. -Git tracks changes. +Git tracks changes of files. 可见，第二次修改确实没有被提交。 那怎么提交第二次修改呢？你可以继续git add再git commit，也可以别着急提交第一次修改，先git add第二次修改，再git commit，就相当于把两次修改合并后一块提交了： 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit 撤销修改自然，你是不会犯错的。不过现在是凌晨两点，你正在赶一份工作报告，你在readme.txt中添加了一行： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. My stupid boss still prefers SVN. 在你准备提交前，一杯咖啡起了作用，你猛然发现了“stupid boss”可能会让你丢掉这个月的奖金！ 既然错误发现得很及时，就可以很容易地纠正它。你可以删掉最后一行，手动把文件恢复到上一个版本的状态。如果用git status查看一下： # git status # On branch master # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 你可以发现，Git会告诉你，git checkout -- file可以丢弃工作区的修改： # git checkout -- readme.txt 命令git checkout -- readme.txt意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 现在，看看readme.txt的文件内容： # cat readme.txt Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. 文件内容果然复原了。 git checkout -- file命令中的--很重要，没有--，就变成了“切换到另一个分支”的命令，我们在后面的分支管理中会再次遇到git checkout命令。 现在假定是凌晨3点，你不但写了一些胡话，还git add到暂存区了： # cat readme.txt Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. My stupid boss still prefers SVN. # git add readme.txt 庆幸的是，在commit之前，你发现了这个问题。用git status查看一下，修改只是添加到了暂存区，还没有提交： # git status # On branch master # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # modified: readme.txt # Git同样告诉我们，用命令git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区： # git reset HEAD readme.txt Unstaged changes after reset: M readme.txt git reset命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。 再用git status查看一下，现在暂存区是干净的，工作区有修改： # git status # On branch master # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 还记得如何丢弃工作区的修改吗？ # git checkout -- readme.txt # git status # On branch master nothing to commit, working directory clean 整个世界终于清静了！ 现在，假设你不但改错了东西，还从暂存区提交到了版本库，怎么办呢？还记得版本回退一节吗？可以回退到上一个版本。不过，这是有条件的，就是你还没有把自己的本地版本库推送到远程。还记得Git是分布式版本控制系统吗？我们后面会讲到远程版本库，一旦你把“stupid boss”提交推送到远程版本库，你就真的惨了…… 删除文件在Git中，删除也是一个修改操作，我们实战一下，先添加一个新文件test.txt到Git并且提交： # touch test.txt # git add test.txt # git commit -m &quot;add test.txt&quot; [master d4dc998] add test.txt 1 file changed, 1 insertion(+) create mode 100644 test.txt 一般情况下，你通常直接在文件管理器中把没用的文件删了，或者用rm命令删了： # rm test.txt 这个时候，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了： # git status # On branch master # Changes not staged for commit: # (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # deleted: test.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit： # git rm test.txt rm &apos;test.txt&apos; # git commit -m &quot;remove test.txt&quot; [master df90ed9] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt 现在，文件就从版本库中被删除了。 另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本： # git checkout -- test.txt git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 分支管理 分支就是科幻电影里面的平行宇宙，当你正在电脑前努力学习Git的时候，另一个你正在另一个平行宇宙里努力学习SVN。 如果两个平行宇宙互不干扰，那对现在的你也没啥影响。不过，在某个时间点，两个平行宇宙合并了，结果，你既学会了Git又学会了SVN！ 分支在实际中有什么用呢？假设你准备开发一个新功能，但是需要两周才能完成，第一周你写了50%的代码，如果立刻提交，由于代码还没写完，不完整的代码库会导致别人不能干活了。如果等代码全部写完再一次提交，又存在丢失每天进度的巨大风险。 现在有了分支，就不用怕了。你创建了一个属于你自己的分支，别人看不到，还继续在原来的分支上正常工作，而你在自己的分支上干活，想提交就提交，直到开发完毕后，再一次性合并到原来的分支上，这样，既安全，又不影响别人工作。 其他版本控制系统如SVN等都有分支管理，但是用过之后你会发现，这些版本控制系统创建和切换分支比蜗牛还慢，简直让人无法忍受，结果分支功能成了摆设，大家都不去用。 但Git的分支是与众不同的，无论创建、切换和删除分支，Git在1秒钟之内就能完成！无论你的版本库是1个文件还是1万个文件。 创建与合并分支在版本回退里，你已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长： 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： 你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！ 不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 所以Git合并分支也很快！就改改指针，工作区内容也不变！ 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 真是太神奇了，你看得出来有些提交是通过分支完成的吗？ 下面开始来实战： 首先，我们创建dev分支，然后切换到dev分支： # git checkout -b dev Switched to a new branch &apos;dev&apos; git checkout命令加上-b参数表示创建并切换，相当于以下两条命令： # git branch dev # git checkout dev Switched to branch &apos;dev&apos; 然后，用git branch命令查看当前分支： # git branch * dev master git branch命令会列出所有分支，当前分支前面会标一个*号。 然后，我们就可以在dev分支上正常提交，比如对readme.txt做个修改，加上一行： # cat readme.txt Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. Creating a new branch is quick. 然后提交： # git add readme.txt # git commit -m &quot;branch test&quot; [dev 149c454] branch test 1 file changed, 1 insertion(+) 现在，dev分支的工作完成，我们就可以切换回master分支： # git checkout master Switched to branch &apos;master&apos; 切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变： 现在，我们把dev分支的工作成果合并到master分支上： # git merge dev Updating 992b634..149c454 Fast-forward readme.txt | 1 + 1 file changed, 1 insertion(+) git merge命令用于合并指定分支到当前分支。合并后，再查看readme.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。 注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。 当然，也不是每次合并都能Fast-forward，我们后面会将其他方式的合并。 合并完成后，就可以放心地删除dev分支了： # git branch -d dev Deleted branch dev (was 149c454). 删除后，查看branch，就只剩下master分支了： # git branch * master 因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。 解决冲突人生不如意之事十之八九，合并分支往往也不是一帆风顺的。 准备新的feature1分支，继续我们的新分支开发： # git checkout -b feature1 Switched to a new branch &apos;feature1&apos; 修改readme.txt最后一行，改为： Creating a new branch is quick AND simple. 在feature1分支上提交： # git add readme.txt # git commit -m &quot;AND simple&quot; [feature1 fdae4fc] AND simple 1 file changed, 1 insertion(+), 1 deletion(-) 切换到master分支： # git checkout master Switched to branch &apos;master&apos; 在master分支上把readme.txt文件的最后一行改为： Creating a new branch is quick &amp; simple. 提交： # git add readme.txt # git commit -m &quot;&amp; simple&quot; [master c27f46d] &amp; simple 1 file changed, 1 insertion(+), 1 deletion(-) 现在，master分支和feature1分支各自都分别有新的提交，变成了这样： 这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突，我们试试看： # git merge feature1 Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. 果然冲突了！Git告诉我们，readme.txt文件存在冲突，必须手动解决冲突后再提交。git status也可以告诉我们冲突的文件： # git status # On branch master # You have unmerged paths. # (fix conflicts and run &quot;git commit&quot;) # # Unmerged paths: # (use &quot;git add &lt;file&gt;...&quot; to mark resolution) # # both modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 我们可以直接查看readme.txt的内容： Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Creating a new branch is quick &amp; simple. ======= Creating a new branch is quick AND simple. &gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们修改如下后保存： # cat readme.txt Git is a distributed version control system. Git is free software distributed under the GPL. Git has a mutable index called stage. Git tracks changes of files. Creating a new branch is quick and simple. 再提交： # git add readme.txt # git commit -m &quot;conflict fixed&quot; [master 7929784] conflict fixed 现在，master分支和feature1分支变成了下图所示： 用带参数的git log也可以看到分支的合并情况： # git log --graph --pretty=oneline --abbrev-commit * 7929784 conflict fixed |\ | * fdae4fc AND simple * | c27f46d &amp; simple |/ * 149c454 branch test ... 最后，删除feature1分支： # git branch -d feature1 Deleted branch feature1 (was fdae4fc). 工作完成。 分支管理策略通常，合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 下面我们实战一下--no-ff方式的git merge： 首先，仍然创建并切换dev分支： # git checkout -b dev Switched to a new branch &apos;dev&apos; 修改readme.txt文件，并提交一个新的commit： # vim readme.txt # git add readme.txt # git commit -m &quot;add merge&quot; [dev ba97f7f] add merge 1 file changed, 1 insertion(+) 现在，我们切换回master： # git checkout master Switched to branch &apos;master&apos; 准备合并dev分支，请注意--no-ff参数，表示禁用Fast forward： # git merge --no-ff -m &quot;merge with no-ff&quot; dev Merge made by the &apos;recursive&apos; strategy. readme.txt | 1 + 1 file changed, 1 insertion(+) 因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。 合并后，我们用git log看看分支历史： # git log --graph --pretty=oneline --abbrev-commit * 02e2f4d merge with no-ff |\ | * ba97f7f add merge |/ * 7929784 conflict fixed ... 可以看到，不使用Fast forward模式，merge后就像这样： 分支策略在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： Bug分支软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。 当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交： # git status # On branch dev # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？ 幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： # git stash Saved working directory and index state WIP on master: 02e2f4d merge with no-ff HEAD is now at 02e2f4d merge with no-ff 现在，用git status查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。 首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支： # git checkout master Switched to branch &apos;master&apos; # git checkout -b &apos;issue-101&apos; Switched to a new branch &apos;issue-101&apos; 现在修复bug，需要把“Git is free software …”改为“Git is a free software …”，然后提交： # vim readme.txt # git add readme.txt # git commit -m &quot;fix bug 101&quot; [issue-101 b04bd1a] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-) 修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： # git checkout master Switched to branch &apos;master&apos; # git merge --no-ff -m &quot;merged bug fix 101&quot; issue-101 Merge made by the &apos;recursive&apos; strategy. readme.txt | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) # git branch -d issue-101 Deleted branch issue-101 (was b04bd1a). 太棒了，原计划两个小时的bug修复只花了5分钟！现在，是时候接着回到dev分支干活了！ # git checkout dev Switched to branch &apos;dev&apos; # git status # On branch dev nothing to commit, working directory clean 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看： # git stash list stash@{0}: WIP on master: 02e2f4d merge with no-ff 工作现场还在，Git把stash内容存在某个地方了，但是需要恢复一下，有两个办法： 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了： # git stash pop # On branch dev # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: readme.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) Dropped refs/stash@{0} (80c40822d954a46e4236a6eed75527d24b21c62f) 再用git stash list查看，就看不到任何stash内容了： # git stash list 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令： git stash apply stash@{0} Feature分支软件开发中，总有无穷无尽的新的功能要不断添加进来。 添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 现在，你终于接到了一个新任务：开发代号为Vulcan的新功能，该功能计划用于下一代星际飞船。 于是准备开发： # git checkout -b feature-vulcan Switched to a new branch &apos;feature-vulcan&apos; 5分钟后，开发完毕： # vim vulcan.py # git add vulcan.py # git status # On branch feature-vulcan # Changes to be committed: # (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # # new file: vulcan.py # # git commit -m &quot;add feature vulcan&quot; [feature-vulcan 144c3a3] add feature vulcan 1 file changed, 1 insertion(+) create mode 100644 vulcan.py 切回dev，准备合并： # git checkout dev Switched to branch &apos;dev&apos; 一切顺利的话，feature分支和bug分支是类似的，合并，然后删除。 但是， 就在此时，接到上级命令，因经费不足，新功能必须取消！ 虽然白干了，但是这个分支还是必须就地销毁： # git branch -d feature-vulcan error: The branch &apos;feature-vulcan&apos; is not fully merged. If you are sure you want to delete it, run &apos;git branch -D feature-vulcan&apos;. 销毁失败。Git友情提醒，feature-vulcan分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用命令git branch -D feature-vulcan。 现在我们强行删除： # git branch -D feature-vulcan Deleted branch feature-vulcan (was 144c3a3). 终于删除成功！ 多人协作当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。 要查看远程库的信息，用git remote： # git remote origin 如果要显示更详细的信息: # git remote -v 推送分支推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上： # git push origin master 如果要推送其他分支，比如dev，就改成： # git push origin dev 如果推送失败，先用git pull抓取远程的新提交 但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？ master分支是主分支，因此要时刻与远程同步； dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步； bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug； feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。 总之，就是在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！ 抓取分支多人协作时，大家都会往master和dev分支上推送各自的修改。 现在模拟从远程库clone下来： # git clone git@github.com:xautlmx/learngit.git 当从远程库clone时，默认情况下，只能看到本地的master分支。可以用git branch命令看看： # git branch * master 现在，你要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支： # git checkout -b dev origin/dev 现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程： # git commit -m &quot;add /usr/bin/env&quot; # $ git push origin dev 你已经向origin/dev分支推送了你的提交，而碰巧你的小伙伴也对同样的文件作了修改，并试图推送： # git add hello.py # git commit -m &quot;add coding: utf-8&quot; # git push origin dev error: failed to push some refs to &apos;git@github.com:xautlmx/learngit.git&apos; 推送失败，因为你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送： 注：pull前先指定本地dev分支与远程origin/dev分支的链接 # git branch --set-upstream dev origin/dev # git pull 注：如果有冲突，要先处理冲突 标签管理 发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。 创建标签在Git中打标签非常简单，首先，切换到需要打标签的分支上： # git branch * dev master # git checkout master Switched to branch &apos;master&apos; 然后，敲命令git tag &lt;name&gt;就可以打一个新标签： # git tag v1.0 可以用命令git tag查看所有标签： # git tag v1.0 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？ 方法是找到历史提交的commit id，然后打上就可以了： # git log --pretty=oneline --abbrev-commit d4e5d0c merged bug fix 101 b04bd1a fix bug 101 02e2f4d merge with no-ff ba97f7f add merge 7929784 conflict fixed c27f46d &amp; simple fdae4fc AND simple ... 比方说要对add merge这次提交打标签，它对应的commit id是ba97f7f，敲入命令： # git tag v0.9 ba97f7f 再用命令git tag查看标签： # git tag v0.9 v1.0 注意，标签不是按时间顺序列出，而是按字母排序的。可以用git show &lt;tagname&gt;查看标签信息： # git show v0.9 commit ba97f7f6a271f95aa0885d4f3b87a0784e4abe24 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 21:10:17 2015 +0800 add merge ... 可以看到，v0.9确实打在add merge这次提交上。 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字： # git tag -a v0.1 -m &quot;version 0.1 released&quot; fd0731d 用命令git show &lt;tagname&gt;可以看到说明文字： # git show v0.1 tag v0.1 Tagger: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 21:57:35 2015 +0800 version 0.1 released commit fd0731deda3c47d8765e2518a8c4fc4f3cface79 Author: koen &lt;379148058@qq.com&gt; Date: Thu Jul 30 18:47:00 2015 +0800 append GPL ... 操作标签如果标签打错了，也可以删除： # git tag -d v0.1 Deleted tag &apos;v0.1&apos; (was ba61979) 因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。 如果要推送某个标签到远程，使用命令git push origin &lt;tagname&gt; 例如： # git push origin v1.0 或者，一次性推送全部尚未推送到远程的本地标签： # git push origin --tags 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除git tag -d &lt;tagname&gt; 例如： # git tag -d v0.9 然后，从远程删除。删除命令也是push，但是格式如下： git push origin :refs/tags/&lt;tagname&gt; 例如： # git push origin :refs/tags/v0.9 使用Github 我们一直用GitHub作为免费的远程仓库，如果是个人的开源项目，放到GitHub上是完全没有问题的。其实GitHub还是一个开源协作社区，通过GitHub，既可以让别人参与你的开源项目，也可以参与别人的开源项目。 在GitHub出现以前，开源项目开源容易，但让广大人民群众参与进来比较困难，因为要参与，就要提交代码，而给每个想提交代码的群众都开一个账号那是不现实的，因此，群众也仅限于报个bug，即使能改掉bug，也只能把diff文件用邮件发过去，很不方便。 但是在GitHub上，利用Git极其强大的克隆和分支功能，广大人民群众真正可以第一次自由参与各种开源项目了。 如何参与一个开源项目呢？比如人气极高的bootstrap项目，这是一个非常强大的CSS框架，你可以访问它的项目主页https://github.com/twbs/bootstrap，点“Fork”就在自己的账号下克隆了一个bootstrap仓库，然后，从自己的账号下clone： git clone git@github.com:michaelliao/bootstrap.git 一定要从自己的账号下clone仓库，这样你才能推送修改。如果从bootstrap的作者的仓库地址`git@github.com:twbs/bootstrap.git`克隆，因为没有权限，你将不能推送修改。 Bootstrap的官方仓库twbs/bootstrap、你在GitHub上克隆的仓库my/bootstrap，以及你自己克隆到本地电脑的仓库，他们的关系就像下图显示的那样： 如果你想修复bootstrap的一个bug，或者新增一个功能，立刻就可以开始干活，干完后，往自己的仓库推送。 如果你希望bootstrap的官方库能接受你的修改，你就可以在GitHub上发起一个pull request。当然，对方是否接受你的pull request就不一定了。 自定义Git在安装Git一节中，我们已经配置了user.name和user.email，实际上，Git还有很多可配置项。 比如，让Git显示颜色，会让命令输出看起来更醒目： # git config --global color.ui true 这样，Git会适当地显示不同的颜色，比如git status命令： 文件名就会标上颜色。 我们在后面还会介绍如何更好地配置Git，以便让你的工作更高效。 忽略特殊文件有些时候，你必须把某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件啦，等等，每次git status都会显示Untracked files ...，有强迫症的童鞋心里肯定不爽。 好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore 忽略文件的原则是： 忽略操作系统自动生成的文件，比如缩略图等；忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 举个例子： 假设你在Windows下进行Python开发，Windows会自动在有图片的目录下生成隐藏的缩略图文件，如果有自定义目录，目录下就会有Desktop.ini文件，因此你需要忽略Windows自动生成的垃圾文件： # Windows: Thumbs.db ehthumbs.db Desktop.ini 然后，继续忽略Python编译产生的.pyc、.pyo、dist等文件或目录： # Python: *.py[cod] *.so *.egg *.egg-info dist build 加上你自己定义的文件，最终得到一个完整的.gitignore文件，内容如下： # Windows: Thumbs.db ehthumbs.db Desktop.ini # Python: *.py[cod] *.so *.egg *.egg-info dist build # My configurations: db.ini deploy_key_rsa 最后一步就是把.gitignore也提交到Git，就完成了！当然检验.gitignore的标准是git status命令是不是说working directory clean。 配置别名有没有经常敲错命令？比如git status？status这个单词真心不好记。 如果敲git st就表示git status那就简单多了，当然这种偷懒的办法我们是极力赞成的。 我们只需要敲一行命令，告诉Git，以后st就表示status： # git config --global alias.st status 好了，现在敲git st看看效果。 当然还有别的命令可以简写，很多人都用co表示checkout，ci表示commit，br表示branch： # git config --global alias.co checkout # git config --global alias.ci commit # git config --global alias.br branch 以后提交就可以简写成： # git ci -m &quot;bala bala bala...&quot; --global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。 配置文件配置Git的时候，加上--global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用。 配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中： # cat .git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [alias] last = log -1 别名就在[alias]后面，要删除别名，直接把对应的行删掉即可。 而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中： # cd ~ # cat .gitconfig [user] name = koen email = 379148058@qq.com [color] ui = true [alias] ci = commit 配置别名也可以直接修改这个文件，如果改错了，可以删掉文件重新通过命令配置。 EOF 本文作者：Koen 原文链接：http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000]]></content>
      <categories>
        <category>通用技巧</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell简介与基础编程]]></title>
    <url>%2Fck74yvgor0021dhkckcuzt4yt.html</url>
    <content type="text"><![CDATA[Linux.Shell简介 什么是ShellShell是核心程序（Kernel）之外的指令解析器，是一个程序，同时也是一种命令语言和程序设计语言。 Shell的类型目前流行的 Shell 有ash、bash、ksh、csh、zsh等，它们各自都有自己的特点，可以根据自己的需要选择相应的Shell，现在在诸多Linux发行版本中默认使用的shell是 Bash Shell。 ashash shell 是由Kenneth Almquist编写的，Linux中占用系统资源最少的一个小shell，它只包含24个内部命令，因而使用起来很不方便。 bashbash 是Linux系统默认使用的shell，它由Brian Fox和Chet Ramey共同完成，是Bourne Again Shell的缩写，内部命令一共有40个（可使用help命令查看）。Linux使用它作为默认的shell是因为它有诸如以下的特色： 可以使用类似DOS下面的doskey的功能，用方向键查阅和快速输入并修改命令。 自动通过查找匹配的方式给出以某字符串开头的命令。 包含了自身的帮助功能，你只要在提示符下面键入help就可以得到相关的帮助。 kshksh 是Korn shell的缩写，由Eric Gisin编写，共有42条内部命令。该shell最大的优点是几乎和商业发行版的ksh完全兼容，这样就可以在不用花钱购买商业版本的情况下尝试商业版本的性能了 cshcsh是Linux比较大的Shell，它由以William Joy为代表的共计47位作者编成，共有52个内部命令。该shell其实是指向/bin/tcsh这样的一个shell，也就是说，csh其实就是tcsh。 zshzch 是Linux最大的shell之一，由Paul Falstad完成，共有84个内部命令。如果只是一般的用途，是没有必要安装这样的shell的。 变量和运算符 什么是Shell变量Shell变量其实就是放在内存中的一定的存储单元，而这个存储单元里存放着这个变量的值，这个值是可以进行改变的。 变量类型本地变量（局部变量）本地变量（局部变量）只在创建它们的shell中可用 例： # lmx=4 #新建本地变量，并将其赋值为4 然后用set命令查看： # set ... XDG_RUNTIME_DIR=/run/user/0 XDG_SESSION_ID=8 _= colors=/root/.dircolors lmx=4 注：set命令可以显示本地所有的变量 接着将本shell注销重新登录或者新开启一个shell，执行set命令： # set ... XDG_RUNTIME_DIR=/run/user/0 XDG_SESSION_ID=10 _=PATH colors=/root/.dircolors 发现之前设置的lmx变量不见了，因为本地变量（局部变量）只在创建它们的shell中可用。 附：readonly &lt; variable_name &gt; #设置只读变量 # lmx=4 # readonly lmx #创建本地变量lmx，并设置其只读 环境变量环境变量可以在创建它们的shell及其派生出来的任意子进程中使用。它们通常被称为全局变量，以区别于本地变量（局部变量），通常环境变量应该大写。环境变量是已经用export内置命令导出的变量。 变量被创建时所处的shell被称为父shell。如果父shell又启动了一个shell，这个新的shell被称作子shell。环境变量将传递给从创建它们的shell里启动的任意子进程。它们从父亲传递给儿子再到孙子等，但是不可向其他方向传递。比如，一个子进程可以创建环境变量，但不能将它传回给它的父进程，只能传给它的子进程。有一些环境变量，比如HOME、LOGNAME、PATH和SHELL，在用户登录之前就已经被/bin/login程序设置好了。通常，环境变量定义并保存在用户主目录下的.bash_profile文件中。 如果想设置环境变量，就要在给变量赋值之后或设置变量时使用export命令： # lmx=4 # export lmx # export #查看环境变量 ... declare -x TERM=&quot;xterm&quot; declare -x USER=&quot;root&quot; declare -x XDG_RUNTIME_DIR=&quot;/run/user/0&quot; declare -x XDG_SESSION_ID=&quot;10&quot; declare -x lmx=&quot;4&quot; 设置环境变量后在父sehll中启动一个子shell，再次使用export查看环境变量： # /bin/bash #启动一个子shell # export ... declare -x TERM=&quot;xterm&quot; declare -x USER=&quot;root&quot; declare -x XDG_RUNTIME_DIR=&quot;/run/user/0&quot; declare -x XDG_SESSION_ID=&quot;10&quot; declare -x lmx=&quot;4&quot; 发现lmx变量还在，可见环境变量可以创建它的shell中传递到子shell中。 变量替换 ${Variable_name:+value} 如果设置了Variable_name，则显示value，否则为空 ${Variable_name:?value} 如果未设置Variable_name，显示用户定义的错误信息value ${Variable_name:-value} 如果未设置Variable_name，则显示其值value，否则显示变量的值 ${Variable_name:=value} 如果未设置Variable_name，设置其值为value，并显示，否则显示变量的值 变量清除unset Variable_name 注：只读变量（readonly）不可以unset 位置变量 $0 表示脚本名称 $1 表示传递给脚本或shell命令的第一个参数 …… $9 表示传递给脚本或shell命令的第九个参数 例如： 123456789101112#!/bin/bash#parm.shecho "名字:$0"echo "第1个参数: $1"echo "第2个参数: $2"echo "第3个参数: $3"echo "第4个参数: $4"echo "第5个参数: $5"echo "第6个参数: $6"echo "第7个参数: $7"echo "第8个参数: $8"echo "第9个参数: $9" 运行命令如下 ./parm A B C D E F G H I 第1个参数: A 第2个参数: B 第3个参数: C 第4个参数: D 第5个参数: E 第6个参数: F 第7个参数: G 第8个参数: H 第9个参数: I 注：利用 $num 的方式来表示位置变量最多只能到$9，不可以超过9个 标准变量bash默认建立了一些标准环境变量，可在/etc/profile中定义，例如：HOME、LOGNAME、MAIL、MAILCHECK 特殊变量 $# 传递到脚本中的参数个数 $* 以一个单字符显示所有向脚本中传递的参数。与位置变量不同，此项参数可超过9个 $$ 脚本运行的当前进程ID号 $? 显示最后命令的退出状态，0表示没有错误，其他任何值表明有错误 $- 显示shell使用的当前选项，与set命令功能相同 $! 后台运行的最后一个进程的进程ID号 影响变量的命令declare设置或显示变量 -f 只显示函数名 -r 创建只读变量 -i 创建整数变量 export用于创建传给子shell的变量，即环境变量 -n 把环境变量转换成本地变量（局部变量），换句话说，变量不再传给子shell -p 显示环境变量列表 shift [n]用于移动位置变量，调整位置变量，使用$3的值赋予$2 例如： 1234567891011121314151617181920212223#!/bin/bash#parm.shecho "名字:$0"echo "第1个参数: $1"echo "第2个参数: $2"echo "第3个参数: $3"echo "第4个参数: $4"echo "第5个参数: $5"echo "第6个参数: $6"echo "第7个参数: $7"echo "第8个参数: $8"echo "第9个参数: $9"shift 1echo "名字:$0"echo "第1个参数: $1"echo "第2个参数: $2"echo "第3个参数: $3"echo "第4个参数: $4"echo "第5个参数: $5"echo "第6个参数: $6"echo "第7个参数: $7"echo "第8个参数: $8"echo "第9个参数: $9" 运行命令如下： # ./test.sh A B C D E F G H I 名字:./test.sh 第1个参数: A 第2个参数: B 第3个参数: C 第4个参数: D 第5个参数: E 第6个参数: F 第7个参数: G 第8个参数: H 第9个参数: I 名字:./test.sh 第1个参数: B 第2个参数: C 第3个参数: D 第4个参数: E 第5个参数: F 第6个参数: G 第7个参数: H 第8个参数: I 第9个参数: 双引号使用双引号引用除字符$、`、\ 外的任意字符或字符串 例如： # hostname=&quot;$HOSTNAME&quot; # echo $hostname server1.example.com 单引号会忽略任何引用值。换句话说，如果屏蔽了其特殊含义，会将引号里的所有字符，包括引号都作为一个字符串 例如： # hostname=&apos;$HOSTNAME&apos; # echo $hostname $HOSTNAME 反引号将反引号中的内容作为一个系统命令，并执行其内容 例如： # echo `date` Thu Jul 30 20:52:47 CST 2015 反斜杠屏蔽有特殊含义的特殊字符 $[ ]表示形式告诉shell对方括号中的表达式求值，例如： # echo $[2+8] 10 $[base#n]base进制的数n，例如： # echo $[10#8+1] 9 Shell的输入与输出 echo显示文本行或变量或者把字符串输入到文件中 echo [option] string -e 解析转义字符 -n 回车不换行，Linux系统默认回车换行 read从键盘或文件的某一行文本中读入信息并将其赋给一个变量 read variable1 variable2 例如： 1234567#!/bin/bash#readnameecho -n "first name:"read firstnameecho -n "last name:"read lastnameecho -e "your name is :\n$firstname $lastname" 运行命令如下： ./test.sh first name:koen last name:li your name is : koen li 标准输入、标准输出与标准错误在 Shell 执行命令时，每个进程都和三个打开的文件相联系，并使用文件描述符来引用这些文件。由于文件描述符不易记忆，Shell同时也给出了相应的文件名： 文件名 文件描述符 输入文件-标准输入 0（缺省是屏幕，也可以是文件） 输出文件-标组输出 1（缺省是键盘，也可以是文件或其他命令的输出） 错误输出文件-标准错误 2（缺省是屏幕，也可以是文件） 系统实际上有12个文件描述符，可以任意使用文件描述符3到9 文件重定向 command 1&gt; filename #把标准输出重定向到一个新文件中 command &gt; filename 2&gt;&amp;1 #把标准输出和标准错误都重定向到filename中 command &gt;&gt; filename 2&gt;&amp;1 #把标准输出和标准错误都重定向追加到filename中 command &lt;&lt; delimiter #从标准输入读入数据，直到delimiter遇到delimiter结束 command &lt; &amp;m #文件描述符m作为标准输入 command &gt; &amp;m #把标准输出重定向到文件描述符m中 command &lt; &amp;- #关闭标准输入 exec可用来代替当前的Shell，换句话说，并没有启动子Shell，使用这一命令时任何现有环境都将会被清除，并重新启动一个Shell exec command 其中command通常是一个Shell脚本 控制流结构 if语句语法格式一： if 条件1;then 命令1 fi 语法格式二： if 条件1;then 命令1 else 命令2 fi 语法格式三： if 条件1;then 命令1 elif 条件2;then 命令2 else 命令3 fi 例如： 12345678910#!/bin/bash#ifage=18if [ $age -ge 18 ];then echo "you are adult!"elif [ $age -ge 13 ];then echo "you are teenager!"else echo "you are child!"fi 运行命令如下： # ./test.sh you are adult! case语句语法格式： case 变量 in 模式1) 命令1 ;; 模式2) 命令2 ;; *) 命令3 ;; esax 例如： 123456789101112#!/bin/bash#casecase $1 indog) echo "you are dog!" ;;cat) echo "you are cat!" ;;*) echo "I don't konw what you are!"esac 运行命令如下： # ./test.sh dog you are dog! # ./test.sh cat you are cat! # ./test.sh I don&apos;t konw what you are! for循环语法格式： for 变量名 in 列表 do 命令1 命令2 done 例如： 123456#!/bin/bash#forfor loop in 1 2 3 4 5do echo $loopdone 运行命令如下： # ./test.sh 1 2 3 4 5 until循环语法格式： until 条件 do 命令1 命令2 done 注：条件可为任意测试条件，测试发生在循环末尾，因此循环至少执行一次 例如： 1234567891011#!/bin/bash#untilpart=/mnt/yumLOOK_OUT=`df |grep $part |awk '&#123;print $5&#125;' |sed 's/%//g'`echo $LOOK_OUTuntil [ "$LOOK_OUT" -gt "90" ]do echo "filesystem is nearly full" | mail root LOOK_OUT=`df |grep $part |awk '&#123;print $5&#125;' |sed 's/%//g'` sleep 36000done 运行命令如下： # ./test.sh 100 While循环语法格式： while 条件/命令 do 命令1 命令2 done 注：在while和do之间虽然通常只使用一条命令，但可以放几条命令，命令通常用作测试条件 例如： 12345678#!/bin/bash#whilewhile :do date sleep 3doneecho "sum is $sum" 运行命令如下： # ./test.sh Thu Jul 30 20:21:20 CST 2015 Thu Jul 30 20:21:23 CST 2015 ... break [n]退出循环，如果是在一个嵌套循环中，可以通过n来指定跳出的循环个数 continue跳出循环步 文本过滤 正则表达式一种用来描述文本模式的特殊语法 正则表达式语言由两种基本字符类型组成：原义（正常）文本字符和元字符。元字符使正则表达式具有处理能力。所谓元字符就是指那些在正则表达式中具有特殊意义的专用字符，可以用来规定其前导字符（即位于元字符前面的字符）在目标对象中的出现模式。 字符 含义 字符 含义 ^ 只匹配行首 $ 只匹配行尾 * 匹配0个或多个在*之前的字符 [ ] 只匹配[]内字符，可以是一个单字符，也可以是符号序列，使用-表示[ ]内字符序列范围，如用[1-5]代替[12345] \ 只用来屏蔽一个元字符的特殊含义 . 只匹配任意单字符 pattem\ {n\ } 只用来匹配前面pattem出现次数，n为次数 pattem\ {n,\ } 含义同上，但次数最少为n pattem\ {n,m\ } 含义同上，但pattem出现次数在n和m之间 Find命令一般形式：find pathname -option [-print -exec -ok] 常用选项-print 将匹配的文件输出到标准输出 -exec 对匹配的文件执行该参数所给出的shell命令，相应命令的形式为command {} \; -ok 与-exec的作用相同，只不过以一种更安全的模式来执行该参数所给出的shell命令，在执行一个命令之前，都会给出提示，让用户来确定是否执行 更多帮助：man find Xargs在使用find命令的-exec选项处理匹配到的文件时，find命令将所有匹配到的文件一起传递给exec。不幸的是，有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是Xargs命令的用处所在，特别是与find命令一起使用。exec会发起多个进程，而Xargs不会多个，只有一个。 # find / -perm -7 -print | xargs chmod o-w Grep命令对文本进行模式查找 一般格式：grep [选项] 基本正则表达式 [文件] 三种变形 Grep 标准grep命令 Egrep 扩展grep，支持基本及扩展的正则表达式 Fgrep 快速grep 常用选项-c 只输出匹配行的计数-i 不区分大小写（只使用于单字符）-h 查询多文件时，不显示文件名-H 显示文件名-l 查询多文件时，只输出包含匹配字符的文件名-n 显示匹配的行及行号-s 不显示不存在或无匹配文本的错误信息-v 显示不包含匹配文本的所有行 Grep命令类名 grep命令类名 等价正则表达式或含义 grep命令类名 等价正则表达式或含义 [[:upper:]] [A-Z] [[:space:]] 空格或tab键 [[:alnum:]] [0-9a-zA-Z] [[:digit:]] [0-9] [[:lower:]] [a-z] [[:alpha:]] [a-zA-Z] 匹配IPv4地址：[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\}.[0-9]\{1,3\} Awk命令可从文件或字符串中基于指定规则浏览和抽取信息，是一种自解释的编程语言 三种调用方式 命令行方式：awk [-F filed-spearator] &#39;command&#39; input_files awk脚本 awk命令插入一个单独文件 awk -f awk-script-file input-files 模式和动作Awk脚本由各种动作和模式组成： 模式部分决定动作语句何时触发及触发事件（BEGIN、END）动作对数据进行处理，放在大括号{ }内指明（print） 分割符、域和记录awk执行时，其浏览域标记为$1、$2、…$n，这种方法称为域标识，$0为所有域 例如： # awk -F : &apos;{print $0&quot;\t&quot;$4}&apos; /etc/passwd # awk &apos;BEGIN{print &quot;IP\n------&quot;} {print $1&quot;\t&quot;$4} END{print &quot;IP\n------&quot;}&apos; score.txt awk中的特殊字符 + 匹配任意字符 ？ 匹配单个字符 awk中的匹配操作符 ~ 表示匹配 ！~ 表示不匹配 例如： # cat score.txt | awk &apos;$0~/218.79.131.96/&apos; # awk &apos;{if($1==&quot;218.79.131.96&quot;) print $0}&apos; score.txt 更过帮助：man awk 或 info awk Sed命令Sed不与初始化文件打交道，它操作的只是一个拷贝，然后所有的改动如果没有重定向到一个文件中，将输出到屏幕 三种调用方式 命令行格式：sed [选项] sed_command input_files sed脚本文件 sed [选项] -f sed_script_file input_files sed脚本文件 [选项] 输入文件 Sed在文件中查询文本的方式 使用行号，可以是一个简单数字，或是一个行号范围 使用正则表达式 x x为一行号 x，y 表示行号范围x到y /pattern/ 查询包含模式的行 /pattern/pattern/ 查询包含两个模式的行 pattern/,x 在给定行号上查询包含模式的行 x,/pattern/ 通过行号和模式查询匹配行 x,y! 查询不包含指定行号x和y的行 基本Sed编辑命令p 打印匹配行 = 显示文件行号 a\ 在定位行号后附加新文本信息 i\ 在定位行号前插入新文本信息 d 删除定位行 c\ 用新文本替换定位文本 s 使用替换模式替代相应模式 r 从另一个文本中读文本 w 写文本到一个文件 选项-n 不打印未匹配的 例如： sed &#39;2p&#39; score.txt sed -n &#39;2p&#39; score.txt #打印第2行 sed -n &#39;4,/los/p&#39; score.txt #打印第4行到第一次匹配los的行 sed -n &#39;/^$/=&#39; score.txt #显示空行行号 sed -n -e &#39;/^$/p&#39; -e &#39;/^$/=&#39; myfile.txt sed -n &#39;/chinaitlab/a\shenzhen&#39; myfile.txt #匹配到chinaitlab后在其后面添加文本 sed -n &#39;/chinaitlab/&amp; hello/p&#39; myfile.txt #匹配到后在后面加上hello Sort命令常用选项-c 测试文件是否已经分类（排序） -m 合并两个分类（排序）文件 -u 删除所有重复行 -o 存储sort结果的输出文件名 -t 域分隔符 -r 比较求逆 - +n n为域号，使用此域号开始分类 -n 指定分类是域上的数字分类项 Uniq命令从一个文本文件中去除或禁止重复行 常用选项-u 只显示不重复行 -d 只显示有重复数据行，每种重复行只显示其中一行 -c 打印每一重复行出现次数 -f [n] n为数字，前n个域被忽略 Split命令用来将大文件分割成小文件 ###一般格式：### split -output_file_size input_filename output_filename 常用选项-b n 每个分割文件的大小为n(k,m) -C n 每个分割文件一行最多n字节数 -l n 每个分割文件的行数 -n 同-l n 例如： # split -10 ls_out.txt splita Shell 函数 什么是函数Shell允许将一组命令集或语句形成一个可用块，这些块称为Shell函数 函数定义与调用定义方法一： 函数名（） { 命令1 ... } 定义方法二： function 函数名() { 命令1 ... } 函数可以放在同一个文件中作为一段代码，也可以放在只包含函数的单独文件中 例如： 123456789#/bin/bash#funcfunction hello()&#123; echo "Hello,today is `date`"&#125;echo "now going to the function hello"helloecho "back from the function" 运行命令如下： # ./test.sh now going to the function hello Hello,today is Thu Jul 30 20:33:04 CST 2015 back from the function 向函数传递参数就像在脚本中使用位置变量\$1、\$2…\$9 例如： 123456789#/bin/bash#funcfunction hello()&#123; echo "Hello,$1 today is `date`"&#125;echo "now going to the function hello"hello shenzhenecho "back from the function" 运行命令如下： # ./test.sh now going to the function hello Hello,shenzhen today is Thu Jul 30 20:35:55 CST 2015 back from the function 函数文件例如： # vim hellofun.sh 1234567#/bin/bash#hello funfunction hello()&#123; echo "Hello,$1 today is `date`" return 1&#125; # vim test.sh 1234567#/bin/bash#func# Source function. hellofun.shecho "now going to the function hello"hello shenzhenecho "back from the function" 运行命令如下： # ./test.sh now going to the function hello Hello,shenzhen today is Thu Jul 30 20:42:31 CST 2015 back from the function 检查载入函数和删除函数检查载入函数：set 例如： 12345678#/bin/bash#func# Source function. hellofun.shsetecho "now going to the function hello"hello shenzhenecho "back from the function" 运行命令如下： # ./test.sh ... XDG_RUNTIME_DIR=/run/user/0 XDG_SESSION_ID=10 _=hellofun.sh lmx=4 hello () { echo &quot;Hello,$1 today is `date`&quot;; return 1 } now going to the function hello Hello,shenzhen today is Thu Jul 30 20:45:23 CST 2015 back from the function 删除函数：unset 函数名 例如： 12345678910#/bin/bash#func# Source function. hellofun.shsetecho "now going to the function hello"hello shenzhenunset hellosetecho "back from the function" 运行命令如下： # ./test.sh ... XDG_RUNTIME_DIR=/run/user/0 XDG_SESSION_ID=10 _=hellofun.sh lmx=4 hello () { echo &quot;Hello,$1 today is `date`&quot;; return 1 } now going to the function hello Hello,shenzhen today is Thu Jul 30 20:45:23 CST 2015 ... XDG_RUNTIME_DIR=/run/user/0 XDG_SESSION_ID=10 _=hello lmx=4 back from the function EOF 本文作者：Koen]]></content>
      <categories>
        <category>Code堡垒</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown简介与简明语法]]></title>
    <url>%2Fck74yvgoj001bdhkcd3n9p6y9.html</url>
    <content type="text"><![CDATA[简介 Markdown 是一种可以使用普通文本编辑器编写的标记语言，通过类似HTML的标记语法，它可以使普通文本内容具有一定的格式。 用途 Markdown 语法简洁明了、学习容易，而且功能比纯文本更强，因此有很多人用它写博客。世界上最流行的博客平台 WordPress 和 大型CMS如 Joomla、Drupal都能很好的支持Markdown。完全采用Markdown编辑器的博客平台有 Ghost 和 Typecho。 特殊字符自动转换 在 HTML 文件中，有两个字符需要特殊处理： &lt;和 &amp; 。 &lt; 符号用于起始标签，&amp; 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &amp;lt; 和 &amp;amp;。 &amp; 字符尤其让网络文档编写者受折磨，如果你要打「AT&amp;T」 ，你必须要写成「AT&amp;amp;T」。而网址中的 &amp; 字符也要转换。比如你要链接到： http://images.google.com/images?num=30&amp;q=larry+bird 你必须要把网址转换写为： http://images.google.com/images?num=30&amp;amp;q=larry+bird 才能放到链接标签的 href 属性里。不用说也知道这很容易忽略，这也可能是 HTML 标准检验所检查到的错误中，数量最多的。 Markdown 让你可以自然地书写字符，需要转换的由它来处理好了。如果你使用的 &amp; 字符是 HTML 字符实体的一部分，它会保留原状，否则它会被转换成 &amp;amp;。 所以你如果要在文档中插入一个版权符号 ©，你可以这样写： &amp;copy; Markdown 会保留它不动。而若你写： AT&amp;T Markdown 就会将它转为： AT&amp;amp;T 类似的状况也会发生在 &lt; 符号上，因为 Markdown 允许兼容HTML，如果你是把 &lt; 符号作为 HTML 标签的定界符使用，那 Markdown 也不会对它做任何转换，但是如果你写： 4 &lt; 5 Markdown 将会把它转换为： 4 &amp;lt; 5 不过需要注意的是，code范围内，不论是行内还是区块， &lt; 和 &amp; 两个符号都一定会被转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML code（和HTML相对而言，HTML语法中，你要把所有的 &lt; 和 &amp; 都转换为HTML实体，才能在HTML文件里面写出HTML code） Markdown简明语法 区块元素段落和换行一个Markdown段落是由一个或多个连续的文本行组成的，它的前后要有一个以上的空行。（空行的定义是显示上看起来像是空的，便会被视为空行。比如说，若某一行只包含空格和制表符，则该行也会被视为空行）普通段落不该用空格或制表符来缩进。 「由一个或多个连续的文本行组成」这句话其实暗示了Markdown允许段落内的强迫换行（插入换行符），这个特性和其他大部分的text-to-HTML格式不一样，其他的格式会把每个换行符都转成&lt;br/&gt;标签 如果你确实想要依赖Markdown来插入&lt;br/&gt;标签的话，在插入处先按入两个以上的空格然后回车。 标题Markdown 支持两种标题的语法，类Setext 和 类Atx 形式 类Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 注：任何数量的 = 和 - 都可以有效果。 类Atx 形式则是在行首插入1到6个 #，对应一级标题到六级标题，例如： # 这是 H1 ## 这是 H2 ###### 这是 H6 你可以选择性的闭合 类Atx 样式的标题，这纯粹只是美观用的，若是觉得这样看起来比较舒适，你就可以在行尾加上 #，而行尾的 # 数量也不用和开头的一样（行首的井字符数量才决定标题的阶数）： # 这是 H1 # ## 这是 H2 ## ### 这是 H3 ###### 区块引用如果你需要引用一小段别处的句子，那么就要用到引用的格式了。 要使用区块引用，你只需要在文本前加入 &gt; 这种尖括号（大于号）即可： &gt; 例如这样 Markdown 允许你偷懒只在整个段落的第一行最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： &gt; This is the first level of quoting. &gt; &gt; &gt; This is nested blockquote. &gt; &gt; Back to the first level. 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： &gt; ## 这是一个标题。 &gt; &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 列表Markdown 支持 有序列表 和 无序列表。 无序列表 使用星号(*)、加号(+)或者减号(-)作为列表标记： * Red * Green * Blue 等价于 + Red + Green + Blue 等价于 - Red - Green - Blue 有序列表 使用数字接一个英文句点(.)作为列表标记： 1. Bird 2. McHale 3. Parish 表格| | | | #表头 | ---- | ---: | :--: | #设置字体对齐方式 | | | | #表项内容 | | | | | | | | | —— | 默认左对齐 | —–: | 右对齐 | :—-: | 居中对齐 代码区块和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 &lt;pre&gt; 和 &lt;code&gt; 标签来把代码区块包起来。 要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或者 1 个制表符就可以，例如： 这是一个普通段落： 这是一个代码区块。 Markdown 会转换成： &lt;p&gt;这是一个普通段落：&lt;/p&gt; &lt;pre&gt;&lt;code&gt;这是一个代码区块。 &lt;/code&gt;&lt;/pre&gt; 代码高亮显示` ` `python @requires_authorization class SomeClass: pass if __name__ == &apos;__main__&apos;: # A comment print &apos;hello world&apos; ` ` ` 分割线在一行中用三个以上的星号(*)、减号(-)、底线(_)来建立一个分割线，行内不能有其他东西。你也可以在星号或者减号中间插入空格。下面的每种写法都可以建立分割线： * * * *** ***** - - - --------------------------------------- 区段元素链接Markdown 支持两种形式的链接语法：行内式 和 参考式 两种形式。 行内式 链接文字用 [方括号] 来标记，然后在方括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号(&quot;)把 title 文字包起来即可，例如： This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. 如果你是要链接到同样主机的资源，你可以使用相对路径： See my [About](/about/) page for details. 参考式 链接文字也用 [方括号] 来标记，然后在链接文字的方括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is [an example][id] reference-style link. 接着，在文件的任意处，你可以把这个标记的链接内容定义出来： [id]: http://example.com/ &quot;Optional Title Here&quot; 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着一个以上的空格或制表符 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或者括弧包着 下面这三种链接的定义都是相同： [foo]: http://example.com/ &quot;Optional Title Here&quot; [foo]: http://example.com/ &apos;Optional Title Here&apos; [foo]: http://example.com/ (Optional Title Here) 注：有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 强调Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 &lt;em&gt; 标签包围，用两个 * 或 _ 包起来的话，则会被转成 &lt;strong&gt;，例如： *single asterisks* _single underscores_ **double asterisks** __double underscores__ 会转成： &lt;em&gt;single asterisks&lt;/em&gt; &lt;em&gt;single underscores&lt;/em&gt; &lt;strong&gt;double asterisks&lt;/strong&gt; &lt;strong&gt;double underscores&lt;/strong&gt; 注：如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： \*this text is surrounded by literal asterisks\* 代码如果要标记一小段行内代码，你可以用反引号把它包起来（`），例如： Use the `printf()` function. 会产生： &lt;p&gt;Use the &lt;code&gt;printf()&lt;/code&gt; function.&lt;/p&gt; 图片很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。 Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式 和 参考式 行内式 行内式的图片语法如下： ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 title 文字。 参考式 参考式的图片语法如下： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式和链接参考一样： [id]: url/to/image &quot;Optional title attribute&quot; 注：到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 &lt; img &gt; 标签。 其它自动链接Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用方括号包起来即可，Markdown就会自动把它转成链接，一般网址的链接文字就和链接地址一样，例如： &lt;http://example.com/&gt; Markdown 会转为： &lt;a href=&quot;http://example.com/&quot;&gt;http://example.com/&lt;/a&gt; 反斜杠Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号 Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 最后推荐一款Markdown编辑器：MarkdownPad 如果你嫌安装软件太麻烦了，没关系，有在线Markdown编辑器： Cmd Markdown Online Markdown Editor EOF 本文作者：Koen 原文链接：http://www.appinn.com/markdown/index.html#html]]></content>
      <categories>
        <category>通用技巧</category>
      </categories>
      <tags>
        <tag>语言</tag>
        <tag>博客</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Hexo搭建博客]]></title>
    <url>%2Fck74yvgow002hdhkclb1np6d9.html</url>
    <content type="text"><![CDATA[一直以来都想要创建属于自己的博客，刚好最近无意中了解到了Hexo这款基于Node.js的博客框架，尝试了一番，觉得很不错，就此写一篇个人总结。 搭建环境(Windows平台下) 安装文本编辑器：Sublime Text 或 Nodepad++ Hexo的文件编码格式为UTF-8 安装Git 下载Git for Windows 进入上面的链接，然后点击 “Windows” 即可自动下载符合你Windows平台的Git安装包 运行Git安装包 点击“ Next ” 点击” Next “ 选择 Git 的安装路径，然后点击” Next “ 勾选要安装的组件，然后点击” Next “ 配置开始菜单文件夹名称，如果不创建就勾选左下角的” Don’t create a Start Menu folder”，然后点击” Next “ 选择是否将Git加入到系统环境变量Path中，建议选择“ Use Git from the Windows Command Prompt”，也可根据自己的喜好选择，然后点击” Next “ 点击” Next “ 开始安装，等待安装完毕 安装成功！ 安装好Git后在GitHub上注册一个账号并登录，如果已经有GitHub账号直接登录，然后在GitHub新建一个仓库(Repository)，作为你博客的版本库。 注：要求GitHub Pages的仓库名必须为your_user_name.github.io 安装Node.js Node安装包里带有npm 安装Hexo 注：新旧版本Hexo安装命令有所区别，请以为官网)为准 运行cmd，执行如下命令安装Hexo npm install hexo-cli -g 查看Node版本 node -v 查看Hexo版本 hexo version 创建并初始化项目 创建项目 hexo init hexo-lmx 进入目录 cd hexo-lmx 安装依赖包 npm install 初始化项目 hexo init 注：之后所有的命令都在该目录下进行(本文中为hexo-lmx目录下) 启动服务 hexo server 用浏览器打开 http://localhost:4000 或者 http://127.0.0.1:4000 就能看到你的博客雏形了，接下来将对你的博客进行一系列自定义配置。 注：按两次Ctrl+c可以停止本地预览服务 使用 目录结构. ├── .deploy #需要部署的文件 ├── node_modules #Hexo插件 ├── public #生成的静态网页文件 ├── scaffolds #模板 ├── source #博客正文和其他源文件，404、favicon、CNAME 都应该放在这里 | ├── _drafts #草稿 | └── _posts #文章 ├── themes #主题 ├── _config.yml #全局配置文件 └── package.json 全局配置_config.yml注：配置文件的冒号”:”后面有空格 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/##Hexo中文配置文档：https://hexo.io/zh-cn/docs/index.html# Site 站点信息title: Koen's Blog #标题subtitle: #副标题description: 想要出类拔萃，就要做别人不想做的事 #站点描述，给搜索引擎看的，可以是自己的座右铭author: Koen #作者email: koen****@gmail.com #此处换成你的电子邮箱language: zh-Hans #语言timezone:# URL 链接设置## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://xautlmx.github.io #博客网址root: / #根目录permalink: :year-:month-:day-:title.html #文章的链接格式#参考https://hexo.io/zh-cn/docs/permalinks.htmlpermalink_defaults:# Directory 目录设置source_dir: source #源文件目录public_dir: public #生成的网页文件目录tag_dir: tags #标签目录archive_dir: archives #归档目录category_dir: categories #分类目录code_dir: downloads/codei18n_dir: :langskip_render:# Writing 写作#Front-matter可以配置文章使用的模板、所属的分类和Tag等#可参考https://hexo.io/zh-cn/docs/front-matter.htmlnew_post_name: :title.md # File name of new posts#新文章标题default_layout: post#默认的模板，包括 post、page、photo、draft（文章、页面、照片、草稿）titlecase: false # Transform title into titlecase#标题转换成大写external_link: true # Open external links in new tab#在新选项卡中打开链接filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: #语法高亮 enable: true #是否启用 line_number: true #显示行号 auto_detect: true tab_replace:# Category &amp; Tag 分类与标签default_category: uncategorized #默认分类category_map:tag_map:# Date / Time format 日期时间格式## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DD#参考http://momentjs.com/docs/#/displaying/format/time_format: HH:mm:ss# Pagination 分页## Set per_page to 0 to disable paginationper_page: 10 #每页文章数，设置为0禁用分页pagination_dir: page# Disqus #Disqus评论，替换为多说disqus_shortname:# Extensions 拓展插件## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: landscape #设置主题# Deployment 部署到github## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: http://github.com/your_user_name/your_user_name.github.io branch: master 命令行的使用常用命令hexo help #查看帮助 hexo init #初始化一个目录 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成网页，可以在 public 目录查看整个网站的文件 hexo server #本地预览，&apos;Ctrl+C&apos;关闭 hexo deploy #部署.deploy目录 hexo clean #清除缓存，**强烈建议每次执行命令前先清理缓存，每次部署前先删除 .deploy 文件夹** 安装插件npm install &lt;plugin-name&gt; --save npm update #升级 npm uninstall &lt;plugin-name&gt; #卸载 &lt; plugin-name &gt;为插件名 安装主题git clone &lt;repository&gt; themes/&lt;theme-name&gt; &lt; repository &gt;为主题的 git 仓库，&lt; theme-name &gt;为要存放在本地的目录名 编辑文章新建文章hexo new &quot;标题&quot; 在 _posts 目录下会生成文件：标题.md title: 标题 date: 2014-11-11 11:11:11 tags: - 标签1 - 标签2 - 标签3 categories: [分类1,分类2,分类3] --- 正文，使用Markdown语法书写 编辑完后保存，执行 hexo server 预览 删除文章先删除仓库里面 source/_posts/ 里的 我的文章.md 文件 然后执行下面命令更新博客： hexo g == hexo generate#生成 hexo s == hexo server #启动预览服务 hexo d == hexo deploy#部署 发布以发布到 Github 为例 先安装Git插件 npm install hexo-deployer-git --save 然后编辑全局配置文件 _config.yml 中的 deploy 部分，your_user_name为用户名 123456# Deployment 部署到github## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repo: http://github.com/your_user_name/your_user_name.github.io branch: master 最后进行部署 hexo deploy 出现以下提示说明部署成功 [info] Deploy done: git 点击 GitHub 上项目的 Settings，GitHub Pages，提示Your site is published at http://xautlmx.github.io/第一次上传网站的话需要等十分钟左右，以后每次更新都能马上打开 优化 配置主题推荐几款酷炫的主题： TKL Next Modernist Mabao Lingyu 如果你觉得都不合你口味，那你可以到Hexo的主题列表中慢慢挑，总有一款适合你&gt;_&lt; 下载主题$ git clone &lt;repository&gt; themes/&lt;theme-name&gt; 注：务必将整个主题目录放在 theme 目录下 在全局配置文件 _config.yml 中将 theme 一行改成想要的主题 theme: Next 主题目录结构. ├── languages #国际化 | ├── default.yml #默认 | └── zh-CN.yml #中文 ├── layout #布局 | ├── _partial #局部的布局 | └── _widget #小挂件的布局 ├── script #js脚本 ├── source #源代码文件 | ├── css #CSS | | ├── _base #基础CSS | | ├── _partial #局部CSS | | ├── fonts #字体 | | ├── images #图片 | | └── style.styl #style.css | ├── fancybox #fancybox | └── js #js ├── _config.yml #主题配置文件 └── README.md #主题介绍 以下是主题 Next 的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# when running hexo in a subdirectory (e.g. domain.tld/blog), remove leading slashes ( "/archives" -&gt; "archives" )#菜单设置menu: home: / #主页 #categories: /categories #分类页 archives: /archives #归档页 tags: /tags #标签页 about: /about #关于页面 #commonweal: /404.html #公益404页面# Place your favicon.ico to /source directory.favicon: /favicon.ico# Set default keywords (Use a comma to separate)keywords: "Hexo,next"# Set rss to false to disable feed link.# Leave rss as empty to use site's feed link.# Set rss to specific value if you have burned your feed already.rss:# Icon fonts# Place your font into next/source/fonts, specify directory-name and font-name here# Avialable: default | linecons | fifty-shades | feathericon_font: default#icon_font: fifty-shades#icon_font: feather#icon_font: linecons# Code Highlight theme# Available value: normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: normal# MathJax Supportmathjax:# Schemesscheme: Mist#侧栏设置# Sidebar, available value:# - post expand on posts automatically. Default.# - always expand for all pages automatically# - hide expand only when click on the sidebar toggle icon.#sidebar: post #在文章页面（拥有目录列表）时显示sidebar: always #在所有页面中都显示#sidebar: hide #在所有页面中都隐藏（可以手动展开）#头像设置avatar: /images/head_portrait.jpg# Automatically scroll page to section which is under &lt;!-- more --&gt; mark.scroll_to_more: true# Automatically add list number to toc.toc_list_number: true#首页显示文章摘录设置# Automatically Excerptauto_excerpt: enable: enable length: 150# Use Lato font# Note: this option is avialable only when the language is not `zh-Hans`use_font_lato: true# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0## DO NOT EDIT THE FOLLOWING SETTINGS## UNLESS YOU KNOW WHAT YOU ARE DOING# Use velocity to animate everything.use_motion: true# Fancyboxfancybox: true# Static filesvendors: vendorscss: cssjs: jsimages: images# Theme version 主题版本version: 0.4.5.1 更多有关Next主题的配置请参考Next主题配置指南 如果对Hexo搭建博客仍有疑问可以参考Hexo官方文档 EOF 本文作者：koen 原文链接：http://blog.lmintlcx.com/post/blog-with-hexo.html]]></content>
      <categories>
        <category>通用技巧</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
